<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-07-17 Sun 16:30 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Kubernetes-cka udemy Notes</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Udemy Mumshad Mannambeth" />
<meta name="description" content="Running Notes for Kubernetes."
 />
<meta name="keywords" content="org-mode, export, html, theme, style, css, js, bigblow" />
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="content">
<h1 class="title">Kubernetes-cka udemy Notes</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgad91bf5">Pre-Requisites:</a></li>
<li><a href="#orgf730b99">Course ToC</a></li>
<li><a href="#orgd4d14cb">Kubernetes trilogy</a>
<ul>
<li><a href="#org88408f4">Kubernetes for Administration</a></li>
<li><a href="#orgde45dc7">Kubernetes for Developers</a></li>
</ul>
</li>
<li><a href="#orgdd09559">Kubernetes Master-Worker(Node) Architecture :</a>
<ul>
<li><a href="#org4dd6c6a">Introduction</a></li>
<li><a href="#org9978309">Etcd</a>
<ul>
<li><a href="#org32d156d">Introduction</a></li>
<li><a href="#orgacaaff2">etcd cmd</a></li>
<li><a href="#orgf97a3a7">Roles of  ETCD in Kubernetes</a></li>
</ul>
</li>
<li><a href="#org6eafe20">Kube-api Server</a>
<ul>
<li><a href="#orga06581e">Kube-API Server Into</a></li>
<li><a href="#orgc7e282e">Install Kube-api Server</a></li>
<li><a href="#org0cd65e5">View api-server - kubeadm</a></li>
<li><a href="#orga38ac33">View api-server options - kubeadm</a></li>
<li><a href="#org4dc5c99">View api-server options</a></li>
</ul>
</li>
<li><a href="#org9b2e51f">Contorll-Manager</a>
<ul>
<li><a href="#orgda26bf1">Controller-Manager Intro</a></li>
<li><a href="#orgc2def7b">Install kube-contorller-manager</a></li>
</ul>
</li>
<li><a href="#org8dd465d">Scheduler</a>
<ul>
<li><a href="#org1e704c9">Intro</a></li>
<li><a href="#orgd966fa8">Installation,Configuration, view options</a></li>
</ul>
</li>
<li><a href="#org0934ac4">Kubelet</a></li>
<li><a href="#org8f29d5f">Kubeproxy:</a></li>
</ul>
</li>
<li><a href="#org0bed0a2">Kubernetes Cluster(pod) Architecture :</a>
<ul>
<li><a href="#orgc97b6a7">Pods</a>
<ul>
<li><a href="#orgbb06e85">Into</a></li>
<li><a href="#org263e135">Pod with Yaml</a></li>
<li><a href="#org02440dd">Access Lab</a></li>
<li><a href="#org08df9e4">Practice test :</a></li>
<li><a href="#orgfb86901">pod cmd</a></li>
</ul>
</li>
<li><a href="#org9c32334">Replication Contorller vs Replicaset</a>
<ul>
<li><a href="#org3266214">Intro</a></li>
<li><a href="#org17a39fd">Replicatoin-Contorller</a></li>
<li><a href="#orgf428fea">Replicaset</a></li>
<li><a href="#org4f13222">Labels and Selector</a></li>
<li><a href="#orgfc0f6f5">Scale the running deploy/pod of running yaml</a></li>
<li><a href="#org6874762">cmd</a></li>
<li><a href="#orgfd71c84">Auto scale pod based on load &lt;later-discuss advance topics&gt;</a></li>
<li><a href="#org82d3e4c">Practice Test</a></li>
</ul>
</li>
<li><a href="#org21f1212">deployment or deploy</a>
<ul>
<li><a href="#org12e112f">Intro</a></li>
<li><a href="#orgac07b5e">insert the image</a></li>
<li><a href="#org1d7fe9b">Defination</a></li>
<li><a href="#org3596283">Practice Test</a></li>
</ul>
</li>
<li><a href="#orgbfd5d0e">namespaces</a>
<ul>
<li><a href="#org19d5381">Intro</a></li>
<li><a href="#orgb70a4f8">Different Namespace in kubernetecis</a></li>
<li><a href="#org7b0c50d">Namespace- Isolation</a></li>
<li><a href="#org31c4a78">Nampespace Policy(Rules)</a></li>
<li><a href="#orgf372749">Namespace - Resource limit</a></li>
<li><a href="#org755637e">DNS</a></li>
<li><a href="#org8651972">cmd</a></li>
<li><a href="#orgf0394ee">Create your own namespace:</a></li>
<li><a href="#org1dcde11">Switch</a></li>
<li><a href="#orgd91b23f">Resource Quota</a></li>
<li><a href="#org31d3aca">Practice Test</a></li>
</ul>
</li>
<li><a href="#orgbb17605">services</a>
<ul>
<li><a href="#orgcb010e8">Intro to Service-Type</a></li>
<li><a href="#orge007ffd">cmd for services, clusterip, nodeport, loadbalancer</a></li>
<li><a href="#org54c3efb">yaml file for nginx-with-no-service, service-yaml for clusterip, nodeport, loadbalancer</a></li>
</ul>
</li>
<li><a href="#org4bebd73">Imperative(cmd line interface cli) vs Declarative(script , yaml file )</a></li>
</ul>
</li>
<li><a href="#org3f2d137">Scheduling  | 1h 50 mints</a>
<ul>
<li><a href="#org7510c1d">Manual Scheduling</a></li>
<li><a href="#org6fa63d8">Practice Test - Manual Scheduling</a></li>
<li><a href="#org0fcab55">Solution - Manual Scheduling (optional)</a></li>
<li><a href="#org0b90c12">Labels and Selectors</a>
<ul>
<li><a href="#org5a5adb9">ReplicaSet : insert video expalined neatly</a></li>
<li><a href="#orgfee3167">Annotation :</a></li>
</ul>
</li>
<li><a href="#org02b1a29">Practice Test - Labels and Selectors</a></li>
<li><a href="#org61b8222">Solution : Labels and Selectors : (Optional)</a></li>
<li><a href="#orge4b3d9a">Taints and Tolerations</a></li>
<li><a href="#org38a8b33">Practice Test - Taints and Tolerations</a></li>
<li><a href="#orgc156dee">Solution - Taints and Tolerations (Optional)</a></li>
<li><a href="#orgf040df7">Node Selectors</a></li>
<li><a href="#org8b47623">Node Affinity</a>
<ul>
<li><a href="#orgadd7cb2">Diffenent Types of NodeAffinity</a></li>
</ul>
</li>
<li><a href="#org1205fb1">Practice Test - Node Affinity</a></li>
<li><a href="#orga480673">Solution - Node Affinity (Optional)</a></li>
<li><a href="#org7a91bd0">Exercise: Taints and Tolerations vs Node Affinity: Insert Video</a></li>
<li><a href="#orgb074145">Resource Requirements and Limits : Insert Images</a>
<ul>
<li><a href="#org8821cce">Resource Requests</a></li>
<li><a href="#org7524387">Set Resource Limits to pod</a></li>
<li><a href="#orge3d5552">Exceed Limits</a></li>
</ul>
</li>
<li><a href="#orgcf9de31">Note on default resource requirements and limits</a></li>
<li><a href="#org7c3633d">A quick note on editing PODs and Deployments</a>
<ul>
<li><a href="#org0bd32f7">A quick note on editing PODs and Deployments</a></li>
</ul>
</li>
<li><a href="#org6835afd">Practice Test - Resource Requirements and Limits</a></li>
<li><a href="#org926faa6">Solution: Resource Limits : (Optional)</a></li>
<li><a href="#org9e9d775">DaemonSets</a>
<ul>
<li><a href="#org95dba45">Demonset Definition</a></li>
<li><a href="#org0b60e7f">How does it work ?</a></li>
</ul>
</li>
<li><a href="#orge70c4c7">Practice Test - DaemonSets</a></li>
<li><a href="#org84ba788">Solution - DaemonSets (optional)</a></li>
<li><a href="#org43194a9">Static Pods</a></li>
<li><a href="#orgd410249">Practice Test - Static Pods</a></li>
<li><a href="#org7f6d9d5">Solution - Static Pods (Optional)</a></li>
<li><a href="#org87c4364">Multiple Schedulers</a>
<ul>
<li><a href="#org91ad84e">Why you need Multiple Scheduler</a></li>
<li><a href="#org8959787">How to create Mulitple Scheduler</a></li>
<li><a href="#org0594a5e">Deploy custome kube-scheduler</a></li>
<li><a href="#org52e10d4">Config new pod to deploy using my-custome-scheduler</a></li>
<li><a href="#orge5552fc">How do know which scheduler will pick the pod</a></li>
<li><a href="#orgb069fac">View logs of a custom scheduler</a></li>
</ul>
</li>
<li><a href="#org05f0575">Practice Test - Multiple Schedulers</a></li>
<li><a href="#org9bf274c">Solution - Practice Test - Multiple Schedulers : (Optional)</a></li>
</ul>
</li>
<li><a href="#org847e441">Logging &amp; Monitoring  13 min</a>
<ul>
<li><a href="#org702f45c">Download Presentation Deck</a></li>
<li><a href="#orgd56a733">Monitor Cluster Components</a>
<ul>
<li><a href="#orgf3bdb31">Monitor</a></li>
<li><a href="#org45a11e7">Heapset vs Metrics Server</a></li>
<li><a href="#orga28e072">Metrics Server</a></li>
<li><a href="#orgece44b4">How are the metrics generated for the PODs on these nodes?</a></li>
<li><a href="#orgf5cbf7b">Metrics Server - Getting Started</a></li>
</ul>
</li>
<li><a href="#org2a5a472">Practice Test - Monitoring</a></li>
<li><a href="#org6fd1ac2">Solution: Monitor Cluster Components : (Optional)</a></li>
<li><a href="#org1dae6e0">Managing Application Logs</a>
<ul>
<li><a href="#org236189a">Logs - Docker</a></li>
<li><a href="#org5eba59b">Logs - Kubernetes <code>kubectl logs event-simulator-pod event-simulator</code></a></li>
<li><a href="#orgf2df235">Logs - Kubernetic Pod with Multi Containers</a></li>
</ul>
</li>
<li><a href="#orgaea8742">Practice Test - Monitor Application Logs</a></li>
<li><a href="#orge5027cc">Solution: Logging : (Optional)</a></li>
</ul>
</li>
<li><a href="#orgfb5700b">Application Lifecycle Management | 1h31min</a>
<ul>
<li><a href="#orgee55f28">Rolling Updates and Rollbacks</a>
<ul>
<li><a href="#org9b85abf">Rollouts and Versioning</a></li>
<li><a href="#org18301fb">Status of rollout Command</a></li>
<li><a href="#org541b919">Deployment Strategy (Recreate and Rolling Update)</a></li>
<li><a href="#orgb1a1d0f">Update your deployment</a></li>
<li><a href="#org2014372">Different btw Recreate and Rolling update &lt;insert img&gt;</a></li>
<li><a href="#orgb664a0f">How Deployment upgrades the cluster</a></li>
<li><a href="#org96ec7da">Roll back</a></li>
<li><a href="#orgb586221">Summarize</a></li>
</ul>
</li>
<li><a href="#orgaa4610e">Practice Test - Rolling Updates and Rollback</a></li>
<li><a href="#org2ccb2ca">Solution: Rolling update : (Optional)</a></li>
<li><a href="#org91767ce">Configure Applications</a></li>
<li><a href="#org895607e">Commands &lt;SKIP because docker cmd and entry point&gt;</a></li>
<li><a href="#org3ff34bc">Practice Test - Commands and Arguments</a></li>
<li><a href="#org08fa062">Solution - Commands and Arguments (Optional)</a></li>
<li><a href="#org081f557">Commands and Arguments &lt;Simillar to Entrypoint and cmd in Docker&gt;</a></li>
<li><a href="#org2e6eb51">Passing(env) to pod</a></li>
<li><a href="#org75c487a">[Plain Key Value pair]</a></li>
<li><a href="#orgbb461ea">[ConfigMa]p and attaching in pod-defin</a>
<ul>
<li><a href="#orga517eee">View ConfigMaps</a></li>
<li><a href="#org035e303">Attach ConfigMap with Pods defination.yaml</a></li>
</ul>
</li>
<li><a href="#orgc0c8415">[ConfigMap] Practice Test: Environment Variables</a></li>
<li><a href="#orge8d6fcc">[ConfigMap] Solution - Environment Variables (Optional)</a></li>
<li><a href="#org1fa375a">[Secrets] and attaching in pod or Applications</a>
<ul>
<li><a href="#org42972e6">Create Secret</a></li>
<li><a href="#org7e04de0">View Secret</a></li>
<li><a href="#orgfb879d8">Config (attach) secret with pod-definition</a></li>
</ul>
</li>
<li><a href="#org0d0338f">Conclusion of Passing ENV to  application</a></li>
<li><a href="#org3630847">A note about Secrets!</a></li>
<li><a href="#org9e7ed44">Practice Test - Secrets</a></li>
<li><a href="#org0c8c97f">Solution - Secrets (Optional)</a></li>
<li><a href="#orgd7db42e">Scale Applications</a></li>
<li><a href="#orgf312d2c">Multi Container PODs (Microservices)</a></li>
<li><a href="#org0460be8">Practice Test - Multi Container PODs</a></li>
<li><a href="#org4eb7b59">Solution - Multi-Container Pods (Optional)</a></li>
<li><a href="#org452da59">Multi-container PODs Design Patterns</a></li>
<li><a href="#orge5ed758">InitContainers</a></li>
<li><a href="#orge2f04ea">Practice Test - Init Containers</a></li>
<li><a href="#org94898d4">Solution - Init Containers (Optional)</a></li>
<li><a href="#org021b395">Self Healing Applications</a></li>
<li><a href="#orgd21de8f">If you like it, Share it!</a></li>
</ul>
</li>
<li><a href="#org04b0fd1">Storage 55min</a>
<ul>
<li><a href="#org998a649">Docker Storage</a>
<ul>
<li><a href="#orgfc2c086">Storage in Docker</a></li>
<li><a href="#org83f9cc3">Volume Driver Plugins in Docker</a></li>
<li><a href="#orgdb0295c">Container Storage Interface (CSI)</a></li>
</ul>
</li>
<li><a href="#org627896d">Volumes in Kubernetics</a>
<ul>
<li><a href="#orge92c16e">Volumes</a></li>
<li><a href="#org5d9f040">Persistent Volumes</a></li>
<li><a href="#org116ab00">Persistent Volume Claims (PVC)</a></li>
<li><a href="#orgdd72baa">Using PVCs in PODs</a></li>
<li><a href="#org965b782">Practice Test - Persistent Volumes and Persistent Volume Claims</a></li>
<li><a href="#org567da6a">Solution - Persistent Volumes and Persistent Volume Claims</a></li>
</ul>
</li>
<li><a href="#org547df55">Application Configuration</a></li>
<li><a href="#org1612dc2">Additional Topics</a></li>
<li><a href="#orge5cc8bd">Storage Class</a></li>
</ul>
</li>
<li><a href="#org57ea756">Networking 3h 7min</a>
<ul>
<li><a href="#orgffa6f2a">Prerequisite Networking</a>
<ul>
<li><a href="#org27522a3">Switching Routing</a></li>
<li><a href="#org2aa59cd">DNS</a></li>
<li><a href="#org4bd9417">CoreDNS</a></li>
<li><a href="#org5fc590d">Network Namespaces</a></li>
</ul>
</li>
<li><a href="#orge0beac0">FAQ</a></li>
<li><a href="#org10598ea">SKIP Prerequisite - Docker Networking</a></li>
<li><a href="#org2950f39">SKIP Prerequisite - CNI</a></li>
<li><a href="#org80f32af">Cluster Networkingin</a></li>
<li><a href="#orgb828b4d">Important Note about CNI and CKA Exam</a></li>
<li><a href="#org09ae042">Practice Test - Explore Kubernetes Environment</a></li>
<li><a href="#orgcfa4298">Solution - Explore Environment (optional)</a></li>
<li><a href="#orge5f4194">Pod Networking</a></li>
<li><a href="#org25abac7">CNI in kubernetes</a></li>
<li><a href="#org0fb0aa7">CNI weave</a></li>
<li><a href="#org782398d">Practice Test - Explore CNI Weave</a></li>
<li><a href="#orgab1ba80">Solution - Explore CNI Weave (optional)</a></li>
<li><a href="#org5c52a63">Practice Test - Deploy Network Solution</a></li>
<li><a href="#org4c448b5">Solution - Deploy Network Solution (optional)</a></li>
<li><a href="#org99958a4">IP Address Management - Weave</a></li>
<li><a href="#org923d0fe">Practice Test - Networking Weave</a></li>
<li><a href="#orgd90f791">Solution - Networking Weave (optional)</a></li>
<li><a href="#org24b1621">Service Networking</a></li>
<li><a href="#org05af443">Practice Test - Service Networking</a></li>
<li><a href="#org2d0c9d4">Solution - Service Networking (optional)</a></li>
<li><a href="#org2e3d06d">DNS in kubernetes</a></li>
<li><a href="#orgdbce78a">CoreDNS in Kubernetes</a></li>
<li><a href="#org818f76e">Practice Test - Explore DNS</a></li>
<li><a href="#org8c4e5f0">Solution - Explore DNS (optional)</a></li>
<li><a href="#org6ba6e31">Ingress</a></li>
<li><a href="#orgd5307dc">Article: Ingress</a></li>
<li><a href="#orga994360">Practice Test - Ingress - 1</a></li>
<li><a href="#orga1f1ff3">Solution - Ingress Networking 1 - (optional)</a></li>
<li><a href="#orge3af46a">Ingress - Annotations and rewrite-target</a></li>
<li><a href="#org3a5a320">Practice Test - Ingress - 2</a></li>
<li><a href="#org75f06a2">Solution - Ingress Networking - 2 (optional)</a></li>
</ul>
</li>
<li><a href="#orgc7c6727">Security 2h 21 min</a>
<ul>
<li><a href="#orga398b96">Kubernetes Security Primitives</a></li>
<li><a href="#orga687c36">Authentication</a></li>
<li><a href="#org0bb94bd">Article on Setting up Basic Authentication</a></li>
<li><a href="#org35effd8">TLS Introduction</a></li>
<li><a href="#orgd8b4588">TLS Basics</a></li>
<li><a href="#org28f5ced">TLS in Kubernetes</a></li>
<li><a href="#org083b91f">TLS in Kubernetes - Certificate Creation</a></li>
<li><a href="#org487eef4">View Certificate Details</a></li>
<li><a href="#org3f4932e">Resource: Download Kubernetes Certificate Health Check Spreadsheet</a></li>
<li><a href="#org2b0cf12">Practice Test - View Certificates</a></li>
<li><a href="#org6603581">Certificates API</a></li>
<li><a href="#orgcf34c14">Practice Test - Certificates API</a></li>
<li><a href="#orgd40c1e8">KubeConfig</a></li>
<li><a href="#org203dace">Practice Test - KubeConfig</a></li>
<li><a href="#org9f3041f">Persistent Key/Value Store</a></li>
<li><a href="#orge2820ea">API Groups</a></li>
<li><a href="#org928686e">Authorization</a></li>
<li><a href="#org242e2dc">Role Based Access Controls</a></li>
<li><a href="#orgb45b49a">Practice Test - RBAC</a></li>
<li><a href="#org04c5c7a">Cluster Roles and Role Bindings</a></li>
<li><a href="#org861d71d">Practice Test - Cluster Roles and Role Bindings</a></li>
<li><a href="#org9899a5b">Service Accounts</a></li>
<li><a href="#org78ea4bd">Practice Test Service Accounts</a></li>
<li><a href="#org7698b2e">Image Security</a></li>
<li><a href="#orgc654f14">Practice Test - Image Security</a></li>
<li><a href="#orga240ec2">Security Contexts</a></li>
<li><a href="#orgdb160fa">Practice Test - Security Contexts</a></li>
<li><a href="#orge3fec2f">Network Policy</a></li>
<li><a href="#org0ba53c9">Developing network policies</a></li>
<li><a href="#org309f9c9">Practice Test - Network Policy</a></li>
<li><a href="#orgf447efb">Solution - Network Policies (optional)</a></li>
</ul>
</li>
<li><a href="#orgbeeccd4">Design and Install a Kubernetes Cluster</a>
<ul>
<li><a href="#org500e43f">Design a Kubernetes Cluster</a></li>
<li><a href="#orgd861752">Choosing Kubernetes Infrastructure</a></li>
<li><a href="#orgff481fa">Configure High Availability</a></li>
<li><a href="#orge0032b3">ETCD in HA</a></li>
<li><a href="#orgfb9fa87">Important Update: Kubernetes the Hard Way</a></li>
</ul>
</li>
<li><a href="#org59fb8b5">Cluster Maintenace | 1h 11 min</a>
<ul>
<li><a href="#orgc9ee594">OS Upgrades</a></li>
<li><a href="#org353e28b">Practice Test - OS Upgrades</a></li>
<li><a href="#org5fc058e">Solution - OS Upgrades (optional)</a></li>
<li><a href="#org2341d39">Kubernetes Software Versions</a></li>
<li><a href="#org5c9e732">References</a></li>
<li><a href="#org8df0251">Cluster Upgrade Process</a></li>
<li><a href="#orgc301fb7">Demo - Cluster upgrade</a></li>
<li><a href="#orgd7d8bfb">Practice Test - Cluster Upgrade</a></li>
<li><a href="#org0ebde59">Solution: Cluster Upgrade</a></li>
<li><a href="#org591e5be">Backup and Restore Methods</a></li>
<li><a href="#org2db90ce">Working with ETCDCTL</a></li>
<li><a href="#orgefbf6c8">Practice Test - Backup and Restore Methods</a></li>
<li><a href="#orgc506378">Solution - Backup and Restore</a></li>
<li><a href="#orgca73c5a">Certification Exam Tip!</a></li>
<li><a href="#org5204120">References</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgad91bf5" class="outline-2">
<h2 id="orgad91bf5">Pre-Requisites:</h2>
<div class="outline-text-2" id="text-orgad91bf5">
<p>
docker                 : brefish  
yaml                   : ansible videos
basics of kuberentes   : 
setting up a basic lab envirnoment with virtualbox or lxd
</p>
</div>
</div>

<div id="outline-container-orgf730b99" class="outline-2">
<h2 id="orgf730b99">Course ToC</h2>
<div class="outline-text-2" id="text-orgf730b99">
<ul class="org-ul">
<li>Core Concepts:
<ul class="org-ul">
<li>Cluster Architecture :</li>
<li>Service &amp; Other Networking Primitives:</li>
<li>API Primitives</li>
</ul></li>
<li>Scheduling
<ul class="org-ul">
<li>labes and selectors</li>
<li>Daemon Sets</li>
<li>Resource Limits</li>
<li>Mulitple Schedulers</li>
<li>Manual Scheduling</li>
<li>Scheduler Events</li>
<li>Configure Kubernetes Scheduler</li>
</ul></li>
<li>Logging Monitoring
<ul class="org-ul">
<li>Monitor Cluster Components</li>
<li>Monitor Cluster Components Logs</li>
<li>Monitori Applications</li>
<li>Application Logs</li>
</ul></li>
<li>Application Lifecycle Management
<ul class="org-ul">
<li>Rolling Updates and Rollbacks in Deploy</li>
<li>Configure Applications</li>
</ul></li>
<li>Cluster Maintenance
<ul class="org-ul">
<li>CLuster Upgrade Process</li>
<li>Operating System Upgrades</li>
<li>Backup and Restore Methodologies</li>
</ul></li>
<li>Security
<ul class="org-ul">
<li>Authentication and Authorizion</li>
<li>Kubernetes Security</li>
<li>Network Polices</li>
<li>TLS Certificates for Cluster Components</li>
<li>Iamges Security</li>
<li>Security Contexts</li>
<li>Security Peristence Value Store</li>
</ul></li>
<li>Storage
<ul class="org-ul">
<li>Persistence Volumes</li>
<li>Persistence Volume Clamis</li>
<li>Access Modes for Volumes</li>
</ul></li>
<li>Networking
<ul class="org-ul">
<li>Pre-Requistes-Network, Switching, Routing Tools</li>
<li>Pre-Requistes-Network Namespaces</li>
<li>Pre-Requisites- DNS and CoreDNS</li>
<li>Pre-Requistes-Networking in Docker</li>
<li>Networking Configuration on Cluster Nodes</li>
<li>Service Networking</li>
<li>POD Networking Concepts</li>
<li>Network Loadbalancer</li>
<li>Ingress</li>
<li>Cluster DNS</li>
<li>CNI</li>
</ul></li>
<li>Installation , Configuration and Validation
<ul class="org-ul">
<li>Design a Kubernetes Cluster</li>
<li>Install Kubernetics Master and Nodes</li>
<li>Secure Cluster Communication</li>
<li>Provision Infrastructure</li>
<li>Run and Analyse end-to-end test</li>
<li>Install Kubernetes Master and Nodes</li>
<li>HA Kubernetes Cluster</li>
<li>Choose a Network Solution</li>
<li>Node end-to-end tests</li>
<li>&#x2026;.</li>
<li>&#x2026;.</li>
</ul></li>
<li>Troubleshooting 
<ul class="org-ul">
<li>Application Failure</li>
<li>Control Plane Failure</li>
<li>Worker Node Failure</li>
<li>Networking</li>
</ul></li>

<li>Practice Test</li>
</ul>
</div>
</div>
<div id="outline-container-orgd4d14cb" class="outline-2">
<h2 id="orgd4d14cb">Kubernetes trilogy</h2>
<div class="outline-text-2" id="text-orgd4d14cb">
</div>
<div id="outline-container-org88408f4" class="outline-3">
<h3 id="org88408f4">Kubernetes for Administration</h3>
<div class="outline-text-3" id="text-org88408f4">
<ul class="org-ul">
<li>High Availability</li>
<li>Scheduler</li>
<li>Logging and Monitoring</li>
<li>Maintaince</li>
<li>Security</li>
<li>Troubleshooting</li>
<li>For cert cka :</li>
</ul>
</div>
</div>
<div id="outline-container-orgde45dc7" class="outline-3">
<h3 id="orgde45dc7">Kubernetes for Developers</h3>
<div class="outline-text-3" id="text-orgde45dc7">
<p>
This cource is for design, build cloud native applications
No coding 
</p>
<ul class="org-ul">
<li>Core Concepts</li>
<li>Config Maps , security</li>
<li>Multi-contianer Pod</li>
<li>Rediness &amp;</li>
<li>Logging &amp; Monitoring</li>
<li>Pod Design</li>
<li>Jobs</li>
<li>Services</li>
<li>Demo</li>
<li>Code Excerices</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgdd09559" class="outline-2">
<h2 id="orgdd09559">Kubernetes Master-Worker(Node) Architecture :</h2>
<div class="outline-text-2" id="text-orgdd09559">
</div>
<div id="outline-container-org4dd6c6a" class="outline-3">
<h3 id="org4dd6c6a">Introduction</h3>
<div class="outline-text-3" id="text-org4dd6c6a">
<ul class="org-ul">
<li>Node-Types : Master &amp; Worker :
<ul class="org-ul">
<li>Master      : (Schedule, Monitor,Contorller)</li>
<li>Worker-Node : Host Applilcation as Pod or Container</li>
</ul></li>
</ul>

<p>
Inside master we have
</p>
<ul class="org-ul">
<li><b>etcd</b> :
<ul class="org-ul">
<li>database store as key-value formate(json)</li>
</ul></li>
<li><b>Controll-Manager</b>
<ul class="org-ul">
<li><b>Node-Controller</b>:
<ul class="org-ul">
<li>Reposible update new/delete node , stauts update if node are un-available</li>
</ul></li>
<li><b>Replication-Contorller</b>:
<ul class="org-ul">
<li>Ensure that desire no of contianer are running at all time</li>
</ul></li>
<li>&#x2026;etc</li>
</ul></li>
<li><b>Scheduler</b>:
<ul class="org-ul">
<li>identifies which pods(container)  should be deployed to which worker-node</li>
</ul></li>
<li><b>kube-apiserver</b>:
<ul class="org-ul">
<li>all above componets (communicate with each other kube-api-server)</li>
<li>also communicate with  user</li>
</ul></li>
<li><b>Container-run-time Engine</b> :
<ul class="org-ul">
<li>to run the container there are differenet Engines:
<ul class="org-ul">
<li>docker (going to be depricated )</li>
<li>containerd</li>
<li>rocket</li>
</ul></li>
</ul></li>
</ul>

<p>
In worker node consist of
</p>
<ul class="org-ul">
<li><b>Kubelet</b>:
<ul class="org-ul">
<li>agent run on each node  which deploy or destroy as require</li>
<li>lisenes  instruction form kube-apiserver for deploying or destroy contianer on node as required</li>
<li>kube-apiserver fetches node's status report/monitoring/logs form kubelet to monitor status of nodes and container</li>
</ul></li>
<li><b>kube-proxy</b>: 
<ul class="org-ul">
<li>communication between two containers</li>
<li>Example: when web-container need to communicate to database-conatainer then kube-proxy used for communition</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9978309" class="outline-3">
<h3 id="org9978309">Etcd</h3>
<div class="outline-text-3" id="text-org9978309">
</div>
<div id="outline-container-org32d156d" class="outline-4">
<h4 id="org32d156d">Introduction</h4>
<div class="outline-text-4" id="text-org32d156d">
<ul class="org-ul">
<li>What is etcd ?
<ul class="org-ul">
<li>Etcd is a distributed reliable key-value store that is Simple,Secure and Fast</li>
</ul></li>
<li>What is a Key-Value Store ?
<ul class="org-ul">
<li>Json format data</li>
</ul></li>
<li><p>
Install etcd using binarys
</p>
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Download binary </span>
curl -L https://github.com/etcd-io/etcd/releases/download/v3.3.11/etcd-
v3.3.11-linux-amd64.tar.gz -o etcd-v3.3.11-linux-amd64.tar.gz
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">extract the tar file </span>
tar xzvf etcd-v3.3.11-linux-amd64.tar.gz
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">run the ETCD Server </span>
./etcd
</pre>
</div></li>
<li><p>
How to operate ETCD ?
</p>
<div class="org-src-container">
<pre class="src src-sh">./etcdctl set key1 value1
./etcdctl get key1
./etcdctl
</pre>
</div></li>
</ul>
<p>
Later Disuss in Role of  etcd kuberentes   
</p>
<ul class="org-ul">
<li>What is a distributed system ?</li>
<li>How ECTD Operates</li>
<li>RAFT Protocal</li>
<li>Best practies on number of nodes ?</li>
</ul>
</div>
</div>

<div id="outline-container-orgacaaff2" class="outline-4">
<h4 id="orgacaaff2">etcd cmd</h4>
<div class="outline-text-4" id="text-orgacaaff2">
<p>
ETCD - Commands (Optional)
(Optional) Additional information about ETCDCTL Utility
ETCDCTL is the CLI tool used to interact with ETCD.
ETCDCTL can interact with ETCD Server using 2 API versions - Version 2 and Version 3.  By default its set to use Version 2. Each version has different sets of commands.
</p>

<p>
For example ETCDCTL version 2 supports the following commands:
</p>
<div class="org-src-container">
<pre class="src src-sh">etcdctl backup
etcdctl cluster-health
etcdctl mk
etcdctl mkdir
etcdctl set
</pre>
</div>

<p>
Whereas the commands are different in version 3
</p>
<div class="org-src-container">
<pre class="src src-sh">etcdctl snapshot save 
etcdctl endpoint health
etcdctl get
etcdctl put
</pre>
</div>

<p>
To set the right version of API set the environment variable ETCDCTL<sub>API</sub> command
<code>export ETCDCTL_API=3</code>
</p>

<p>
When API version is not set, it is assumed to be set to version 2. And version 3 commands listed above don't work. When API version is set to version 3, version 2 commands listed above don't work.
</p>


<p>
Apart from that, you must also specify path to certificate files so that ETCDCTL can authenticate to the ETCD API Server. The certificate files are available in the etcd-master at the following path. We discuss more about certificates in the security section of this course. So don't worry if this looks complex:
</p>

<div class="org-src-container">
<pre class="src src-sh">--cacert /etc/kubernetes/pki/etcd/ca.crt     
--cert /etc/kubernetes/pki/etcd/server.crt     
--key /etc/kubernetes/pki/etcd/server.key
</pre>
</div>


<p>
So for the commands I showed in the previous video to work you must specify the ETCDCTL API version and path to certificate files. Below is the final form:
</p>

<div class="org-src-container">
<pre class="src src-sh">kubectl exec etcd-master -n kube-system <span style="color: #2d9574;">\</span>
           -- sh -c <span style="color: #2d9574;">"ETCDCTL_API=3 etcdctl get / \</span>
<span style="color: #2d9574;">           --prefix --keys-only --limit=10 \</span>
<span style="color: #2d9574;">           --cacert /etc/kubernetes/pki/etcd/ca.crt </span>
<span style="color: #2d9574;">           --cert /etc/kubernetes/pki/etcd/server.crt  </span>
<span style="color: #2d9574;">           --key /etc/kubernetes/pki/etcd/server.key"</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgf97a3a7" class="outline-4">
<h4 id="orgf97a3a7">Roles of  ETCD in Kubernetes</h4>
<div class="outline-text-4" id="text-orgf97a3a7">
<ul class="org-ul">
<li>Intro 
<ul class="org-ul">
<li>Etcd stores information of Nodes, Pods, Configs, Secrets, Accounts, Roles, Bindings, Others</li>
<li>When you run <code>kubectl get ..</code> the result is from the etcd-server</li>
<li>Every change are update in etcd,</li>
<li>Only when changes are saved in etcd server then only the changes are complete</li>
</ul></li>
<li><p>
Manual Install Setup
</p>
<div class="org-src-container">
<pre class="src src-sh">wget -q --https-only <span style="color: #2d9574;">\</span>
         <span style="color: #2d9574;">"https://github.com/coreos/etcd/releases/download/v3.3.9/etcd-v3.3.9-linux-amd64.tar.gz"</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">etcd.service</span>
<span style="color: #715ab1;">ExecStart</span>=/usr/local/bin/etcd <span style="color: #2d9574;">\\</span>
--name ${<span style="color: #715ab1;">ETCD_NAME</span>} <span style="color: #2d9574;">\\</span>
--cert-file=/etc/etcd/kubernetes.pem <span style="color: #2d9574;">\\</span>
--key-file=/etc/etcd/kubernetes-key.pem <span style="color: #2d9574;">\\</span>
--peer-cert-file=/etc/etcd/kubernetes.pem <span style="color: #2d9574;">\\</span>
--peer-key-file=/etc/etcd/kubernetes-key.pem <span style="color: #2d9574;">\\</span>
--trusted-ca-file=/etc/etcd/ca.pem <span style="color: #2d9574;">\\</span>
--peer-trusted-ca-file=/etc/etcd/ca.pem <span style="color: #2d9574;">\\</span>
--peer-client-cert-auth <span style="color: #2d9574;">\\</span>
--client-cert-auth <span style="color: #2d9574;">\\</span>
--initial-advertise-peer-urls https://${<span style="color: #715ab1;">INTERNAL_IP</span>}:2380 <span style="color: #2d9574;">\\</span>
--listen-peer-urls https://${<span style="color: #715ab1;">INTERNAL_IP</span>}:2380 <span style="color: #2d9574;">\\</span>
--listen-client-urls https://${<span style="color: #715ab1;">INTERNAL_IP</span>}:2379,https://127.0.0.1:2379 <span style="color: #2d9574;">\\</span>
--advertise-client-urls https://${<span style="color: #715ab1;">INTERNAL_IP</span>}:2379 <span style="color: #2d9574;">\\</span>
--initial-cluster-token etcd-cluster-0 <span style="color: #2d9574;">\\</span>
--initial-cluster controller-0=https://${<span style="color: #715ab1;">CONTROLLER0_IP</span>}:2380,controller-1=https://${<span style="color: #715ab1;">CONTROLLER1_IP</span>}:2380 <span style="color: #2d9574;">\\</span>
--initial-cluster-state new <span style="color: #2d9574;">\\</span>
--data-dir=/var/lib/etcd
</pre>
</div></li>
<li><p>
Setup- Kuberadm, Explore Etcd:
</p>
<ul class="org-ul">
<li>Kubenetes store the specific data  in key-value pair to view all keys sotred by etcd</li>
</ul>
<div class="org-src-container">
<pre class="src src-sh">kubectl get pods -n kube-system
kubectl exec etcd-master &#8211;n kube-system etcdctl get / --prefix &#8211;keys-only
</pre>
</div></li>
<li>Explore Etcd   
<ul class="org-ul">
<li>Kubernetes stores data in specific directory structure
<ul class="org-ul">
<li>root/registory
<ul class="org-ul">
<li>minions</li>
<li>pods</li>
<li>roles</li>
<li>secrets</li>
<li>replicaset</li>
<li>replica</li>
<li>authentication</li>
<li>autoscaling</li>
<li>storage</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>
ETCD in HA Enviorment:
</p>
<ul class="org-ul">
<li><p>
In high avilablity env we have multipule master enviroment so we have to make sure that they know about each other by etcd configuration
</p>
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">etcd.service</span>
<span style="color: #715ab1;">ExecStart</span>=/usr/local/bin/etcd <span style="color: #2d9574;">\\</span>
--name ${<span style="color: #715ab1;">ETCD_NAME</span>} <span style="color: #2d9574;">\\</span>
--cert-file=/etc/etcd/kubernetes.pem <span style="color: #2d9574;">\\</span>
--key-file=/etc/etcd/kubernetes-key.pem <span style="color: #2d9574;">\\</span>
--peer-cert-file=/etc/etcd/kubernetes.pem <span style="color: #2d9574;">\\</span>
--peer-key-file=/etc/etcd/kubernetes-key.pem <span style="color: #2d9574;">\\</span>
--trusted-ca-file=/etc/etcd/ca.pem <span style="color: #2d9574;">\\</span>
--peer-trusted-ca-file=/etc/etcd/ca.pem <span style="color: #2d9574;">\\</span>
--peer-client-cert-auth <span style="color: #2d9574;">\\</span>
--client-cert-auth <span style="color: #2d9574;">\\</span>
--initial-advertise-peer-urls https://${<span style="color: #715ab1;">INTERNAL_IP</span>}:2380 <span style="color: #2d9574;">\\</span>
--listen-peer-urls https://${<span style="color: #715ab1;">INTERNAL_IP</span>}:2380 <span style="color: #2d9574;">\\</span>
--listen-client-urls https://${<span style="color: #715ab1;">INTERNAL_IP</span>}:2379,https://127.0.0.1:2379 <span style="color: #2d9574;">\\</span>
--advertise-client-urls https://${<span style="color: #715ab1;">INTERNAL_IP</span>}:2379 <span style="color: #2d9574;">\\</span>
--initial-cluster-token etcd-cluster-0 <span style="color: #2d9574;">\\</span>
--initial-cluster controller-0=https://${<span style="color: #715ab1;">CONTROLLER0_IP</span>}:2380,controller-1=https://${<span style="color: #715ab1;">CONTROLLER1_IP</span>}:2380 <span style="color: #2d9574;">\\</span>
--initial-cluster-state new <span style="color: #2d9574;">\\</span>
--data-dir=/var/lib/etcd
</pre>
</div></li>
</ul>

<p>
<code>--initial-cluster controller-0=https://${CONTROLLER0_IP}:2380,controller-1=https://${CONTROLLER1_IP}:2380 \\</code> this cmd is used in etcd for master to communicate between masters in HA Env
</p></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org6eafe20" class="outline-3">
<h3 id="org6eafe20">Kube-api Server</h3>
<div class="outline-text-3" id="text-org6eafe20">
</div>
<div id="outline-container-orga06581e" class="outline-4">
<h4 id="orga06581e">Kube-API Server Into</h4>
<div class="outline-text-4" id="text-orga06581e">
<ul class="org-ul">
<li>Kub-apiserver is main componet in master-node which enable the communication between the components and other master and worker nodes</li>
<li>Eg: <code>kubectl get nodes</code>
<ul class="org-ul">
<li>Steps
<ol class="org-ol">
<li>authenticate User request <code>kubectl get nodes</code></li>
<li><code>validate request</code> then request <code>etcd cluseter</code></li>
<li><code>retrive data</code> for <code>etcd cluseter</code></li>
</ol></li>
</ul></li>
<li>Eg: <code>kubectl run nginx --image=nginx --port=80</code>
<ul class="org-ul">
<li>Steps
<ul class="org-ul">
<li>authenticate User request <code>kubectl run nginx --image=nginx --port=80</code></li>
<li>validate request in  <code>etcd cluseter</code></li>
<li><code>Update ETCD</code> <code>etcd cluster</code> update the database</li>
<li><code>etcd cluster</code> update kube-apiserver and api-server update user</li>
<li><code>scheduler</code> continously monitor the <code>api-server</code> when <code>schedule</code> see <code>new pod is create with no-node assing</code></li>
<li><code>scheduler</code> select a node to assign then <code>new pod</code> and communicate back to the <code>kube-api-server</code></li>
<li><code>kube-apiserver</code> will update the <code>etcd cluster</code></li>
<li>then <code>kube-apiserver</code> pass the instruction to the <code>kubelet</code> of that corresponding node</li>
<li><code>kubelet</code> construct pod</li>
<li><code>kubelet</code>  instructs corresponding <code>container runtime engin(docker)</code> to deploy corresponding image</li>
<li><code>kubelet</code> update status back to <code>kubeapi-server</code></li>
<li><code>kube-apiserver</code> update status to <code>etcd cluster</code></li>
</ul></li>
</ul></li>
</ul>

<p>
For above example we see kube-apiserver palys important role in communicating with  component and worker-node(kubelet)
</p>

<ul class="org-ul">
<li>Summarize: kube-api Server is used for
<ul class="org-ul">
<li>Authenticating User</li>
<li>Validate Request</li>
<li>Retrive data</li>
<li>Update ETCD</li>
<li>Scheduler</li>
<li>Kubelet</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgc7e282e" class="outline-4">
<h4 id="orgc7e282e">Install Kube-api Server</h4>
<div class="outline-text-4" id="text-orgc7e282e">
<div class="org-src-container">
<pre class="src src-sh">wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-apiserver

<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kube-apiserver.service</span>
<span style="color: #715ab1;">ExecStart</span>=/usr/local/bin/kube-apiserver <span style="color: #2d9574;">\\</span>
--advertise-address=${<span style="color: #715ab1;">INTERNAL_IP</span>} <span style="color: #2d9574;">\\</span>
--allow-privileged=true <span style="color: #2d9574;">\\</span>
--apiserver-count=3 <span style="color: #2d9574;">\\</span>
--authorization-mode=Node,RBAC <span style="color: #2d9574;">\\</span>
--bind-address=0.0.0.0 <span style="color: #2d9574;">\\</span>
--enable-admission-
<span style="color: #715ab1;">plugins</span>=Initializers,NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota <span style="color: #2d9574;">\\</span>
--enable-swagger-ui=true <span style="color: #2d9574;">\\</span>
--etcd-servers=https://127.0.0.1:2379 <span style="color: #2d9574;">\\</span>
--event-ttl=1h <span style="color: #2d9574;">\\</span>
--experimental-encryption-provider-config=/var/lib/kubernetes/encryption-config.yaml <span style="color: #2d9574;">\\</span>
--runtime-config=api/all <span style="color: #2d9574;">\\</span>
--service-account-key-file=/var/lib/kubernetes/service-account.pem <span style="color: #2d9574;">\\</span>
--service-cluster-ip-range=10.32.0.0/24 <span style="color: #2d9574;">\\</span>
--service-node-port-range=30000-32767 <span style="color: #2d9574;">\\</span>
--v=2
</pre>
</div>

<p>
here <code>--etcd-servers=https://127.0.0.1:2379 \\</code>
</p>
</div>
</div>

<div id="outline-container-org0cd65e5" class="outline-4">
<h4 id="org0cd65e5">View api-server - kubeadm</h4>
<div class="outline-text-4" id="text-org0cd65e5">
<div class="org-src-container">
<pre class="src src-sh">kubectl get pods -n kube-system | grep kube-apiserver 
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">calico-kube-controllers-75f8f6cc59-p5t6p   1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">calico-node-j4lpc                          1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">calico-node-kl687                          1/1     Running   0          26h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">calico-node-xmlv8                          1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">coredns-78fcd69978-29rnj                   1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">coredns-78fcd69978-sq2c8                   1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">etcd-ip-172-31-33-27                       1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kube-apiserver-ip-172-31-33-27             1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kube-controller-manager-ip-172-31-33-27    1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kube-proxy-jtv6m                           1/1     Running   0          26h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kube-proxy-r9rgb                           1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kube-proxy-v9nt9                           1/1     Running   0          2d3h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kube-scheduler-ip-172-31-33-27             1/1     Running   0          2d3h</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orga38ac33" class="outline-4">
<h4 id="orga38ac33">View api-server options - kubeadm</h4>
<div class="outline-text-4" id="text-orga38ac33">
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">cat /etc/kubernetes/manifests/kube-apiserver.yaml</span>
spec:
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=172.31.33.27
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true
    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
    - --etcd-servers=https://127.0.0.1:2379
    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
    - --requestheader-allowed-names=front-proxy-client
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --requestheader-extra-headers-prefix=X-Remote-Extra-
    - --requestheader-group-headers=X-Remote-Group
    - --requestheader-username-headers=X-Remote-User
    - --secure-port=6443
    - --service-account-issuer=https://kubernetes.default.svc.cluster.local
    - --service-account-key-file=/etc/kubernetes/pki/sa.pub
    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
</pre>
</div>

<p>
we will discuss aabout etcd ca file, cert file, key file, servers later in comming up-section
</p>
</div>
</div>

<div id="outline-container-org4dc5c99" class="outline-4">
<h4 id="org4dc5c99">View api-server options</h4>
<div class="outline-text-4" id="text-org4dc5c99">
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">ps -aux | grep kube-apiserver</span>
root       15696  5.3  8.8 1244720 355248 ?      Ssl  Oct12 167:10 kube-apiserver --advertise-address=172.31.33.27 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-account-signing-key-file=/etc/kubernetes/pki/sa.key --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org9b2e51f" class="outline-3">
<h3 id="org9b2e51f">Contorll-Manager</h3>
<div class="outline-text-3" id="text-org9b2e51f">
</div>
<div id="outline-container-orgda26bf1" class="outline-4">
<h4 id="orgda26bf1">Controller-Manager Intro</h4>
<div class="outline-text-4" id="text-orgda26bf1">
<p>
Controller-Manager: Is a Process which continously monitor the state for different system or components and bring the system to the desire state or configuration
Controller-Manger consist of
</p>
<ul class="org-ul">
<li>Node Controller :
<ul class="org-ul">
<li>Monitoring the status of node and keep the application running</li>
<li>Eg: <code>kubectl get nodes</code>
<ul class="org-ul">
<li><code>Node Monitor Period=5s</code> <code>Node Contorller</code> check the status of node (kube-apiserver instruction kubelet of node ) for every 5s</li>
<li><code>Node Monitor Grace Period=40s</code> If node fails to send heart-bete to master then it status change to <code>Not Ready</code> and waits for 40s and change to Status <code>Unreacheable</code></li>
<li><code>POD Eviction Timeout=5m</code> After mark it as unreacheable it give 5mints to come back if failed to comeback then it remove the pod assign to that node and assigne then to healthy nodes</li>
</ul></li>
</ul></li>
<li>Repication-Contorller :
<ul class="org-ul">
<li>It monitor the status of replica sets and ensure the desire replica(pods) are running/avaiable on corresponding nodes</li>
<li>If pod die then it will create other one</li>
</ul></li>
<li>Repilcaset :</li>
<li>Depolyment-Controller</li>
<li>Namespace-Controller</li>
<li>Endpoint-Controller</li>
<li>CronJob</li>
<li>Job-Crontorller</li>
<li>PV-Protection-Contorller</li>
<li>Service Account-Contorller</li>
<li>Stateful-Set</li>
<li>PV-Buinder-Contorller</li>
<li>Replication-Contorller</li>
</ul>
</div>
</div>

<div id="outline-container-orgc2def7b" class="outline-4">
<h4 id="orgc2def7b">Install kube-contorller-manager</h4>
<div class="outline-text-4" id="text-orgc2def7b">
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-controller-manager</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubectl get pods -n kube-system | grep kube-contorller-manager</span>
calico-kube-controllers-75f8f6cc59-p5t6p   1/1     Running   0          2d3h
calico-node-j4lpc                          1/1     Running   0          2d3h
calico-node-kl687                          1/1     Running   0          26h
calico-node-xmlv8                          1/1     Running   0          2d3h
coredns-78fcd69978-29rnj                   1/1     Running   0          2d3h
coredns-78fcd69978-sq2c8                   1/1     Running   0          2d3h
etcd-ip-172-31-33-27                       1/1     Running   0          2d3h
kube-apiserver-ip-172-31-33-27             1/1     Running   0          2d3h
kube-controller-manager-ip-172-31-33-27    1/1     Running   0          2d3h
kube-proxy-jtv6m                           1/1     Running   0          26h
kube-proxy-r9rgb                           1/1     Running   0          2d3h
kube-proxy-v9nt9                           1/1     Running   0          2d3h
kube-scheduler-ip-172-31-33-27             1/1     Running   0          2d3h

<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">cat /etc/kubernetes/manifests/kube-controller-manager.yaml</span>
spec:
  containers:
  - command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --bind-address=127.0.0.1
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --cluster-cidr=10.244.0.0/16
    - --cluster-name=kubernetes
    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
    - --controllers=*,bootstrapsigner,tokencleaner
    - --kubeconfig=/etc/kubernetes/controller-manager.conf
    - --leader-elect=true
    - --port=0
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --root-ca-file=/etc/kubernetes/pki/ca.crt
    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --use-service-account-credentials=true

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;"># View contorller-manager options</span>
ps -aux | grep kube-contorller-manager
</pre>
</div>

<p>
Note:
the setting like node-monitor-period=5s, node-monitor-grace-period=40s, pod-eviction-timeout-5m0s will go on above yaml file or arg in cmd
</p>

<div class="org-src-container">
<pre class="src src-sh">--node-monitor-period=5s
--node-monitor-grace-period=40s
--pod-eviction-timeout-5m0s


</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org8dd465d" class="outline-3">
<h3 id="org8dd465d">Scheduler</h3>
<div class="outline-text-3" id="text-org8dd465d">
</div>
<div id="outline-container-org1e704c9" class="outline-4">
<h4 id="org1e704c9">Intro</h4>
<div class="outline-text-4" id="text-org1e704c9">
<ul class="org-ul">
<li>scheduler will decide which pod is assign to to which node but scheduler will not create or move the pods to node that job of kubelet</li>
<li>The scheduler decides which pod go where</li>
<li>How Scheduler decides/assign pod  which node to choose ?
<ul class="org-ul">
<li>Scheduler look at each pod and try to find the best node for it.
<ul class="org-ul">
<li>Example :
<ul class="org-ul">
<li>Consider there are 3 pod which as spec cpu utilization
<ul class="org-ul">
<li>pod 1 : cpu 1</li>
<li>pod 2 : cpu 2</li>
<li>pod 3 : cpu 10</li>
</ul></li>
<li>Consider there are 4 node with respective cpus
<ul class="org-ul">
<li>Node 1 :  4 cpus</li>
<li>Node 2 :  4 cpus</li>
<li>Node 3 : 12 cpus</li>
<li>Node 4 : 16 cpus</li>
</ul></li>
<li>Select <code>pod 3</code> need to scheduled (need to assign them to best node)</li>
<li>Scheduler has two phases</li>
<li><b>Filter Node</b> : scheduler filter node by  NO.of.cpu(in Node) &gt;= <code>pod3 cpu requrie</code></li>
<li><b>Rank Node</b>   : scheduler rank the node by  priority=  <code>No.of.cpus.inNode - pod3.cpus_requirement</code>, high priority node the pod3 will be deployed</li>
</ul></li>
</ul></li>
</ul></li>
<li>This Scheduler assign can be customize and we can write own scheduler as well</li>

<li><p>
Sucheduler consist of
</p>
<ul class="org-ul">
<li>Resource Requirement &amp; Limits</li>
<li>Taints and Tolerations</li>
<li>Node Selectors/Affinity</li>
<li>labes and selectors</li>
<li>Daemon Sets</li>
<li>Mulitple Schedulers</li>
<li>Manual Scheduling</li>
<li>Scheduler Events</li>
<li>Configure Kubernetes Scheduler</li>
</ul>

<p>
Which will be covered in later topics
</p></li>
</ul>
</div>
</div>
<div id="outline-container-orgd966fa8" class="outline-4">
<h4 id="orgd966fa8">Installation,Configuration, view options</h4>
<div class="outline-text-4" id="text-orgd966fa8">
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;"># install kube-schedule</span>
wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler

<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kube-scheduler.service</span>
<span style="color: #715ab1;">ExecStart</span>=/usr/local/bin/kube-scheduler <span style="color: #2d9574;">\\</span>
--config=/etc/kubernetes/config/kube-scheduler.yaml <span style="color: #2d9574;">\\</span>
--v=2

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;"># View kube-scheduler options -kubeadm</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">cat /etc/kubernetes/manifests/kube-scheduler.yaml</span>
spec:
containers:
- command:
  - kube-scheduler
  - --address=127.0.0.1
  - --kubeconfig=/etc/kubernetes/scheduler.conf
  - --leader-elect=true

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;"># View kube-scheduler options</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">ps -aux | grep kube-schedule</span>
root  2477  0.8  1.6  48524  34044  ?  Ssl  17:31  0:08
kube-scheduler -- <span style="color: #715ab1;">address</span>=127.0.0.1 --kubeconfig=/etc/kubernetes/scheduler.conf --leader-elect=true
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org0934ac4" class="outline-3">
<h3 id="org0934ac4">Kubelet</h3>
<div class="outline-text-3" id="text-org0934ac4">
<p>
Kubelet used for
</p>
<ul class="org-ul">
<li>Register Node</li>
<li>Create Pods</li>
<li>Monitor Nodes and Pods</li>
</ul>

<p>
Install Kubelet
</p>
<div class="org-src-container">
<pre class="src src-sh">wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubelet.service</span>
<span style="color: #715ab1;">ExecStart</span>=/usr/local/bin/kubelet <span style="color: #2d9574;">\\</span>
--config=/var/lib/kubelet/kubelet-config.yaml <span style="color: #2d9574;">\\</span>
--container-runtime=remote <span style="color: #2d9574;">\\</span>
--container-runtime-endpoint=unix:///var/run/containerd/containerd.sock <span style="color: #2d9574;">\\</span>
--image-pull-progress-deadline=2m <span style="color: #2d9574;">\\</span>
--kubeconfig=/var/lib/kubelet/kubeconfig <span style="color: #2d9574;">\\</span>
--network-plugin=cni <span style="color: #2d9574;">\\</span>
--regis
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">NOTE: THIS WILL NOT INSTALL KUBLET IN WORKER-NODE</span>
ps -aux | grep kubelet
root  2095   1.8 2.4   960676   98788   ?  Ssl   02:32  0:36   /usr/bin/kubelet
--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf
--kubeconfig=/etc/kubernetes/kubelet.conf
--config=/var/lib/kubelet/config.yaml
--cgroup-driver=cgroupfs
--cni-bin-dir=/opt/cni/bin
--cni-conf-dir=/etc/cni/net.d
--network-plugin=cni
</pre>
</div>
</div>
</div>
<div id="outline-container-org8f29d5f" class="outline-3">
<h3 id="org8f29d5f">Kubeproxy:</h3>
<div class="outline-text-3" id="text-org8f29d5f">
<p>
Within a kube cluster every pod can connect with other pod this acommplished by deploying a pod networking solution to cluster
</p>

<p>
Pod Network : is a internal network that span across all pods in cluster
Through this network they are able to communicate with each other 
</p>

<p>
Kubeproxy :
</p>
<ul class="org-ul">
<li>is a process or agent that runs on every node managing the communication between the pods/containers</li>
<li>at each node kubeproxy will create the ip-table of other nodes ip address and try to communicate betweeen then</li>
</ul>

<pre class="example">
# # Installing kube-proxy
wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy
ExecStart=/usr/local/bin/kube-proxy \\
--config=/var/lib/kube-proxy/kube-proxy-config.yaml
Restart=on-failure
RestartSec=5

# # View kube-proxy - kubeadm


kubectl get pods -n kube-system | grep kube-proxy
#calico-kube-controllers-75f8f6cc59-p5t6p   1/1     Running   0          2d3h
#calico-node-j4lpc                          1/1     Running   0          2d3h
#calico-node-kl687                          1/1     Running   0          26h
#calico-node-xmlv8                          1/1     Running   0          2d3h
#coredns-78fcd69978-29rnj                   1/1     Running   0          2d3h
#coredns-78fcd69978-sq2c8                   1/1     Running   0          2d3h
#etcd-ip-172-31-33-27                       1/1     Running   0          2d3h
#kube-apiserver-ip-172-31-33-27             1/1     Running   0          2d3h
#kube-controller-manager-ip-172-31-33-27    1/1     Running   0          2d3h
#kube-proxy-jtv6m                           1/1     Running   0          26h
#kube-proxy-r9rgb                           1/1     Running   0          2d3h
#kube-proxy-v9nt9                           1/1     Running   0          2d3h
#kube-scheduler-ip-172-31-33-27             1/1     Running   0          2d3h

kubectl get daemonset -n kube-system
NAME          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
calico-node   3         3         3       3            3           kubernetes.io/os=linux   2d5h
kube-proxy    3         3         3       3            3           kubernetes.io/os=linux   2d5h
</pre>
</div>
</div>
</div>
<div id="outline-container-org0bed0a2" class="outline-2">
<h2 id="org0bed0a2">Kubernetes Cluster(pod) Architecture :</h2>
<div class="outline-text-2" id="text-org0bed0a2">
<p>
Assume we are running kubenetes with two worker nodes and one master node
</p>
</div>
<div id="outline-container-orgc97b6a7" class="outline-3">
<h3 id="orgc97b6a7">Pods</h3>
<div class="outline-text-3" id="text-orgc97b6a7">
</div>
<div id="outline-container-orgbb06e85" class="outline-4">
<h4 id="orgbb06e85">Into</h4>
<div class="outline-text-4" id="text-orgbb06e85">
<p>
pod is wrapper, which wrapper docker container
</p>

<p>
Note: in a pod there can be any-number of contianter but for good practice we only use pod with one contianer in rare case you may see pod with two container (main container + helper container )
</p>

<pre class="example">
kubectl run my-nginx --image=nginx --port=80  # we didn't config exteranl ip access
kubectl get pods
kubectl describe pod my-nignx  
kubectl describe pod coredns -n kube-system
kubectl delete pods my-nginx

# Force delete 
kubectl delete pod &lt;PODNAME&gt; --grace-period=0 --force --namespace &lt;NAMESPACE&gt;


</pre>


<pre class="example">
# ###########################
kubectl describe pod my-nginx
# #######################

Name:         nginx
Namespace:    default
Priority:     0
Node:         ip-172-31-46-193/172.31.46.193
Start Time:   Thu, 14 Oct 2021 10:03:48 +0000
Labels:       run=nginx
Annotations:  cni.projectcalico.org/containerID: 5085cfbe3c2f71267d83e0bc2a1d4bb4df54d8dcab3a9c857be376e50d585c8e
	      cni.projectcalico.org/podIP: 10.244.85.80/32
	      cni.projectcalico.org/podIPs: 10.244.85.80/32
Status:       Running
IP:           10.244.85.80
IPs:
  IP:  10.244.85.80
Containers:
  nginx:
    Container ID:   docker://91d170df74e0a11e46ba059dead713678d56cd7aa7277ba677c9ffc8903294db
    Image:          nginx
    Image ID:       docker-pullable://nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Thu, 14 Oct 2021 10:03:52 +0000
    Ready:          True
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-l498k (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-l498k:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       &lt;nil&gt;
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              &lt;none&gt;
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
			     node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      &lt;none&gt;
</pre>
</div>
</div>
<div id="outline-container-org263e135" class="outline-4">
<h4 id="org263e135">Pod with Yaml</h4>
<div class="outline-text-4" id="text-org263e135">
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: apps/v1
<span style="color: #715ab1;">kind</span>: Deployment
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: nginx-deployment
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">selector</span>:
    <span style="color: #715ab1;">matchLabels</span>:
      <span style="color: #715ab1;">app</span>: nginx
  <span style="color: #715ab1;">replicas</span>: 2 <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">tells deployment to run 2 pods matching the template</span>
  <span style="color: #715ab1;">template</span>:
    <span style="color: #715ab1;">metadata</span>:
      <span style="color: #715ab1;">labels</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">app</span>: nginx
    <span style="color: #715ab1;">spec</span>:
      <span style="color: #715ab1;">containers</span>:
      - <span style="color: #715ab1;">name</span>: nginx
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">image</span>: nginx:1.14.2
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">ports</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">- containerPort</span>: 80   <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">target portxs</span>

kubectl create -f file.yaml
kubectl apply -f file.yaml
</pre>
</div>
</div>
</div>
<div id="outline-container-org02440dd" class="outline-4">
<h4 id="org02440dd">Access Lab</h4>
<div class="outline-text-4" id="text-org02440dd">
<pre class="example">
Link: https://uklabs.kodekloud.com/courses/labs-certified-kubernetes-administrator-with-practice-tests/
Apply the coupon code udemystudent151113
</pre>
</div>
</div>
<div id="outline-container-org08df9e4" class="outline-4">
<h4 id="org08df9e4">Practice test :</h4>
<div class="outline-text-4" id="text-org08df9e4">
<ul class="org-ul">
<li>How may pods are prscent on default namespace ?
<ul class="org-ul">
<li><code>kubectl get pod -n default | wc</code> or</li>
<li><code>echo $(($(kubectl get pods | wc -l)-1))</code></li>
</ul></li>
<li>How may replicaset exist on sysstem  ?
<ul class="org-ul">
<li><code>kubectl get replicasets.app</code></li>
<li><code>echo$(($(kubectl get replicasets.app| wc - l)-1))</code></li>
</ul></li>
<li>How may pods are  DESIRED in  replicaset name='new-replica-set' ?
<ul class="org-ul">
<li><code>kubectl get replicasets.app</code> or</li>
</ul></li>
<li>What is the image used to create pod in replicaset name ="new-replica-set" ?
<ul class="org-ul">
<li><code>kubectl describe replicasets.apps new-replica-set| grep -i image</code></li>
</ul></li>
<li>How may pods are READY in "new-replica-set"
<ul class="org-ul">
<li><code>kubectl describe replicasets.apps new-replica-set</code> or</li>
<li><code>kubectl get replicasets.app</code></li>
</ul></li>
<li>What are the pods names that are created by repliaset name='name-replica-set' ?
<ul class="org-ul">
<li><code>kubectl describe replicasets.apps new-replica-set</code>  see <b>Events Message</b> if pods are created then it show the name of pod OR</li>
<li><code>kubectl get pods</code> search for pod by pod name or describe pod and see replicaset</li>
</ul></li>
<li>Why do you think the Pods are not ready ?
<ul class="org-ul">
<li><code>kubectl describe replicasets.apps new-replica-set</code>  see <b>Events Message</b> show the reason for failure  OR</li>
<li><code>kubectl get pods</code> select the corresponding pod and describe the pod
<code>kubectl describe pod new-replica-set-7ld2d</code> see <b>Events Message</b> show the reason for failure</li>
</ul></li>
<li>Delete any one of 4 pods in 'new-replica-set' ?
<ul class="org-ul">
<li><code>=kubectl delete pod new-replica-set-7ld2d</code></li>
</ul></li>
<li>How may pods are running after deleting a pod form 'new-replica-set'?
<ul class="org-ul">
<li><code>kubectl get pod</code> there no change in no.of.Pod as new pod is created as soon as we delete the pod</li>
</ul></li>
<li>Why are there still 4 PODs, even after you deleted one ?
<ul class="org-ul">
<li>Replicaset ensure that desired number of POD always run</li>
</ul></li>
<li>Create a ReplicaSet using the 'replicaset-definition-1.yaml' located at <i>root</i> ?
<ul class="org-ul">
<li><code>kubectl apply -f replicaset replicaset-definition-1.yaml</code></li>
<li>change v1 to apps/v1  and <code>kubectl apply -f replicaset replicaset-definition-1.yaml</code></li>
</ul></li>
<li>Fix the issue in the replicaset-definition-2.yaml file and create a Replicaset ?
<ul class="org-ul">
<li><code>kubectl apply -f replicaset replicaset-definition-2.yaml</code></li>
<li>change template/metadata/label/tire: nginx to frontend  and <code>kubectl apply -f replicaset replicaset-definition-2.yaml</code></li>
</ul></li>
<li>Delete two newly create replicaset-1 and replicaset-2
<ul class="org-ul">
<li><code>kubectl delete replicasets.apps replicaset-1 replicaset-2</code></li>
</ul></li>
<li>Fix the  replica set name = 'new-replica-set'to use image= bussybox
<ul class="org-ul">
<li><code>kubectl edit replicasets.apps new-replica-set</code></li>
<li>change image from "bussybox777" to "bussybox"</li>
<li>delete all existing pods <code>kubectl delete pods  new-replica-set-f2nc new-replica-set-gqcsr new-replica-set-zl5lf new-replica-set-w2r9p</code></li>
</ul></li>

<li>Scale the ReplicaSet to 5 PODs
<ul class="org-ul">
<li><code>kubectl scale replicaset --replicaset=5 new-replica-set</code></li>
<li><code>kubectl get pods</code></li>
</ul></li>

<li>Scale down ReplicaSet to 2 PODs
<ul class="org-ul">
<li><code>kubectl scale replicaset --replicaset=2 new-replica-set</code></li>
<li><code>kubectl get pods</code></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgfb86901" class="outline-4">
<h4 id="orgfb86901">pod cmd</h4>
</div>
</div>
<div id="outline-container-org9c32334" class="outline-3">
<h3 id="org9c32334">Replication Contorller vs Replicaset</h3>
<div class="outline-text-3" id="text-org9c32334">
</div>
<div id="outline-container-org3266214" class="outline-4">
<h4 id="org3266214">Intro</h4>
<div class="outline-text-4" id="text-org3266214">
<ul class="org-ul">
<li>Repication-Contorller :
<ul class="org-ul">
<li>It monitor the status of replica sets and ensure the desire replica(pods) are running/avaiable on corresponding nodes</li>
<li>If pod die then it will create other one</li>
</ul></li>
</ul>


<p>
load balancing and scaling:
</p>

<p>
Replication Contorller vs Replicaset
Replicaset is new version of Replica Contorller :
</p>
</div>
</div>
<div id="outline-container-org17a39fd" class="outline-4">
<h4 id="org17a39fd">Replicatoin-Contorller</h4>
<div class="outline-text-4" id="text-org17a39fd">
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Pod
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: myapp-pod
  <span style="color: #715ab1;">labels</span>:
     <span style="color: #715ab1;">app</span>: myapp
     <span style="color: #715ab1;">type</span>: front-end
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">containers</span>:
  - <span style="color: #715ab1;">name</span>: nginx-container
    <span style="color: #715ab1;">image</span>: nginx
</pre>
</div>

<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: ReplicationContorller
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: myapp-rc
  <span style="color: #715ab1;">labels</span>:
      <span style="color: #715ab1;">app</span>: myapp
      <span style="color: #715ab1;">type</span>: front-end
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">replicas</span>: 3
  <span style="color: #715ab1;">template</span>:

    <span style="color: #715ab1;">metadata</span>:
     <span style="color: #715ab1;">name</span>: myapp-pod
     <span style="color: #715ab1;">labels</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">app</span>: myapp
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">type</span>: front-end
     <span style="color: #715ab1;">spec</span>:
       <span style="color: #715ab1;">containers</span>:
       - <span style="color: #715ab1;">name</span>: nginx-container
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;"> image</span>: nginx
kubectl create -f rc-definition.yaml
kubectl get replicationcontorller <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">see how many total and current no.of pods</span>
kubeclt get pods

</pre>
</div>
</div>
</div>

<div id="outline-container-orgf428fea" class="outline-4">
<h4 id="orgf428fea">Replicaset</h4>
<div class="outline-text-4" id="text-orgf428fea">
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: apps/v1
<span style="color: #715ab1;">kind</span>: ReplicaSet 
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: myapp-replicaset
  <span style="color: #715ab1;">labels</span>:
      <span style="color: #715ab1;">app</span>: myapp
      <span style="color: #715ab1;">type</span>: front-end
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">replicas</span>: 3
  <span style="color: #715ab1;">selector</span>:
    <span style="color: #715ab1;">matchLabels</span>:
       <span style="color: #715ab1;">type</span>: front-end
  <span style="color: #715ab1;">template</span>:

    <span style="color: #715ab1;">metadata</span>:
     <span style="color: #715ab1;">name</span>: myapp-pod
     <span style="color: #715ab1;">labels</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">app</span>: myapp
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">type</span>: front-end
     <span style="color: #715ab1;">spec</span>:
       <span style="color: #715ab1;">containers</span>:
       - <span style="color: #715ab1;">name</span>: nginx-container
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;"> image</span>: nginx

kubectl create -f replicaset-definition.yaml
kubectl get replicaset <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">see how many total and current no.of pods</span>
kubeclt get pods
</pre>
</div>

<p>
Difference:
In yaml file for replicaset: defines what pods comes under the replicas or replicaset by <b>matchLabel</b> (matched label is type: front-end)   in <b>selector</b>
</p>

<ul class="org-ul">
<li>The <b>selector</b> specify what pods come under <b>replicaset</b></li>
<li><p>
Why you we need to give  <b>pod-data</b> in <b>templete</b>  if  <b>selector</b> specified what pod come under <b>replicaset</b> ?
</p>
<ul class="org-ul">
<li>Replicatset can also manage the pod which are created as part of replicaset creation
<ul class="org-ul">
<li>Ex: there are replicas of pod which are created before replicaset then also those pods which are not part of replicaset come under replicaset</li>
</ul></li>
</ul>
<ul class="org-ul">
<li><b>selector</b> is major difference between replicationcontorller and replicaset</li>
<li><b>selector</b> is not complusory but optional in yaml file
if selector is not sepecified then also</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org4f13222" class="outline-4">
<h4 id="org4f13222">Labels and Selector</h4>
<div class="outline-text-4" id="text-org4f13222">
<ul class="org-ul">
<li>Why do we label our pods and object in kubernetecis ?
<ul class="org-ul">
<li><p>
Let say you deploy 3 pod of frond-end  and you ensure that 3 pod are deployed and active any time by replicaset.
</p>
<ul class="org-ul">
<li>replicaset can be used to  monitoring pods if you have alread created the pods</li>
<li>if  incase you have not created pods then replicaset create them for you</li>
</ul>
<ul class="org-ul">
<li>the role of replicaset is to monitor the pods and if any one fails then you will re-deploy the pod</li>
</ul></li>
</ul></li>
<li>How does replicaset know which pod should be monitor under the specific replicaset ?
<ul class="org-ul">
<li>By labeling the pods we can filter the pods that should be monitor</li>
</ul></li>
<li>Same concept used in many part in kubernetecis</li>
</ul>
</div>
</div>
<div id="outline-container-orgfc0f6f5" class="outline-4">
<h4 id="orgfc0f6f5">Scale the running deploy/pod of running yaml</h4>
<div class="outline-text-4" id="text-orgfc0f6f5">
<p>
Different method
</p>
<ul class="org-ul">
<li>update replicas form 3 to 6 in yaml file and replace the running deploy/pod config
<ul class="org-ul">
<li><code>kubectl replica -f replicaset-definition.yaml</code></li>
</ul></li>
<li>update the running config with-out changing the origina yaml file
<ul class="org-ul">
<li><code>kubectl scale --replicas=6 -f replicaset-defiinition.yaml</code></li>
<li>Note: this will not change replicas in <code>yaml file</code></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org6874762" class="outline-4">
<h4 id="org6874762">cmd</h4>
<div class="outline-text-4" id="text-org6874762">
<pre class="example">
kubectl create -f replicaset-definition.yaml
kubectl get replicaset
kubectl delete replicaset myapp-replicaset
kubectl replace -f replicaset-definition.yaml
kubectl scale -replicas=6 -f replicaset-definition.yaml 
</pre>
</div>
</div>

<div id="outline-container-orgfd71c84" class="outline-4">
<h4 id="orgfd71c84">Auto scale pod based on load &lt;later-discuss advance topics&gt;</h4>
</div>
<div id="outline-container-org82d3e4c" class="outline-4">
<h4 id="org82d3e4c">Practice Test</h4>
<div class="outline-text-4" id="text-org82d3e4c">
<ul class="org-ul">
<li>How may pods are prscent on default namespace ?
<ul class="org-ul">
<li><code>kubectl get pod -n default | wc</code> or</li>
<li><code>echo $(($(kubectl get pods | wc -l)-1))</code></li>
</ul></li>
<li>Create a new pod with nginx ?
<ul class="org-ul">
<li><code>kubectl run nginx --image=nginx</code></li>
</ul></li>
<li>How may pods are prscent on default namespace ?
<ul class="org-ul">
<li><code>kubectl get pod -n default | wc</code> or</li>
<li><code>echo $(($(kubectl get pods | wc -l)-1))</code></li>
</ul></li>
<li>What is the image used to create pod "newpord-bcm4" ?
<ul class="org-ul">
<li>kubectl describe pod newpods-bcm4 | grep -i image</li>
</ul></li>

<li>Which nodes are pods placed on
<ul class="org-ul">
<li><code>kubectl get pods -o wide</code></li>
</ul></li>
<li>How many container(pods)(images) are running on 'webapp' pod ?
<ul class="org-ul">
<li><code>kubectl get pods webapp</code></li>
</ul></li>

<li>What images are used in 'webapp' pod ?
<ul class="org-ul">
<li><code>kubeclt describe pod webapp | grep -i image</code></li>
</ul></li>
<li>What is status of container 'agentx' in the pod 'webapp' ?
<ul class="org-ul">
<li><code>kubeclt describe pod webapp</code> see container agentx, state:</li>
</ul></li>
<li>Why do you think the contiaenr agentx in pod 'webapp  is in error ?
<ul class="org-ul">
<li><code>kubectl descirbe pod webapp</code> see EVENTS: Failed,Pulling, BackOff</li>
</ul></li>
<li><p>
What does READY column in output of <code>kubectl get pods</code> cmd indicate ?
</p>
<ul class="org-ul">
<li>Running Container in Pod/ Total Container in Pod</li>
</ul>
<ul class="org-ul">
<li>Delete webapp pod3
<ul class="org-ul">
<li><code>kubectl get pods webapp</code></li>
</ul></li>
<li>Create a new pod  with image 'redis123' and pod name redis ?
<ul class="org-ul">
<li><code>kubectl run redis --image=redis123</code></li>
</ul></li>
<li>Create a yaml file of new pod
<ul class="org-ul">
<li><code>kubectl run redis --image=redis123 --dry-run=client -o yaml &gt; pod.yaml</code></li>
<li><code>kubectl apply -f pod.yaml</code></li>
</ul></li>
</ul></li>
<li>edit the running pod.yaml who name is redis  and change image name form 'redis123' to 'redis'?
<ul class="org-ul">
<li><code>kubectl edit pod redis</code> change image name</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org21f1212" class="outline-3">
<h3 id="org21f1212">deployment or deploy</h3>
<div class="outline-text-3" id="text-org21f1212">
</div>
<div id="outline-container-org12e112f" class="outline-4">
<h4 id="org12e112f">Intro</h4>
<div class="outline-text-4" id="text-org12e112f">
<p>
How you want to deploy your web-app in production server ? 
</p>
<ul class="org-ul">
<li><code>deploy on mulitple instance</code> You want to deploy on mulitpule ec2-instance</li>
<li><code>New version or Upgdate</code> is availabe in production env then
<ul class="org-ul">
<li>how you want to upgrade you instance ? You will not upgrade all instance once ?
<ul class="org-ul">
<li>you want to upgrade then one-after other this is know as <code>Roll Update</code></li>
</ul></li>
</ul></li>
<li><code>Roll Back</code> Suppose if you new-version as some error, bug and you want to undo changes (move back to old version) which is also know as <code>Roll Back</code></li>
<li><code>Pause &amp; Resume update</code> If you would like to do mulitple chagens in environment like upgrade, scaling the envirnoment, modify the resource allocation you don't want to apply the chagens all at once but pass the changes resume</li>
</ul>
<p>
All this feature are available in deployment
</p>
</div>
</div>

<div id="outline-container-orgac07b5e" class="outline-4">
<h4 id="orgac07b5e">insert the image</h4>
</div>
<div id="outline-container-org1d7fe9b" class="outline-4">
<h4 id="org1d7fe9b">Defination</h4>
<div class="outline-text-4" id="text-org1d7fe9b">
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: apps/v1
<span style="color: #715ab1;">kind</span>: Deployment 
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: myapp-replicaset
  <span style="color: #715ab1;">labels</span>:
      <span style="color: #715ab1;">app</span>: myapp
      <span style="color: #715ab1;">type</span>: front-end
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">replicas</span>: 3
  <span style="color: #715ab1;">selector</span>:
    <span style="color: #715ab1;">matchLabels</span>:
       <span style="color: #715ab1;">type</span>: front-end
  <span style="color: #715ab1;">template</span>:

    <span style="color: #715ab1;">metadata</span>:
     <span style="color: #715ab1;">name</span>: myapp-pod
     <span style="color: #715ab1;">labels</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">app</span>: myapp
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">type</span>: front-end
     <span style="color: #715ab1;">spec</span>:
       <span style="color: #715ab1;">containers</span>:
       - <span style="color: #715ab1;">name</span>: nginx-container
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;"> image</span>: nginx

kubectl create -f deployment-definition.yaml
kubectl get deployment  <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">see how many total and current no.of pods</span>
kubectl get replicaset
kubeclt get pods
kubectl get all 
</pre>
</div>
</div>
</div>
<div id="outline-container-org3596283" class="outline-4">
<h4 id="org3596283">Practice Test</h4>
<div class="outline-text-4" id="text-org3596283">
<ul class="org-ul">
<li>How many PODs exist on the system ?
<ul class="org-ul">
<li><code>kubectl get pods</code></li>
</ul></li>
<li>How many Replicaset exist on the system ?
<ul class="org-ul">
<li><code>kubectl get replicasets.apps</code></li>
</ul></li>
<li>How many Deployment on the system ?
<ul class="org-ul">
<li><code>kubectl get deployment</code></li>
</ul></li>
<li>On existing pods how many of them are ready ?
<ul class="org-ul">
<li><code>kubectl get pods</code>  see <b>READY</b></li>
</ul></li>
<li>What is the image used in deployment name= "frontend-deployment"
<ul class="org-ul">
<li><code>kubectl describe deployemts.apps frontend-deployment | grep -i image</code></li>
</ul></li>
<li>Why do you think deployment is not ready ?
<ul class="org-ul">
<li><code>kubectl get pods</code> get the pod name</li>
<li><code>kubectl describe pod frontend-deployment-66687b8d77</code>
<ul class="org-ul">
<li>Search <b>Event Message</b> shows Error Image Pull</li>
</ul></li>
</ul></li>
<li>Create new Deployment using 'deployment-definition-1.yaml' ?
<ul class="org-ul">
<li><code>kubectl apply -f deployment-definition-1.yaml</code>
<ul class="org-ul">
<li>Error: deployment in version "v1" can't be handled as a Deployemnt</li>
<li>replace: kind: deployment to Deployment</li>
</ul></li>
</ul></li>
<li>Create a new Deployment with the below attributes using your own deployment definition file
<ul class="org-ul">
<li><code>kubectl create deployment httpd-frontend --image=httpd:2.4-apline</code></li>
<li><code>kubectl scale deployment --replicas=3 httpd-frontend</code></li>
<li><code>kubectl get deployment</code></li>
</ul></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgbfd5d0e" class="outline-3">
<h3 id="orgbfd5d0e">namespaces</h3>
<div class="outline-text-3" id="text-orgbfd5d0e">
</div>
<div id="outline-container-org19d5381" class="outline-4">
<h4 id="org19d5381">Intro</h4>
<div class="outline-text-4" id="text-org19d5381">
<p>
Let consider two boys with same name but different sur-name
</p>
<ul class="org-ul">
<li>Mark Smith</li>
<li>Mark William</li>
</ul>
<p>
Inside smith house
</p>
<ul class="org-ul">
<li>Mark repesent : own person that is Mark William</li>
<li>other Mark is know as : Mark William</li>
</ul>
<p>
Ouside both house:
</p>
<ul class="org-ul">
<li>Mark Smith and Mark William is used to call the person</li>
</ul>

<p>
Inside each house has own
</p>
<ul class="org-ul">
<li>set of rules    : defines who does what</li>
<li>set of resource : that they can consume</li>
</ul>

<p>
INSERT IMAGE:
</p>

<p>
This house is know as namespace
</p>
</div>
</div>
<div id="outline-container-orgb70a4f8" class="outline-4">
<h4 id="orgb70a4f8">Different Namespace in kubernetecis</h4>
<div class="outline-text-4" id="text-orgb70a4f8">
<p>
Inside kubenetics we have created pods, services, deployment but all this has happend inside the namespace.
Kubernetecis has different namespaces:
</p>
<ul class="org-ul">
<li>default     : Created by automatically when the cluster is setup</li>
<li>kube-system : Kubernetics create a set of pods and servies like networking solution , codeDNS..etc this all are created at cluseter startup under kube-system namespaces</li>
<li>kube-public : Resource that should be made availabe for users are created.if your environment is small then you should not worry about namespace.</li>
</ul>

<p>
If you have small cluster,learning  then you shouldn't worry about namespaces you can use default
</p>
</div>
</div>
<div id="outline-container-org7b0c50d" class="outline-4">
<h4 id="org7b0c50d">Namespace- Isolation</h4>
<div class="outline-text-4" id="text-org7b0c50d">
<p>
But if your cluster grow and getting bigger, use in enterprise, use in production  they you may want to consider
</p>

<p>
Example :
</p>
<ul class="org-ul">
<li>If you want to use same cluster for Dev and Prod Environment but same time isolate the resouce between them, you can create different namespace between them</li>
<li>That way you can seperate (isolate) the resouce, so you can't accidentally modify resourc in production env</li>
</ul>
</div>
</div>
<div id="outline-container-org31c4a78" class="outline-4">
<h4 id="org31c4a78">Nampespace Policy(Rules)</h4>
<div class="outline-text-4" id="text-org31c4a78">
<p>
Each of namespace as set of rules or policy where we define who can do what
</p>
</div>
</div>
<div id="outline-container-orgf372749" class="outline-4">
<h4 id="orgf372749">Namespace - Resource limit</h4>
<div class="outline-text-4" id="text-orgf372749">
<p>
You can create a limit resource(cpu, memory) for each enviorment   
</p>
</div>
</div>
<div id="outline-container-org755637e" class="outline-4">
<h4 id="org755637e">DNS</h4>
<div class="outline-text-4" id="text-org755637e">
<p>
Inside a namespace just like member inside house call each other simillary we can all other pods or services by its name
</p>

<p>
example:
</p>
<ul class="org-ul">
<li>Consider you are using default namespace and has three pod
<ul class="org-ul">
<li>web-pod</li>
<li>db-server</li>
<li>web-deployment</li>
</ul></li>

<li>Here web-app-pod can reach db-server <code>mysql.connect("db-server")</code></li>

<li>If prod env web-app pod want to access the db-server in dev env then
<ul class="org-ul">
<li><code>mysql.connect(" db-server.dev.svc.cluster.local")</code>
<ul class="org-ul">
<li>dev : namespace</li>
<li>svc : service</li>
<li>cluster.local : domain</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org8651972" class="outline-4">
<h4 id="org8651972">cmd</h4>
<div class="outline-text-4" id="text-org8651972">
<pre class="example">
kubectl get pods
kubectl get pods -n kube-system

# create a pod on a default namespace
kubectl create -f pod-definition.yml

#kubetl create -f pod-definition.yml --namespace=dev 

# you can move namespace defination inside yaml file inside metada/namespace: dev
# this will ensure the pod or deployment is created inside the given 

# create your own namespace
</pre>
</div>
</div>

<div id="outline-container-orgf0394ee" class="outline-4">
<h4 id="orgf0394ee">Create your own namespace:</h4>
<div class="outline-text-4" id="text-orgf0394ee">
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Namespace

<span style="color: #715ab1;">metadata</span>:
    <span style="color: #715ab1;">name</span>: dev
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubectl create -f namespace-dev.yaml</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubectl create namespace dev</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org1dcde11" class="outline-4">
<h4 id="org1dcde11">Switch</h4>
<div class="outline-text-4" id="text-org1dcde11">
<p>
set the default namespace to dev 
</p>
<pre class="example">
kubectl get pods --namespace=dev
kubectl get pods
kubectl get pods --namespace=dev

kubectl config set-context $(kubectl config current-context) --namespace=dev
kubectl get pod  # give pods on dev

kubectl get pods --all-namespaces
</pre>
</div>
</div>

<div id="outline-container-orgd91b23f" class="outline-4">
<h4 id="orgd91b23f">Resource Quota</h4>
<div class="outline-text-4" id="text-orgd91b23f">
<pre class="example">
apiVersion: v1
kind: ResourceQuota
metadata:
    name: computer-quota
    namespace: dev
spec:
  hard:
    pods: "10"
    requests.cpu : "4"
    limits.cpu: "10"
    limits.memory: 10Gi

kubectl create -f computer-quota.yaml
</pre>
</div>
</div>


<div id="outline-container-org31d3aca" class="outline-4">
<h4 id="org31d3aca">Practice Test</h4>
<div class="outline-text-4" id="text-org31d3aca">
<p>
How many namespcaes exist on the system ?
</p>
<ul class="org-ul">
<li>kubectl get ns $ namespace</li>
<li>kubectl get ns &#x2013;no-headers</li>
<li>kubectl get ns &#x2013;no-headers |wc -l</li>
</ul>
<p>
How much pod exit in &lt;research&gt; namespace
</p>
<ul class="org-ul">
<li>kubectl -n research get pods &#x2013;no-hearders</li>
</ul>
<p>
Create a pod in 'finance' namespace  with image redis and image-name: redis
How run redis &#x2013;image=redis &#x2013;dry-run=client -o yaml &gt; pod.yaml
</p>
<ul class="org-ul">
<li>Add namespace in pod.yaml/metadata/namespace:finance</li>
<li>kubectl apply -f pod.yaml</li>
<li># check if the pod is created in finance namespace ?
<ul class="org-ul">
<li>kubectl -n finace get pod redis</li>
</ul></li>
<li>which namespace has &lt;blue&gt; pod in it ?
<ul class="org-ul">
<li>kubectl get pods &#x2013;all-namespace | grep blue</li>
<li>access the blue application in blue termininal</li>
</ul></li>
<li>What DNS name  should the Blue application use to access the database 'db-service'  in its namespace- 'marketing' ?</li>
<li></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgbb17605" class="outline-3">
<h3 id="orgbb17605">services</h3>
<div class="outline-text-3" id="text-orgbb17605">
<p>
<a href="https://itnext.io/kubernetes-clusterip-vs-nodeport-vs-loadbalancer-services-and-ingress-an-overview-with-722a07f3cfe1">https://itnext.io/kubernetes-clusterip-vs-nodeport-vs-loadbalancer-services-and-ingress-an-overview-with-722a07f3cfe1</a>
</p>
</div>
<div id="outline-container-orgcb010e8" class="outline-4">
<h4 id="orgcb010e8">Intro to Service-Type</h4>
<div class="outline-text-4" id="text-orgcb010e8">
<p>
Kubernetes offers several options when exposing your service based on a feature called Kubernetes Service-types and they are:
</p>
<ul class="org-ul">
<li><b>NodePort</b> (30000-32767):
<ul class="org-ul">
<li>This is the most basic option of exposing your service to be accessible outside of your cluster, on a specific port (called the NodePort) on every node in the cluster. We will illustrate this option shortly.</li>
</ul></li>
<li><b>ClusterIP</b> : 
<ul class="org-ul">
<li>This Service-type generally exposes the service on an internal IP, reachable only within the cluster, and possibly only within the cluster-nodes.</li>
</ul></li>
<li><b>LoadBalancer</b> 
<ul class="org-ul">
<li>This option leverages on external Load-Balancing services offered by various providers to allow access to your service. This is a more reliable option when thinking about high availability for your service, and has more feature beyond default access.</li>
</ul></li>
<li><b>ExternalName</b> 
<ul class="org-ul">
<li>This service does traffic redirect to services outside of the cluster. As such the service is thus mapped to a DNS name that could be hosted out of your cluster. It is important to note that this does not use proxying.</li>
</ul></li>
<li><b>Ingress</b>
<ul class="org-ul">
<li>Actually, the Ingress isn't a dedicated Service - it just describes a set of rules for the Kubernetes Ingress Controller to create a Load Balancer, its Listeners and routing rules for them.</li>
<li>Generally used for http,https</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orge007ffd" class="outline-4">
<h4 id="orge007ffd">cmd for services, clusterip, nodeport, loadbalancer</h4>
<div class="outline-text-4" id="text-orge007ffd">
<div class="org-src-container">
<pre class="src src-sh">kubectl create deployment nginx --image=nginx
kubectl scale deployment nginx --replicas=5


kubectl expose deployment/nginx --port 80 --name service-cip   <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Create ClusterIP Service</span>
kubectl expose deployment/nginx --port 80 --name service-np --type NodePort        <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Create NodePort Servic</span>
kubectl expose deployment/nginx --port 80 --name service-lb --type LoadBalancer

NAME         TYPE        CLUSTER-IP          EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.96.0.1           &lt;none&gt;        443/TCP        27h
service-ip   ClusterIP   10.105.107.120      &lt;none&gt;        80/TCP         6m9s
service-np   NodePort    10.100.116.118      &lt;none&gt;        80:32463/TCP   2m35s
service-lb   LoadBalancer   10.106.169.117   &lt;pending&gt;     80:30556/TCP   7s

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">For ClusterIP</span>
curl 10.105.107.120:80 
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;!DOCTYPE html&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;html&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;head&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;style&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">html { color-scheme: light dark; }</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">body { width: 35em; margin: 0 auto;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">font-family: Tahoma, Verdana, Arial, sans-serif; }</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;/style&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;/head&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;body&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">working. Further configuration is required.&lt;/p&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;p&gt;For online documentation and support please refer to</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">Commercial support is available at</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;/body&gt;</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">&lt;/html&gt;</span>

<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">For NodePort</span>
firefox public_ip:NodePort 
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">firefox http://13.232.106.187:32453</span>
curl 10.100.116.118:32453

firefox public_ip:Loadbalancer_port 
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">firefox http://13.232.106.187:30556 </span>

kubectl delete services service-ip service-np service-lb
kubectl delete deploy/nginx
</pre>
</div>
</div>
</div>
<div id="outline-container-org54c3efb" class="outline-4">
<h4 id="org54c3efb">yaml file for nginx-with-no-service, service-yaml for clusterip, nodeport, loadbalancer</h4>
<div class="outline-text-4" id="text-org54c3efb">
</div>
<ul class="org-ul">
<li><a id="orgf912d90"></a>Nginx-No-service yaml file<br />
<div class="outline-text-5" id="text-orgf912d90">
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: apps/v1
<span style="color: #715ab1;">kind</span>: Deployment
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: nginx-deployment
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">selector</span>:
    <span style="color: #715ab1;">matchLabels</span>:
      <span style="color: #715ab1;">app</span>: nginx
  <span style="color: #715ab1;">replicas</span>: 2 <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">tells deployment to run 2 pods matching the template</span>
  <span style="color: #715ab1;">template</span>:
    <span style="color: #715ab1;">metadata</span>:
      <span style="color: #715ab1;">labels</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">app</span>: nginx
    <span style="color: #715ab1;">spec</span>:
      <span style="color: #715ab1;">containers</span>:
      - <span style="color: #715ab1;">name</span>: nginx
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">image</span>: nginx:1.14.2
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">ports</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">- containerPort</span>: 80   <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">target port</span>
</pre>
</div>
</div>
</li>
<li><a id="org25a6f09"></a>ClusterIp yaml file<br />
<div class="outline-text-5" id="text-org25a6f09">
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Service
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: <span style="color: #2d9574;">"nginx-service"</span>
  <span style="color: #715ab1;">namespace</span>: <span style="color: #2d9574;">"default"</span>
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">ports</span>:
    - <span style="color: #715ab1;">port</span>: 80
  <span style="color: #715ab1;">type</span>: ClusterIP
  <span style="color: #715ab1;">selector</span>:
    <span style="color: #715ab1;">app</span>: <span style="color: #2d9574;">"nginx"</span>
</pre>
</div>
</div>
</li>
<li><a id="org96753f3"></a>NodePort  yaml file<br />
<div class="outline-text-5" id="text-org96753f3">
<pre class="example">
apiVersion: v1
kind: Service
metadata:
  name: "nginx-service"
  namespace: "default"
spec:
  ports:
    - port: 80
      nodePort: 30001
  type: NodePort
  selector:
    app: "nginx"
</pre>
</div>
</li>

<li><a id="orgd0a5068"></a>LoadBalancer  yaml file<br />
<div class="outline-text-5" id="text-orgd0a5068">
<pre class="example">
apiVersion: v1
kind: Service
metadata:
  name: "nginx-service"
  namespace: "default"
spec:
  ports:
    - port: 80
  type: LoadBalancer
  selector:
    app: "nginx"
</pre>
</div>
</li>

<li><a id="org054a6f0"></a>Kubernetic cmd<br />
<div class="outline-text-5" id="text-org054a6f0">
<div class="org-src-container">
<pre class="src src-sh">kubectl appy -f nginx-no-service.yaml
kubectl apply -f nginx-LoadBalancer.yaml
kubectl apply -f nginx-ClusterIP.yaml 
kubectl apply -f nginx-NodePort.yml 

kubectl get services
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">NAME         TYPE        CLUSTER-IP          EXTERNAL-IP   PORT(S)        AGE</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubernetes   ClusterIP   10.96.0.1           &lt;none&gt;        443/TCP        27h</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">service-ip   ClusterIP   10.105.107.120      &lt;none&gt;        80/TCP         6m9s</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">service-np   NodePort    10.100.116.118      &lt;none&gt;        80:32463/TCP   2m35s</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">service-lb   LoadBalancer   10.106.169.117   &lt;pending&gt;     80:30556/TCP   7s</span>

kubectl delete -f nginx-NodePort.yml 


</pre>
</div>
</div>
</li>
<li><a id="org918318b"></a>Practice Solution<br />
<div class="outline-text-5" id="text-org918318b">
<p>
Create a new service to access the web applilcation using the servie-definition-1.yam file
Name: webapp-service
Type: NodePort
targetPort: 8080
port: 8080
nodePort:30080
</p>


<ul class="org-ul">
<li>kubect expose depolyment simple-webapp-deplooyment &#x2013;name=webapp-service &#x2013;target port=8080 &#x2013;type=NodePort &#x2013;port=8080 &#x2013;dry-run=client -o yaml &gt; svc.yaml</li>
<li>insert svc.yaml/spec/pprts/- port:8080/nodePort: 30080</li>
<li>kubeclt apply -f svc.yaml</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div id="outline-container-org4bebd73" class="outline-3">
<h3 id="org4bebd73">Imperative(cmd line interface cli) vs Declarative(script , yaml file )</h3>
<div class="outline-text-3" id="text-org4bebd73">
</div>
<ul class="org-ul">
<li><a id="org167a7c9"></a>Imperative<br />
<div class="outline-text-5" id="text-org167a7c9">
<pre class="example">
kubectl run --image=nginx  nginx
kubectl create deployment --image=nginx nginx
kubectl expose deployment nginx --port 80
kubectl edit deployment nginx
kubectl scale deployment nginx --replica=5
kubectl set image deployment nginx nginx
kubectl create -f nginx.yaml
kubectl replica -f nginx.yaml
kubectl delete -f nginx.yaml


# Creating the objetcs
kubect run --image=nginx nginx
kubectl create deployment --image=nginx nginx
kubectl expose deployment ngnx --port 80

# Update Objects

kubectl edit deployment nginx
kubectl scale deployment nginx --replicas=5
kubectl set image deployment nginx nginx=nignx:1:18

# Imperative Object Configuration File

# Create Object 
kubectl create -f nginx.yaml

# Update Object

kubectl edit deployment nignx  # it is live object don't save changes in a file or config file

# Best practies is to edit the nginx.yaml file and apply changes to cluster

nano nginx.yaml # change the config 
kubectl replace -f nginx.yaml   # NOTE: object should exsist in the local kube cluster

kubectl replace --force -f nginx.yaml 
</pre>
</div>
</li>

<li><a id="org705dfbe"></a>Declrative script<br />
<div class="outline-text-5" id="text-org705dfbe">
<p>
apply cmd will see the configuration of existance config and figure-out what is min changes need to get the desired configuretion
</p>

<p>
apply cmd is used to creating ,updating ,deleting the object
</p>

<pre class="example">

# Create Objects

kubectl apply -f nginx.yaml # create, update

# to load  all yaml file in a folder
kubectl apply -f nginx.yaml

# Update Objects
kubectl apply -f nginx.yaml


</pre>
</div>
</li>

<li><a id="orgdb8189a"></a>Imperative Practice Lab<br />
<div class="outline-text-5" id="text-orgdb8189a">
<ul class="org-ul">
<li>deploy a pod named nginx-pod using nginx:alpine image
<ul class="org-ul">
<li><code>kubectl run nginx-pod --image=nginx:alpine</code></li>
</ul></li>
<li>Deploy a redis pod using the redis: alpine image with labels set to tire=db
<ul class="org-ul">
<li>~kubectl run redis &#x2013;image=redis:alpine &#x2013;labels=tire=db</li>
</ul></li>
<li>Create a service to expose redis application with the cluster on port 6379
<ul class="org-ul">
<li><code>kubectl expose pod redis --name redis-service --port 6379-port 6379</code></li>
<li><code>kubectl describe svc redis-service</code></li>
</ul></li>
<li>Create a deployment webapp using image Kodekloud/webapp-color with 3 replicas
<ul class="org-ul">
<li><code>kubectl create deployment webappp --image=kodekloud/webapp-color</code></li>
<li><code>kubectl scale deployment --replicas=3 webapp</code></li>
</ul></li>
<li>Create new pod custome-nginx using nginx image and expose it on container port 8080
<ul class="org-ul">
<li><code>kubectl run custom-nginx -image=nginx --port 8080</code></li>
<li><code>kubectl describe pod custom-nginx</code></li>
</ul></li>
<li>Create a new namespace dev-ns
<ul class="org-ul">
<li><code>kubectl create ns dev-ns</code></li>
</ul></li>
<li>Create new deployment called redis-deploy in the dev-ns namespace with redis image. It should have 2 replicas.
<ul class="org-ul">
<li><code>kubectl create deployment redis-deploy --image=redis --namespace=dev-ns --dry-run=client -o yaml</code></li>
</ul></li>
<li>Create a pod called <code>httpd</code> using the image <code>httpd:alphine</code> in the default namespace. Next create a service of type ClusterIp by the same name (httpd). The target por for the service should be 80.
<ul class="org-ul">
<li><code>kubectl run httpd --image=httpd:alpine --port 80 --expose --dry-run=client -o yaml</code></li>
<li><code>kubectl get pods</code></li>
</ul></li>
</ul>
</div>
</li>
<li><a id="org87b905a"></a>How kubectl apply work ?<br />
<div class="outline-text-5" id="text-org87b905a">
<p>
If the object doesn't already exist and you are creating a new object
then
</p>
<ul class="org-ul">
<li>kubectl will create a cluster and a  running yaml</li>
<li>local yaml is converted into json format and sotred as last applied kube format configuration</li>
<li>IF UPDATE LOCAL-FILE.YAML FILE AND <code>kubectl apply</code>
<ul class="org-ul">
<li>Then <b>local-file.yaml</b> and <b>last applied config</b> and <b>kube cluster yaml</b> all three are compared and specific changes are made</li>
<li>Why me need <b>last-applied-config</b> if we can do the thinks
<ul class="org-ul">
<li>If few fields are deleted in local-file.yaml then by
<b>last-applied-config</b> we figure out what field need to be removed</li>
<li>the json file is stored in kube-runtime yaml file as live annotation</li>
</ul></li>
</ul></li>
</ul>
</div>
</li>
</ul>
</div>
</div>

<div id="outline-container-org3f2d137" class="outline-2">
<h2 id="org3f2d137">Scheduling  | 1h 50 mints</h2>
<div class="outline-text-2" id="text-org3f2d137">
<p>
In this section we can see  various concept in scheduling
</p>
</div>
<div id="outline-container-org7510c1d" class="outline-3">
<h3 id="org7510c1d">Manual Scheduling</h3>
<div class="outline-text-3" id="text-org7510c1d">
<p>
Every pod has a field called nodeName: which is not set but kubernetics manages
The scheduler will go to all pods and see in which pod the nodeName is not allocated then. By running shcedule algorithum and assign node
</p>

<pre class="example">
kubectl get pods
</pre>

<p>
If pod is already assign then we can't chanage the node but drain teh pods form one node
</p>

<p>
How to assing a pod in a specific node 
</p>
<pre class="example">
apiVersion: v1
kind: Binding
metadata:
  name: nginx
target:
  apiVersion: v1
  kind: Node
  name: node02 
</pre>
</div>
</div>
<div id="outline-container-org6fa63d8" class="outline-3">
<h3 id="org6fa63d8">Practice Test - Manual Scheduling</h3>
<div class="outline-text-3" id="text-org6fa63d8">
</div>
</div>
<div id="outline-container-org0fcab55" class="outline-3">
<h3 id="org0fcab55">Solution - Manual Scheduling (optional)</h3>
<div class="outline-text-3" id="text-org0fcab55">
<ul class="org-ul">
<li>A pod definiton file nginx.yaml is given.Create a pod using the file ?
<ul class="org-ul">
<li>kubectl apply -f nignx.yaml</li>
</ul></li>
<li>What is status of pods ?
<ul class="org-ul">
<li>kubectl get pods # CHECK STATUS</li>
</ul></li>
<li>Why pod is pending state ?
<ul class="org-ul">
<li><code>kubectl -n kube-system get pods</code> # check all system are present</li>
<li>kube-scheduler is not present</li>
</ul></li>
<li>Manually scheduler the pod on node01
<ul class="org-ul">
<li>set yaml/spec/nodeName: node01 in yaml file</li>
<li>kubectl apply -f nginx.yaml</li>
<li>check if the pod is create in node01 <code>kubectl get pod -o</code></li>
</ul></li>
<li>Scheduler the same pod in master node ?
<ul class="org-ul">
<li>set <code>yaml/spec/nodeName: master</code> in yaml file</li>
<li>kubectl apply -f nginx.yaml</li>
<li><code>kubectl get pods -o wide</code></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org0b90c12" class="outline-3">
<h3 id="org0b90c12">Labels and Selectors</h3>
<div class="outline-text-3" id="text-org0b90c12">
<p>
Label and selectors are used to standard method to group them together
like:
</p>
<ul class="org-ul">
<li>mammals, replites, arthropods, fish, birds</li>
<li>domentic and wild</li>
<li>herbiours, carnoious, omnious</li>
<li>colour:</li>

<li>Muti classification:
colour green and bird</li>
</ul>


<p>
This kind of classification is done by by selector in our kube-cluster
</p>

<p>
We can classify or group in kubernetics by
</p>

<ul class="org-ul">
<li>Type: pods, replicaset, deployement, service&#x2026;.etcd</li>
<li>group by Environment: dev env, test env, pre-prod,, demo,  prod,  &#x2026;etc</li>
<li>group by projects : assesment, authenication, scheduler, class,</li>
<li>group by functionally: web Server, Front End, Back-End, DB, Image Processing, Video Processing, Cache.</li>
</ul>

<p>
Slection :
project: assensment
functionally: web-server
Environment: prod
</p>


<p>
GET THE PODS AT SPECIFIC SELECTOR
</p>
<pre class="example">
kubectl get pods --selector app=App1
</pre>
</div>

<div id="outline-container-org5a5adb9" class="outline-4">
<h4 id="org5a5adb9">ReplicaSet : insert video expalined neatly</h4>
</div>
<div id="outline-container-orgfee3167" class="outline-4">
<h4 id="orgfee3167">Annotation :</h4>
<div class="outline-text-4" id="text-orgfee3167">
<p>
phone, email id ,
</p>
</div>
</div>
</div>
<div id="outline-container-org02b1a29" class="outline-3">
<h3 id="org02b1a29">Practice Test - Labels and Selectors</h3>
</div>
<div id="outline-container-org61b8222" class="outline-3">
<h3 id="org61b8222">Solution : Labels and Selectors : (Optional)</h3>
<div class="outline-text-3" id="text-org61b8222">
<ul class="org-ul">
<li>We deployed no of PODs. They are labelled with 'tire' , 'env' and 'bu'. How may PODs exist in the 'dev' environment ?
<ul class="org-ul">
<li><code>kubectl get pods --selector=dev</code></li>
<li><code>kubectl get pods --show-labels</code></li>
<li><code>kubectl get pods  -l env=dev</code></li>
<li><code>kubectl get pods  -l env=dev --no-header | wc -l</code></li>
</ul></li>
<li>How many PODs are in the 'finance' business unit ('bu') ?
<ul class="org-ul">
<li><code>kubectl get pods  -l bu=finance --no-header | wc -l</code></li>
</ul></li>
<li>How may object are in the 'prod' environment including PODS, ReplicaSets, and any other objects ?
<ul class="org-ul">
<li><code>kubectl get all -l env=prod --no-headers</code></li>
<li><code>kubectl get all -l env=prod --no-headers | wc -l</code> # 7 object</li>
</ul></li>
<li>Identify teh pod part of finace 'BU' and is a 'frontend' tier
<ul class="org-ul">
<li><code>kubectl get all -l env=prod,bu=finance,tire=frondend</code></li>
</ul></li>
<li>ReplicaSet defination file is given 'replicaset-defined-1.yaml'. Try to create replicaset. If there is a issue with file.Try to fix it.
<ul class="org-ul">
<li><code>set yaml/sepc/template/metadata/label/tire:frontend</code></li>
<li><code>kubectl create -f replicaset-defination-1.yaml</code></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orge4b3d9a" class="outline-3">
<h3 id="orge4b3d9a">Taints and Tolerations</h3>
<div class="outline-text-3" id="text-orge4b3d9a">
<p>
BEST PRACTICE: Not to deploy application on MASTER NODE
</p>

<p>
Example:
bug
person
bug-repalent : taints
general bug is INTOLERANT so  taints so they don't get closer to person
after some time: some bugs become TOLERANT TO bug-replanet TAINT
</p>

<p>
Conclusion:
There are two factors where we jugde if bug lands on the person
</p>

<p>
THEY ARE
</p>
<ul class="org-ul">
<li>TAINT     : Is person taint with bug-repalent</li>
<li>TOLARANCE : What is the tolarance of bug for tain (bug repalent )</li>
</ul>

<p>
Summary :
Simillary here the
</p>
<ul class="org-ul">
<li>BUG           : Pod</li>
<li>Person        : Node</li>
<li><p>
Bug-Repalent  : Taint(blue) the node <code>kubectl taint nodes node-name=value:taint-effect</code>
</p>
<ul class="org-ul">
<li>There three taint-effect
<ul class="org-ul">
<li><b>NoSchedule</b>       : Not schedule on node</li>
<li><b>PreferNoSchedule</b> : Will try not to place them in node</li>
<li><b>NoExecute</b>        : New pod will be placed in  node</li>
</ul></li>
</ul>
<p>
-eg: kubectl taint nodes node1 app=blue:NoSchedule
</p>
<pre class="example">
apiVersion:
kind
metadata:
 name: myapp-pod
spec:
  containers:
  - name: nginx-container
    image: nginx
  tolerations:
  key: "app"
  operatior: "Equal"
  value: "blue"
  effect: "NoSchedule"
</pre></li>
<li>Bug-Tolarence : Pod{D, TOLARANCE=blue}</li>
</ul>

<p>
To see the if node is taint or not
kubectl describe node kubemaster | grep Taint  
</p>
</div>
</div>
<div id="outline-container-org38a8b33" class="outline-3">
<h3 id="org38a8b33">Practice Test - Taints and Tolerations</h3>
</div>
<div id="outline-container-orgc156dee" class="outline-3">
<h3 id="orgc156dee">Solution - Taints and Tolerations (Optional)</h3>
<div class="outline-text-3" id="text-orgc156dee">
<ul class="org-ul">
<li>How many Nodes exist on the system
<ul class="org-ul">
<li><code>kubectl get nodes</code></li>
<li><code>kubectl describe node node01</code></li>
<li><code>kubectl describe node node01 | grep -i taint</code></li>
</ul></li>
<li>Create taint on node01 with key of spary value of mortein and effect of NoSchedule
<ul class="org-ul">
<li><code>kubectl taint node node01 sray=mortein:NoScheduler</code></li>
<li><code>kubectl describe node node01 | grep -i taint</code></li>
</ul></li>
<li>Create a pod with image nginx and pod name mosquito
<ul class="org-ul">
<li><code>kubectl run mosquito --image=nginx --restart=Never</code></li>
</ul></li>
<li>What is state of pod ?
<ul class="org-ul">
<li><code>kubectl get pod mosquito</code> get the state</li>
</ul></li>
<li>Why teh pod is in pending state ?
<ul class="org-ul">
<li>Pod (mosquito) doesn't torelate the taint</li>
</ul></li>
<li>Create a pod name bee with nginx image, which has a toleration set to the taint Mortein
<ul class="org-ul">
<li><code>kubectl run mosquito --image=nginx --restart=Never --dry-run -o yaml &gt; bee.yaml</code></li>
<li><code>kubectl expalin pod -recursive | less</code></li>
<li><code>kubectl expalin pod -recursive | grep -A5 tolerations</code></li>
<li><p>
<code>vi bee.yaml</code>
</p>
<pre class="example">
spec:
  tolerations:
  - effect: NoSchedule
    key: spray
    operator: Equal
    value: mortein
#kubectl apply -f bee.yaml
#kubectl get pods
</pre></li>
</ul></li>

<li>What is state of pod ?
<ul class="org-ul">
<li><code>kubectl get pod mosquito</code> get the state</li>
</ul></li>
<li>Do you see taint on master node ?
<ul class="org-ul">
<li><code>kubectl describe nodes master | grep -i taint</code> #&gt;&gt; <code>node-role.kubenetes.io/master:NoSchedule</code></li>
</ul></li>

<li>Remove the taint on master, which currently has taint effect of NoSchedule
<ul class="org-ul">
<li><code>kubectl taint node master node-role.kubernetecis.io/master:NoSchedule-node/master:NoSchedule-</code></li>
</ul></li>
<li>What is state of pod 'mosquito' now ?
<ul class="org-ul">
<li><code>kubectl get nodes</code></li>
</ul></li>
<li>Which node is the POD 'mosquito' on now ?
<ul class="org-ul">
<li><code>kubectl get pods -o wide</code></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgf040df7" class="outline-3">
<h3 id="orgf040df7">Node Selectors</h3>
<div class="outline-text-3" id="text-orgf040df7">
<p>
There are three node cluster :
hig<sub>cpu</sub> : 6 cpu
mid<sub>cpu</sub> : 5 cpu
low<sub>cpu</sub> : 4 cpu
</p>

<p>
There are three pods which are diff min-cpu utilizations
pod-name : min cpu requirement
pod-1    : 1 cpu
pod-2    : 2 cpu
pod-3    : 4 cpu
</p>

<p>
If the pods can be assingned randmally
if
pod-3 (4cpu) utiliztion is assigned to low-cpu (4 cpu) the resouce are in satutarted state (which is not desireable) if there is need for extra resource then then the <b>job run outof resources</b> which is not desireable
To solve this We can set a limitation on the pods so that they only run on particular nodes.
</p>

<ul class="org-ul">
<li><p>
<b>Node Selector</b> :  is using Node selectors which is the simple and easier method with yaml file
</p>
<pre class="example">
#prod-definition.yaml
apiVersion:
kind: Pod
metadata:
  name: myapp-pod
spec:
  containers:
  - name: data-processor
    image: dat-processor
  nodeSelector:
   size: Large
</pre></li>
</ul>


<p>
There are two ways to do this.
</p>
<ul class="org-ul">
<li>Where did the <b>yaml/spec/size:Large</b>  come from ?
How does Kubernetes know which is the large node ?</li>
<li>The key value pair of size and large are infact labels assigned to the nodes. Scheduler uses these labels to match and identify the right node to place the pods.
You must have first labelled your nodes prior to creating this pod.</li>

<li>How we can label the nodes to label ? 
<ul class="org-ul">
<li><code>kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;</code></li>
<li><code>kubectl label nodes node-1 size=Large</code></li>
</ul></li>

<li>Then create the pod <code>kubectl apply -f prod-definition</code>
When the pod is now created it is placed on Node(high-cpu) as we desired <b>Node Selectors</b> served our purpose but it has limitations.
We used a single label and selector to achieve our goal here.</li>

<li>But what if our requirement is much more complex. ?
For example, we would like to say something like place the pod on a large or medium node or something like place the pod on any nodes that are not small.
You cannot achieve this using <b>Node selectors</b> for this <b>Node Affinity</b> and <b>Anti Affinity</b> features were introduced and we will look at that next.</li>
</ul>
</div>
</div>

<div id="outline-container-org8b47623" class="outline-3">
<h3 id="org8b47623">Node Affinity</h3>
<div class="outline-text-3" id="text-org8b47623">
<ul class="org-ul">
<li>The primary purpose of node affinity feature is to ensure that pods are hosted on particular nodes.</li>
<li>In this case to ensure the large data processing pod ends up on no node-01 in the previous section we did using <b>Notes Selectors</b></li>
<li>As we discussed that you cannot provide advanced expressions like
<ul class="org-ul">
<li><b>Large OR Medium</b></li>
<li><b>NOT Small</b>        in <b>Node Selectors</b></li>
</ul></li>
<li>But <b>Node Affinity</b> feature provides us with advanced capabilities to
<ul class="org-ul">
<li>limit pod placement on specific nodes</li>
<li>But <b>Node Affinit</b> is little complex than <b>Node Selector</b> with great power comes great complexity.</li>
</ul></li>
<li>Let give example that we discuss in previous section about and try to implement using <b>Node Affinity</b></li>
</ul>
<pre class="example">
apiVersion:
kind:

metadata:
  name: myapp-pod
spec:

  containers:
    - name: data-processor
      image: data-processor

    affinity:
     nodeAffinity:
	requiremenDuringSchedulingIgnodeDuringExecution:
	  nodeSelectorTerms:
	  - matchExperssions:
	    - key: size
	      operator: In
	      values:
	       - Large 
</pre>

<ul class="org-ul">
<li>The yaml file  we inserted <b>NodeAffinity</b> block at  <b>yaml/sepc/affinity</b> section.    
<ul class="org-ul">
<li>Inside <b>nodAffinity</b> you will see <b>requiremenDuringSchedulingIgnodeDuringExecution</b>  which has <b>NodeSeletorTerm</b>
<ul class="org-ul">
<li><b>NodeSeletorTerm</b> is a array where we specify the key and value pairs
<ul class="org-ul">
<li>The key value pair are  :[matchExperssions[key: size, operator:In, values: Large]
<ul class="org-ul">
<li><b>operator</b> is <b>In</b>  ensures  the <b>pod</b> will be <b>placed</b> on <b>a node</b> whose <b>label[value]=large</b></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>

<li>If you want to palce you pod on <b>large</b> or <b>medium</b> Node then you need to <b>add array<sub>element</sub>[value]=Medium</b> in <b>nodeAffinity</b> will be</li>
</ul>
<pre class="example">
affinity:
 nodeAffinity:
  requiremenDuringSchedulingIgnodeDuringExecution:
   nodeSelectorTerms:
   - matchExperssions:
     - key: size
       operator: In
       values:
	- Large
	- Medium
</pre>

<p>
If you want to place pod any thing except <b>Small Size</b> Node then
</p>
<pre class="example">
affinity:
 nodeAffinity:
  requiremenDuringSchedulingIgnodeDuringExecution:
   nodeSelectorTerms:
   - matchExperssions:
     - key: size
       operator: NotIn
       values:
	- Small
</pre>

<p>
We know that we have only set the labels size too large and medium nodes the smaller nodes don't even have the labels set.
So we don't really have to even check the value of the label as long as we are sure we don't set a label size to the smaller nodes
Then we can use the <b>exists operator</b> which give us same result.
</p>
<pre class="example">
affinity:
 nodeAffinity:
  requiremenDuringSchedulingIgnodeDuringExecution:
   nodeSelectorTerms:
   - matchExperssions:
     - key: size
       operator: Exists
</pre>

<p>
The <b>matchExperssions[operator]=Exists</b> will simply check if the label size exists on the node and you don't need the values section for that as it does not compare the values.
</p>
</div>
<div id="outline-container-orgadd7cb2" class="outline-4">
<h4 id="orgadd7cb2">Diffenent Types of NodeAffinity</h4>
<div class="outline-text-4" id="text-orgadd7cb2">
<p>
If node affinity of pod doesn't match with node label
when the pods are created.
These rules are considered and the pods are placed onto the right nodes.
But what if node affinity could not match a node with a given expression.
</p>


<p>
In this case what if there are no nodes with a label called <b>size</b>
</p>

<p>
say we had the labels and the pods are scheduled.
What if someone changes the label on the node at a future point in time.
Will the pod continue to stay on the Node ?
</p>

<p>
which happens to be the type of node affinity the type of node affinity defines the behaviour of the scheduler with respect to
</p>

<p>
node affinity and the stages in the lifecycle of the pod.
</p>

<ul class="org-ul">
<li>During Defination of <b>nodeAffinity</b> in yaml/sepc/affinity we set the property(behaviour or Types)
There are diffenent NodeAffinity  Types
<ul class="org-ul">
<li>Available 
<ul class="org-ul">
<li><code>requiredDuringSchedulingIgnodeDuringExecution</code></li>
<li><code>preferredDuringSchedulingIgnodeDuringExecution</code></li>
</ul></li>
<li>Planned:
<ul class="org-ul">
<li><code>requiredDuringSchedulingRequiredDuringExection</code></li>
</ul></li>
</ul></li>
</ul>

<p>
In Available there two types
There are two states in the lifecycle of a pod when considering node affinity
</p>
<ul class="org-ul">
<li>during scheduling</li>
<li>during execution</li>
</ul>

<p>
During scheduling:
</p>
<ul class="org-ul">
<li>Is the state where a pod does not exist</li>
<li>Create Pod for the first time and affinity rules specife to place the pods on the right node.</li>

<li>If the nodes with matching labels are not available.
<ul class="org-ul">
<li>Example we forgot to label the node as large.</li>
<li>This where the <b>type of node affinity</b> used comes into play.</li>
</ul></li>
</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">DuringScheduling</th>
<th scope="col" class="org-left">DuringExecution</th>
<th scope="col" class="org-left">type of NodeAffinity</th>
<th scope="col" class="org-left">Descirbe</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">Required</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">Prefereed</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">Ignored</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">Required</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">Type 1</td>
<td class="org-left">Required</td>
<td class="org-left">Ignored</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">Type 2</td>
<td class="org-left">Prefereed</td>
<td class="org-left">Ignored</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">Type 3</td>
<td class="org-left">Required</td>
<td class="org-left">Required</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li><b>Type0fNodeAffinity[DuringScheduling]= Required</b> :
<ul class="org-ul">
<li>Scheduler will mandate that the pod should be placed in spec node if node is not prescent then pod will not be scheduled.
<ul class="org-ul">
<li>This type is used when pod placement is crucial</li>
</ul></li>
<li>If palacement of pod is not mandatory and you need the pod to run the work-loadt hen we go for <b>Prefereed</b></li>
<li>But let's say the pod placement is less important than running the workload itself.</li>
</ul></li>
<li><b>Type0fNodeAffinity[DuringScheduling]= Prefered</b> :
<ul class="org-ul">
<li>Scheduler will Prefer placing the pod match-label in spec node. In case where a matching node is not found.
<ul class="org-ul">
<li>In that case you could set it to preferred and in case where a matching node is not found.</li>
<li>Then scheduler will simply ignore node affinity rules and place the card on any available note.</li>
</ul></li>
<li>This is a way of telling the scheduler: try your best to place the pod on matching node but if you really cannot find one just plays it anywhere.</li>
</ul></li>
</ul>

<p>
The second part of the property (or other state) is <b>DuringExecution</b>
<b>DuringExecution</b> is the state where a pod has been running and a change is made in the environment that affects node affinity such as a change in the label of a node.
</p>

<ul class="org-ul">
<li>For example say an administrator removed the label we said earlier called size equals large from the node.Now what would happen to the pods that are running on the Node. ?</li>
<li>As you can see the two types <b>DuringExecution ={ignore,required}</b> available has this value set too ignored which means</li>
</ul>
<p>
<b>Type0fNodeAffinity[DuringExecution]= ignored</b>
</p>
<ul class="org-ul">
<li>pods will continue to run and any changes in node affinity will not impact them once they are scheduled.</li>
</ul>
<p>
<b>Type0fNodeAffinity[DuringExecution]= Required</b>
</p>
<ul class="org-ul">
<li>any pods that are running on node that do not meet affinity rules will be re-assigned or will be waiting in scheduler(pod is termintated)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org1205fb1" class="outline-3">
<h3 id="org1205fb1">Practice Test - Node Affinity</h3>
<div class="outline-text-3" id="text-org1205fb1">
<p>
<a href="https://uklabs.kodekloud.com/topic/practice-test-node-affinity-3/">https://uklabs.kodekloud.com/topic/practice-test-node-affinity-3/</a>
</p>
</div>
</div>
<div id="outline-container-orga480673" class="outline-3">
<h3 id="orga480673">Solution - Node Affinity (Optional)</h3>
<div class="outline-text-3" id="text-orga480673">
<ul class="org-ul">
<li>What is the value set to the label beta.kubernetecis.io/arch on node01 ?
<ul class="org-ul">
<li><code>kubectl get nodes node01 --show-labels</code></li>
</ul></li>
<li>Apply a label color=blue to node node01
<ul class="org-ul">
<li><code>kubctl label nodes node01 color=blue</code></li>
<li><code>kubectl get nodes node01 --show-labels</code></li>
</ul></li>
<li>Create a new deployment name 'blue' with NGINX image and 6 replica
<ul class="org-ul">
<li><code>kubectl create deployment blue --image=nginx</code></li>
<li><code>kubectl scale deployment blue --replicas=6</code></li>
</ul></li>
<li>Which nodes are pods placed on     
<ul class="org-ul">
<li><code>kubectl get pods -o wide</code></li>
</ul></li>
<li>Set Node Affinity to the depolyment to place the POD on node01 only ?
Name: blue, Replicas:6, Image:nginx, NodeAffinity: requiredDuringSchedulingIgnodeDuringExecution, key:color, value: blue
<ul class="org-ul">
<li><p>
Create a yaml file for existing depolyment[blue]
<code>kubectl get deployments.apps blue -o yaml &gt; blue.yaml</code>
</p>
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: apps/v1
<span style="color: #715ab1;">kind</span>: Deployment
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">annotations</span>:
    <span style="color: #715ab1;">deployment.kubernetes.io/revision</span>: <span style="color: #2d9574;">"1"</span>
  <span style="color: #715ab1;">creationTimestamp</span>: <span style="color: #2d9574;">"2021-10-19T09:19:49Z"</span>
  <span style="color: #715ab1;">generation</span>: 2
  <span style="color: #715ab1;">labels</span>:
    <span style="color: #715ab1;">app</span>: blue
  <span style="color: #715ab1;">name</span>: blue
  <span style="color: #715ab1;">namespace</span>: default
  <span style="color: #715ab1;">resourceVersion</span>: <span style="color: #2d9574;">"746156"</span>
  <span style="color: #715ab1;">uid</span>: dd6b51e0-7e2e-416d-98a0-3155459b51fa
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">affinity</span>:
    <span style="color: #715ab1;">nodeAffinity</span>:
      <span style="color: #715ab1;">requiredDuringSchedulingIgnoredDuringExecution</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">nodeSelectorTerms</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">- matchExpressions</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">  - key</span>: colour
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">    operator</span>: In
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">    values</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span>    - blue    
  <span style="color: #715ab1;">progressDeadlineSeconds</span>: 600
  <span style="color: #715ab1;">replicas</span>: 6
  <span style="color: #715ab1;">revisionHistoryLimit</span>: 10
  <span style="color: #715ab1;">selector</span>:
    <span style="color: #715ab1;">matchLabels</span>:
      <span style="color: #715ab1;">app</span>: blue
  <span style="color: #715ab1;">strategy</span>:
    <span style="color: #715ab1;">rollingUpdate</span>:
      <span style="color: #715ab1;">maxSurge</span>: 25%
      <span style="color: #715ab1;">maxUnavailable</span>: 25%
    <span style="color: #715ab1;">type</span>: RollingUpdate
  <span style="color: #715ab1;">template</span>:
    <span style="color: #715ab1;">metadata</span>:
      <span style="color: #715ab1;">creationTimestamp</span>: <span style="color: #4e3163;">null</span>
      <span style="color: #715ab1;">labels</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">app</span>: blue
    <span style="color: #715ab1;">spec</span>:
      <span style="color: #715ab1;">containers</span>:
      - <span style="color: #715ab1;">image</span>: nginx
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">imagePullPolicy</span>: Always
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">name</span>: nginx
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">resources</span>: {<span style="color: #715ab1;">}</span>
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">terminationMessagePath</span>: /dev/termination-log
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">terminationMessagePolicy</span>: File
      <span style="color: #715ab1;">dnsPolicy</span>: ClusterFirst
      <span style="color: #715ab1;">restartPolicy</span>: Always
      <span style="color: #715ab1;">schedulerName</span>: default-scheduler
      <span style="color: #715ab1;">securityContext</span>: {<span style="color: #715ab1;">}</span>
<span style="color: #715ab1;">      terminationGracePeriodSeconds</span>: 30
<span style="color: #715ab1;">status</span>:
  <span style="color: #715ab1;">availableReplicas</span>: 6
  <span style="color: #715ab1;">conditions</span>:
  - <span style="color: #715ab1;">lastTransitionTime</span>: <span style="color: #2d9574;">"2021-10-19T09:19:49Z"</span>
    <span style="color: #715ab1;">lastUpdateTime</span>: <span style="color: #2d9574;">"2021-10-19T09:19:57Z"</span>
    <span style="color: #715ab1;">message</span>: ReplicaSet <span style="color: #2d9574;">"blue-7bb46df96d"</span> has successfully progressed.
    <span style="color: #715ab1;">reason</span>: NewReplicaSetAvailable
    <span style="color: #715ab1;">status</span>: <span style="color: #2d9574;">"True"</span>
    <span style="color: #715ab1;">type</span>: Progressing
  - <span style="color: #715ab1;">lastTransitionTime</span>: <span style="color: #2d9574;">"2021-10-19T09:20:10Z"</span>
    <span style="color: #715ab1;">lastUpdateTime</span>: <span style="color: #2d9574;">"2021-10-19T09:20:10Z"</span>
    <span style="color: #715ab1;">message</span>: Deployment has minimum availability.
    <span style="color: #715ab1;">reason</span>: MinimumReplicasAvailable
    <span style="color: #715ab1;">status</span>: <span style="color: #2d9574;">"True"</span>
    <span style="color: #715ab1;">type</span>: Available
  <span style="color: #715ab1;">observedGeneration</span>: 2
  <span style="color: #715ab1;">readyReplicas</span>: 6
  <span style="color: #715ab1;">replicas</span>: 6
  <span style="color: #715ab1;">updatedReplicas</span>: 6
</pre>
</div></li>
<li>insert affinity at yaml/spec  get <code>yaml-nodeAffinity</code>  for <a href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/">https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/</a>
<ul class="org-ul">
<li>How to assign pod to a node having a spec: label</li>
</ul></li>
<li>Update the deployment
<ul class="org-ul">
<li><code>kubectl apply -f blue.yaml</code></li>
</ul></li>
<li>Check the pods are created
<ul class="org-ul">
<li><code>kubectl get pods</code> #</li>
</ul></li>
<li>Check which nodes are assigned
<ul class="org-ul">
<li><code>kubectl get pods -o wide</code></li>
</ul></li>
</ul></li>
<li>Create a new deployment [name:red, image:NGINX, replica:3] ensure it gets it placed on the master node only and
master having label: node-role.kuberntes.io/master
<ul class="org-ul">
<li>Hint: key: node-role.kubernetecis.io/master</li>
<li>Create the depolyment with name: red, image:nginx
<ul class="org-ul">
<li><code>kubectl create deployment red --image=nginx  --dry-run=client -o yaml &gt; red.yaml</code>
<ul class="org-ul">
<li><p>
cat red.yaml
</p>
<pre class="example">
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: red
  name: red
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
	nodeSelectorTerms:
	- matchExpressions:
	  - key: colour
	    operator: In
	    values:
	    - blue
  replicas: 3
  selector:
    matchLabels:
      app: red
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
	app: red
    spec:
      containers:
      - image: nginx
	name: nginx
	resources: {}
status: {}
</pre></li>
</ul></li>
</ul></li>
<li>set replia to 3 : in yaml/spec/replicas:3</li>
<li>insert affinity at yaml/spec  get <code>yaml-nodeAffinity</code>  for <a href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/">https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes-using-node-affinity/</a>
<ul class="org-ul">
<li>How to assign pod to a node having a spec: label</li>
</ul></li>
<li>set yaml/spec/affinit/key:node-role.kubernetecis.io/master</li>
<li>set yaml/spec/affinit/operator:Exists</li>
<li>Create deployment 
<ul class="org-ul">
<li><code>kubectl apply -f red.yaml</code></li>
</ul></li>
<li>Check on which node , which pods are deployed</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org7a91bd0" class="outline-3">
<h3 id="org7a91bd0">Exercise: Taints and Tolerations vs Node Affinity: Insert Video</h3>
<div class="outline-text-3" id="text-org7a91bd0">
<p>
Now that we have learned about teens and toleration and no affinity, let us tie together the two concepts through a fun exercise.
</p>

<p>
Aim:
</p>
<ul class="org-ul">
<li>We have three notes and three parts, each in three colors, blue, red and green.The ultimate aim is to place the blue part in the blue note, the red part in the red note.And likewise for Green, we are sharing the same cabinet cluster with other teams.</li>
<li>So there are other parts in the cluster as well as other nodes.</li>
<li>We do not want any other pod to be placed on our note.</li>
<li>Neither do we want our pods to be placed on their notes.</li>
</ul>
<p>
Solutions
</p>
<ul class="org-ul">
<li>Solution: 1
<ul class="org-ul">
<li>Let us first try to solve this problem using teens and toleration as we apply a taint to the notes,marking them with their colours blue, red and green.
And we then set a toleration on the part to tolerate the respective colours. When the parks are now created, the notes ensure they only accept the parts with the right toleration.
So the green part ends up on the green note and the blue part ends up on the blue note. However, teens and toleration does not guarantee that the parts will only prefer these notes.
So the red note ends up on one of the other notes that do not have a taint or toleration set. This is not desired.</li>
</ul></li>
<li>Solutions: 2 
<ul class="org-ul">
<li>Let us try to solve the same problem with no affinity, with no definity, we first labeled the nodes with their respective colors blue, red and green.
We then said no selectors on the part to tie the part to the notes.As such, the pods end up on the right note.
However, that does not guarantee that other parts are not placed on these notes.In this case, there is a chance that one of the other parts may end up on our notes.
This is not something we desired</li>
</ul></li>
<li>Solution 3: 
<ul class="org-ul">
<li>As such a combination of things and toleration and no definitive rules can be used together to completely dedicate notes for specific parts.
We first used tents and colorations to prevent other parts from being placed on our nodes, and then
we use node affinity to prevent our ports from being placed on their nodes.</li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgb074145" class="outline-3">
<h3 id="orgb074145">Resource Requirements and Limits : Insert Images</h3>
<div class="outline-text-3" id="text-orgb074145">
<p>
Let's look at a three Node Kube cluster.
</p>

<p>
Each node has a set of CPU, memory and disk resources available, every part consumes a set of resources,in this case, two CPUs, one memory and some disk space.
</p>

<p>
Whenever a pod is placed on a node, it consumes resources available to that node.
As we have discussed before, it is the cabinet as scheduler that decides which node a part goes to.
</p>

<p>
The scheduler takes into consideration the amount of resources required by a part and those available on the nodes.
In this case, the scheduler schedules a new part on to. If the node has no sufficient resources, the scheduler avoids placing the part on that node, instead
places the part on one where sufficient resources are available.
</p>

<p>
If there is no sufficient resources available on any of the nodes, coordinators hold back scheduling the part, you will see the part in a pending state.
If you look at the events, you will see the reason, insufficient CPU.
</p>

<p>
Let us now focus on the resource requirements for each part.
</p>

<p>
What are these blogs and what are their values by default coordinators assumes that a port or a container within a port requires point five CPU and 256 megabyte of memory.
</p>

<p>
This is known as the resource request for a container, the minimum amount of CPU or memory requested by the container when the scheduler tries to place the port on a note.
</p>

<p>
It uses these numbers to identify a node which has sufficient amount of resources available.
Now, if you know that your application will need more than this, you can modify these values by specifying them in your part of our deployment definition files.
</p>

<p>
In the simple pod definition file, add a section called Resources, under which ad requests and specify the new values for memory and CPU usage.
</p>
</div>



<div id="outline-container-org8821cce" class="outline-4">
<h4 id="org8821cce">Resource Requests</h4>
<div class="outline-text-4" id="text-org8821cce">
<p>
insert this section in pod yaml file below spec/containers/images 
</p>
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">resources</span>:
  <span style="color: #715ab1;">requests</span>:
    <span style="color: #715ab1;">memory</span>: <span style="color: #2d9574;">"1Gi"</span>
    <span style="color: #715ab1;">cpu</span>: <span style="color: #2d9574;">"1"</span>
  <span style="color: #715ab1;">limits</span>:
    <span style="color: #715ab1;">memory</span>: <span style="color: #2d9574;">"2Gi"</span>
    <span style="color: #715ab1;">cpu</span>: <span style="color: #2d9574;">"2"</span>
</pre>
</div>



<p>
In cpu : 0.1 = 100m (milli) min cpu is (1m)
1-cpu
</p>
<ul class="org-ul">
<li>1 aws cpu</li>
<li>1 gcp core</li>
<li>1 Azure core</li>
<li>1 Hyperthread</li>
</ul>

<p>
In Memory:
</p>
<ul class="org-ul">
<li>256 Mi or (268435456)</li>
</ul>

<p>
Differnet Terminology:
1 G (Gigabyte) : 1,000,000,000 bytes
1 M (Megabyte) :     1,000,000 bytes
1 K (Kilobyte) :         1,000 bytes
</p>

<p>
1 Gi (Gibibyte): 1,073,741,824 bytes
1 Mi (Mebibyte):     1,048,576 bytes
1 Ki (Kibibyte):         1,024 bytes
</p>
</div>
</div>
<div id="outline-container-org7524387" class="outline-4">
<h4 id="org7524387">Set Resource Limits to pod</h4>
<div class="outline-text-4" id="text-org7524387">
<p>
By default pod is set to limit of 1 vCpu and 512 Mi
</p>
</div>
</div>
<div id="outline-container-orge3d5552" class="outline-4">
<h4 id="orge3d5552">Exceed Limits</h4>
<div class="outline-text-4" id="text-orge3d5552">
<p>
What happends when the pod uses more resources(cpu) than the limit set ?
</p>
<ul class="org-ul">
<li>In case of cpu:  kubernetecis <b>THROTTLE</b> cpu so the it will not go beyond the limit a container don't go beyond the limit.
<ul class="org-ul">
<li>A container can't use it's cpu beyond the limit</li>
</ul></li>

<li>In case of memory:
A pod can use more memory than the limit
<ul class="org-ul">
<li>If a pod uses more memory than the limit constantly then the pod is <b>terminated</b>.</li>
</ul></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgcf9de31" class="outline-3">
<h3 id="orgcf9de31">Note on default resource requirements and limits</h3>
<div class="outline-text-3" id="text-orgcf9de31">
</div>
</div>
<div id="outline-container-org7c3633d" class="outline-3">
<h3 id="org7c3633d">A quick note on editing PODs and Deployments</h3>
<div class="outline-text-3" id="text-org7c3633d">
</div>
<div id="outline-container-org0bd32f7" class="outline-4">
<h4 id="org0bd32f7">A quick note on editing PODs and Deployments</h4>
<div class="outline-text-4" id="text-org0bd32f7">
</div>
<ul class="org-ul">
<li><a id="org0999483"></a>Edit a POD<br />
<div class="outline-text-5" id="text-org0999483">
<p>
Remember, you CANNOT edit specifications of an existing POD other than the below.
</p>
<ul class="org-ul">
<li>spec.containers[*].image</li>
<li>spec.initContainers[*].image</li>
<li>spec.activeDeadlineSeconds</li>
<li>spec.tolerations</li>
</ul>

<p>
For example you cannot edit the environment variables, service accounts, resource limits (all of which we will discuss later) of a running pod. But if you really want to, you have 2 options:
</p>

<ul class="org-ul">
<li>Run the <code>kubectl edit pod &lt;pod name&gt;</code> command.  This will open the pod specification in an editor (vi editor). Then edit the required properties. When you try to save it, you will be denied. This is because you are attempting to edit a field on the pod that is not editable.
<ul class="org-ul">
<li>A copy of the file with your changes is saved in a temporary location as shown above.</li>
<li>You can then delete the existing pod by running the command:</li>
<li><code>kubectl delete pod webapp</code></li>
<li>Then create a new pod with your changes using the temporary file</li>
<li><code>kubectl create -f /tmp/kubectl-edit-ccvrq.yaml</code></li>
</ul></li>
<li>The second option is to extract the pod definition in YAML format to a file using the command
<ul class="org-ul">
<li><code>kubectl get pod webapp -o yaml &gt; my-new-pod.yaml</code></li>
<li>Then make the changes to the exported file using an editor (vi editor). Save the changes
<ul class="org-ul">
<li><code>vi my-new-pod.yaml</code></li>
</ul></li>
<li>Then delete the existing pod
<ul class="org-ul">
<li><code>kubectl delete pod webapp</code></li>
</ul></li>
<li>Then create a new pod with the edited file
<ul class="org-ul">
<li><code>kubectl create -f my-new-pod.yaml</code></li>
</ul></li>
</ul></li>
</ul>
</div>
</li>
<li><a id="org26e2df0"></a>Edit Deployments<br />
<div class="outline-text-5" id="text-org26e2df0">
<p>
With Deployments you can easily edit any field/property of the POD template. Since the pod template is a child of the deployment specification,  with every change the deployment will automatically delete and create a new pod with the new changes. So if you are asked to edit a property of a POD part of a deployment you may do that simply by running the command  <code>kubectl edit deployment my-deployment</code> 
</p>
</div>
</li>
</ul>
</div>
</div>
<div id="outline-container-org6835afd" class="outline-3">
<h3 id="org6835afd">Practice Test - Resource Requirements and Limits</h3>
<div class="outline-text-3" id="text-org6835afd">
<p>
Practice Test: <a href="https://uklabs.kodekloud.com/topic/practice-test-resource-limits-2/">https://uklabs.kodekloud.com/topic/practice-test-resource-limits-2/</a>
</p>
</div>
</div>
<div id="outline-container-org926faa6" class="outline-3">
<h3 id="org926faa6">Solution: Resource Limits : (Optional)</h3>
<div class="outline-text-3" id="text-org926faa6">
<ul class="org-ul">
<li>A pod named 'rabbit' is deployed. Identify the cpu requirement set on the pod ?
<ul class="org-ul">
<li>Get the name of pod for all pods in cluster</li>
<li><code>kubectl get pods</code></li>
<li>Describe the pod</li>
<li><code>kubectl describe pod rabbit</code></li>
<li>Search for cpu-stres/Requests and cpu-stress/Limits in descirbe</li>
</ul></li>
<li>Delete the pod name rabbit
<ul class="org-ul">
<li>kubectl delete pod rabbit</li>
</ul></li>
<li>Inspect the pod <b>elephant</b> and identify the status.
<ul class="org-ul">
<li><code>kubectl get pods</code> check the status: ans (CrashLoopBackOff)</li>
<li><code>kubectl describe pod elephant</code>  Check <b>State</b>, <b>Reason</b>
<ul class="org-ul">
<li>Reason: OOMKilled  which means OUT OF Memory</li>
</ul></li>
</ul></li>
<li>The staus 'OOMKilled' indicates that pod ran out of memory. Identify the memory limit set on the POD.
<ul class="org-ul">
<li><code>kubectl describe pod elephant</code>  Check <b>Limit</b>
<ul class="org-ul">
<li>Limits: memory: 10 Mi, Requested: 5Mi</li>
</ul></li>
</ul></li>
<li>The Elephant runs a process that consume 15 Mi of memory. Increase the limit of the elephant pod to 20 Mi
Delete and recreate the pod if required. Do not modify anything other than the required fields
<ul class="org-ul">
<li>Create a yaml file from running pod[elephant]
<ul class="org-ul">
<li><code>kubectl get pod elephant -o yaml &gt;elephant.yaml</code></li>
<li><code>nano elephant.yaml</code></li>
</ul></li>
<li>set elephant.yaml/spec/container/resources/limits/memory:20Mi</li>
<li>Delete the existing pod
<ul class="org-ul">
<li><code>kubectl delete pod elephant</code></li>
</ul></li>
<li>Create new pod
<ul class="org-ul">
<li><code>kubectl create -f elephant.yaml</code></li>
</ul></li>
<li>Check the memory limit and status of pod if it is launched</li>
</ul></li>
<li>Delete the 'elephant' Pod.
<ul class="org-ul">
<li><code>kubectl delete pod elephant</code></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9e9d775" class="outline-3">
<h3 id="org9e9d775">DaemonSets</h3>
<div class="outline-text-3" id="text-org9e9d775">
<p>
So far, we have deployed various parts on different nodes in our cluster with the help of replica sets and deployments, we made sure multiple copies of our applications are made available across various different worker nodes.
</p>
<pre class="example">
$kubectl get pods -o wide
</pre>
<p>
But Demon sets are like replica sets, as in it helps you deploy multiple instances of pot, but it runs one copy of your pod on each node in your cluster.
</p>

<p>
Whenever a new node is added to the cluster,
</p>
<ul class="org-ul">
<li>a replica of the pod is automatically added to that node.</li>
<li>And when a node is removed, the pod is automatically removed.</li>
<li>The demonset ensures that one copy of the pod is always present in all nodes in the cluster.</li>
</ul>

<p>
Advantages and used cases of Demonset:  
</p>
<ul class="org-ul">
<li><b>Monitoring agent</b> you would like to deploy a monitoring agent or log collector on each of your nodes in the cluster so you can monitor your cluster better.
A demon set is perfect for that, as it can deploy your monitoring agent in the form of a pod in all the nodes in your cluster.
Then you don't have to worry about adding or removing monitoring agents from these nodes when there are changes in your cluster, as the demon said, will take care of that for you.</li>
<li><b>Kubeproxy</b> We learned that one of the worker node components that is required on every node in the cluster is a Kube proxy.
That is one good use case of demon sets.
The kube proxy component can be deployed as a demon said in the cluster.</li>
<li>Another use case is for networking. Networking solutions like <a href="https://www.weave.works/">Weave</a> requires an agent to be deployed on each node in the cluster.</li>
</ul>
</div>

<div id="outline-container-org95dba45" class="outline-4">
<h4 id="org95dba45">Demonset Definition</h4>
<div class="outline-text-4" id="text-org95dba45">
<p>
Demonset Definitoin(yaml) is similar to the replica set Definition.
</p>

<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">filename: daemon-set-definition.yaml</span>
<span style="color: #715ab1;">apiVersion</span>: apps/v1
<span style="color: #715ab1;">kind</span>: DaemonSet
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">labels</span>:
    <span style="color: #715ab1;">app</span>: my-nginx
  <span style="color: #715ab1;">name</span>: my-nginx-daemonset
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">selector</span>:
    <span style="color: #715ab1;">matchLabels</span>:
      <span style="color: #715ab1;">app</span>: my-nginx
  <span style="color: #715ab1;">template</span>:
    <span style="color: #715ab1;">metadata</span>:
      <span style="color: #715ab1;">labels</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">app</span>: my-nginx
    <span style="color: #715ab1;">spec</span>:
      <span style="color: #715ab1;">containers</span>:
      - <span style="color: #715ab1;">image</span>: nginx
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">name</span>: nginx
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">ports</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">- containerPort</span>: 80
</pre>
</div>

<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">filename: replicaset-definition.yaml</span>
<span style="color: #715ab1;">apiVersion</span>: apps/v1
<span style="color: #715ab1;">kind</span>: ReplicaSet
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">labels</span>:
    <span style="color: #715ab1;">app</span>: my-nginx
  <span style="color: #715ab1;">name</span>: my-nginx-replica
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">replica</span>: 1
  <span style="color: #715ab1;">selector</span>:
    <span style="color: #715ab1;">matchLabels</span>:
      <span style="color: #715ab1;">app</span>: my-nginx
  <span style="color: #715ab1;">template</span>:
    <span style="color: #715ab1;">metadata</span>:
      <span style="color: #715ab1;">labels</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">app</span>: my-nginx
    <span style="color: #715ab1;">spec</span>:
      <span style="color: #715ab1;">containers</span>:
      - <span style="color: #715ab1;">image</span>: nginx
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">name</span>: nginx
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">ports</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">- containerPort</span>: 80
</pre>
</div>

<pre class="example">
# create the daemonset
kubectl create -f daemon-set-definition.yaml
# View the daemonset 
kubectl get daemonsets
# Inspect the daemonset
kubectl describe daemonset monitoring-daemon 
</pre>
</div>
</div>
<div id="outline-container-org0b60e7f" class="outline-4">
<h4 id="org0b60e7f">How does it work ?</h4>
<div class="outline-text-4" id="text-org0b60e7f">
<p>
How does it schedule part on each node and how does it ensure that every node has a pod?
If you were asked to schedule a part on each node in the cluster, how would you do it?
</p>

<p>
In one of the previous lectures in this section, we discussed that we could set the node name properly on the pod to bypass the scheduler and get the part placed on a node directly.
</p>

<p>
So that's one approach on each part, said the node name, property and its specification before it is created.
And when they are created, they automatically land on the respective Node. So that's how it used to be until version 1.0 12
</p>

<p>
from version 1.0 12 onwards, the demonset uses the default scheduler and node affinity rules that we learned in one of the previous lectures to schedule part on node.
</p>
</div>
</div>
</div>

<div id="outline-container-orge70c4c7" class="outline-3">
<h3 id="orge70c4c7">Practice Test - DaemonSets</h3>
<div class="outline-text-3" id="text-orge70c4c7">
<p>
Practice Test: <a href="https://uklabs.kodekloud.com/topic/practice-test-daemonsets-2/">https://uklabs.kodekloud.com/topic/practice-test-daemonsets-2/</a>
</p>
</div>
</div>
<div id="outline-container-org84ba788" class="outline-3">
<h3 id="org84ba788">Solution - DaemonSets (optional)</h3>
<div class="outline-text-3" id="text-org84ba788">
<ul class="org-ul">
<li>How many DaemonSets are created in cluster in all namespaces?
<ul class="org-ul">
<li><code>kubectl get ds --all-namespaces</code></li>
</ul></li>
<li>Which namespace are the DaemonSet created in ?
<ul class="org-ul">
<li><code>kubectl get ds --all-namespaces</code> get the namespace: kube-system</li>
</ul></li>
<li>Which of below is DaemonSet ?
<ul class="org-ul">
<li><code>kubectl get ds --all-namespaces</code> check the name of daemonset</li>
</ul></li>
<li>How may nodes are the pods scheduled by DaemonSet kube-proxy ?
<ul class="org-ul">
<li><code>kubectl get nodes</code></li>
<li><code>kubectl get pods -n kube-system -o wide | grep proxy</code></li>
</ul></li>
<li>What is the image used by pod deployed by weave-net DaemonSet?
<ul class="org-ul">
<li><code>kubectl describe ds weave-net | grep -i image</code></li>
</ul></li>
<li>Deploy a DaemonSet for FluentDLogging
<ul class="org-ul">
<li>search for DaemonSet for FluentDlogging <a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/">https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/</a></li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: apps/v1
<span style="color: #715ab1;">kind</span>: DaemonSet
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: fluentd-elasticsearch
  <span style="color: #715ab1;">namespace</span>: kube-system
  <span style="color: #715ab1;">labels</span>:
    <span style="color: #715ab1;">k8s-app</span>: fluentd-logging
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">selector</span>:
    <span style="color: #715ab1;">matchLabels</span>:
      <span style="color: #715ab1;">name</span>: fluentd-elasticsearch
  <span style="color: #715ab1;">template</span>:
    <span style="color: #715ab1;">metadata</span>:
      <span style="color: #715ab1;">labels</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">name</span>: fluentd-elasticsearch
    <span style="color: #715ab1;">spec</span>:
      <span style="color: #715ab1;">tolerations</span>:
      <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">this toleration is to have the daemonset runnable on master nodes</span>
      <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">remove it if your masters can't run pods</span>
      - <span style="color: #715ab1;">key</span>: node-role.kubernetes.io/master
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">operator</span>: Exists
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">effect</span>: NoSchedule
      <span style="color: #715ab1;">containers</span>:
      - <span style="color: #715ab1;">name</span>: fluentd-elasticsearch
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">image</span>: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">resources</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">  limits</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">    memory</span>: 200Mi
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">  requests</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">    cpu</span>: 100m
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">    memory</span>: 200Mi
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">volumeMounts</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">- name</span>: varlog
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">  mountPath</span>: /var/log
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">- name</span>: varlibdockercontainers
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">  mountPath</span>: /var/lib/docker/containers
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">  readOnly</span>: <span style="color: #4e3163;">true</span>
      <span style="color: #715ab1;">terminationGracePeriodSeconds</span>: 30
      <span style="color: #715ab1;">volumes</span>:
      - <span style="color: #715ab1;">name</span>: varlog
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">hostPath</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">  path</span>: /var/log
      - <span style="color: #715ab1;">name</span>: varlibdockercontainers
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">hostPath</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">  path</span>: /var/lib/docker/containers
</pre>
</div>
</div>
</div>
<div id="outline-container-org43194a9" class="outline-3">
<h3 id="org43194a9">Static Pods</h3>
<div class="outline-text-3" id="text-org43194a9">
<p>
Kubernetes Architechture: insert image
</p>

<p>
Q) What if you want to run the pod on worker-node  with no master-node not part of any cluster ?
The one thing that the kubelet knows to do is create PODs. But we dont have an API server here to provide POD details.
By now we know that to create a POD you need the details of the POD in a pod-definition.yaml file. But
</p>

<p>
Q)How do you provide a pod definition file to the kubelet without a kube-api server ? 
</p>
<ul class="org-ul">
<li>You can configure the kubelet to read the pod definition files from a directory on the server designated to store information about pods.</li>
<li>Place the  pods definition files in dir: <code>/etc/kuberentes/manifests</code>.</li>
<li>Kubelet periodically checks this directory for files reads these files and creates pods on the host.</li>
<li>Not only does it create the pod, but it can ensure that the pod stays alive.
<ul class="org-ul">
<li>If the application crashes, the kubelet attempts to restart it.</li>
</ul></li>
<li>If you make a change to any of the file within this directory, the kubelet recreates the pod for those changes to take effect.</li>
<li>If you remove a file from this directory the part is deleted automatically.</li>
</ul>

<p>
So these PODs that are created by the kubelet on its own without the intervention from the API server or rest of the kuberentes cluster components are known as <b>Static PODs</b>.
</p>

<p>
#NOTE:
NOTE: 
Remember you can only create PODs this way.
You cannot create replicasets or deployments or services by placing a definition file in the designated directory.
</p>


<p>
They are all concepts part of the whole Kubernetes architecture, that requires other control plane components like the replication and deployment controllers etc. The kubelet works at a POD level and can only understand PODs. Which is why it is able to create static pods this way.
</p>

<p>
Q) So what is that designated folder and how do you configure it.
</p>
<ul class="org-ul">
<li>There are two ways
<ul class="org-ul">
<li>give file-path during creating or run time   
<ul class="org-ul">
<li>It could be any directory on the host. And the location of that directory is passed in to the kubelet as a option while creating(run) the service.</li>
<li>The option is <b>pod-manifest-path</b> = <code>--pod-manifest-path=/etc/Kubernetes/manifests</code></li>
</ul></li>
</ul></li>
</ul>

<pre class="example">
# kubelet.service
ExecStart=/usr/local/bin/kubelet \\
--config=/var/lib/kubelet/kubelet-config.yaml \\
--container-runtime=remote \\
--pod-manifest-path=/etc/Kubernetes/manifests \\
--container-runtime-endpoint=unix:///var/run/containerd/containerd.sock \\
--image-pull-progress-deadline=2m \\
--kubeconfig=/var/lib/kubelet/kubeconfig \\
--network-plugin=cni \\
--regis
</pre>

<ul class="org-ul">
<li>give file-path in a config.yaml file
<ul class="org-ul">
<li>Create a config.yaml file for kubelet while create kubelet service
<ul class="org-ul">
<li><b>config</b> = <code>/var/lib/kubelet/kubelet-config.yaml</code></li>
</ul></li>
</ul></li>
</ul>
<pre class="example">
# kubelet.service
ExecStart=/usr/local/bin/kubelet \\
--config=/var/lib/kubelet/kubelet-config.yaml \\
--container-runtime=remote \\
--pod-manifest-path=/etc/Kubernetes/manifests \\
--container-runtime-endpoint=unix:///var/run/containerd/containerd.sock \\
--image-pull-progress-deadline=2m \\
--kubeconfig=/var/lib/kubelet/kubeconfig \\
--network-plugin=cni \\
--regis
</pre>
<ul class="org-ul">
<li>Insert the the file-path in <code>kube-config.yaml</code>
<ul class="org-ul">
<li>Instead of specifying the option directly in the kubelet.service file, you could provide a path to another config file using the config option, and define the directory path as <b>staticPodPath</b> in that file.</li>
</ul></li>
</ul>
<pre class="example">
#filename: kube-config.yaml
staticPodPath: /etc/kubernetes/manifest....yaml
</pre>

<ul class="org-ul">
<li>Q) How to view which pod is running
Once the satic pod is creaed you can view them with <code>docker ps</code>
Since we dont have an API server now, no kubectl utility. which is why we're using the docker command.</li>

<li>Q) So then how does it work when the node is part of a cluster. When there is an API server requesting the Kubelet to create pods. ?
Can the kubelet create both kinds of PODs at the same time? Well, the way the kubelet works is it can take in requests for creating parts from different inputs.
<ul class="org-ul">
<li>From static folder :
<ul class="org-ul">
<li>The first is through the POD definition files from the static pods folder, as we just saw.</li>
</ul></li>
<li>From HTTP API endpoint:
<ul class="org-ul">
<li>The second, is through an HTTP API endpoint. And that is how the kube-apiserver provides input to kubelet. The kubelet can create both kinds of PODs  the staticpods and the ones from the api server - at the same time.</li>
</ul></li>
</ul></li>
<li>Q) Well,in that case is the API server aware of the static pods created by the kubelet?
<ul class="org-ul">
<li>Yes it is.</li>
<li><p>
If you run the kubectl get pods command on the master node, the static pods will be listed as any other pod.
</p>
<div class="org-src-container">
<pre class="src src-sh"><span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubectl get pods </span>
NAME                READY    STATUS               RESTART   AGE
static-web-node01   0/1      ContainerCreating    0         29s
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">Note that the name of the pod =static-web-node01= is automatically appended with the =node name=.</span>
</pre>
</div></li>
</ul></li>
<li><p>
Q) How master-node know about static-pod ? When the kubelet creates a static pod ?
if it is part of a cluster, it also creates a mirror object in the kubeapi server.
</p>

<p>
What you see from the kube-apiserver is just a read only mirror of the pod. You can <code>view details</code> about the pod but <code>you cannot edit or delete</code> it like the usual parts.
You can only delete them by modifying the files from the nodes manifest folder.
</p></li>

<li>Q) In the case node01, So then why would you want to use Static PODs?
<ul class="org-ul">
<li>Static pods are not dependent on the Kubernetes control plane, you can use static pods to deploy the control plane components itself as pods on a node.
Start by installing kubelet on all the master nodes.
Then create pod definition files that uses Docker images of the various control plane components such as the api server, controller, etcd etc.
Place the definition files in the designated manifests folder. And kubelet takes care of deploying the control plane components themselves as PODs on the cluster.
This way you don't have to download the binaries configure services or worry about so the service is crashing.
If any of these services were to crash since it's a static pod it will automatically be restarted by the kubelet. Neat and simple.</li>
<li>Thats how the kubeadmin tool sets up a Kubernetes cluster.
Which is why when you list the pods in the kube-system namespace, you see the control plane components as PODs in a cluster setup by the kubeadmin tool.</li>
</ul></li>
<li><p>
Q) Different between Static PODs and DaemonSets.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Static PODs</th>
<th scope="col" class="org-left">DaemonSet</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Created by Kubelet</td>
<td class="org-left">Created by Kube-API server(DaemonSet Contorller)</td>
</tr>

<tr>
<td class="org-left">Deploy Contorl Plane compoents as Static Pods</td>
<td class="org-left">Deploy Monitoring Agents, Logging Agents on nodes</td>
</tr>

<tr>
<td class="org-left">Both are ignored by Kube-scheduler</td>
<td class="org-left">Both are ignored by Kube-scheduler</td>
</tr>
</tbody>
</table>

<ul class="org-ul">
<li>DaemonSets as we saw earlier are used to ensure one instance of an application is available on all nodes in the cluster. It is handled by a daemonset controller through the kube-api server.</li>
<li>Whereas static pods, as we saw in this lecture, are created directly by the kubelet without any interference from the</li>
<li>kube-api server or rest of the Kubernetes control plane components. Static pods can be used to deploy the Kubernetes control plane components itself.</li>
</ul></li>
<li>Both static pods and pods created by daemonsets are ignored by the kube-scheduler. The kube-scheduler has no affect on these pods.</li>
</ul>
</div>
</div>
<div id="outline-container-orgd410249" class="outline-3">
<h3 id="orgd410249">Practice Test - Static Pods</h3>
<div class="outline-text-3" id="text-orgd410249">
<p>
Practice Test Link: <a href="https://uklabs.kodekloud.com/topic/practice-test-static-pods-2/">https://uklabs.kodekloud.com/topic/practice-test-static-pods-2/</a>
</p>
</div>
</div>
<div id="outline-container-org7f6d9d5" class="outline-3">
<h3 id="org7f6d9d5">Solution - Static Pods (Optional)</h3>
<div class="outline-text-3" id="text-org7f6d9d5">
<ul class="org-ul">
<li>Q) How many Static pods exist in the cluster in all namespaces?
<ul class="org-ul">
<li>A) <code>Kubectl get pods --all-namespace</code>
<ul class="org-ul">
<li>For Static pods the <code>node-name</code> to the end of pod-name since current node host-name or node is <code>master</code> we should search for pod ending with <code>master</code></li>
<li><code>Kubectl get pods --all-namespace | grep "\-master" | wc - l</code></li>
</ul></li>
</ul></li>
<li>Q) Which below components is NOT deployed as a static pod ?
<ul class="org-ul">
<li>A)</li>
</ul></li>
<li>Q) Which of the below is NOT deployed as a static pod ?</li>
<li>Q) On what nodes are static pods created ?
<ul class="org-ul">
<li>A) get all pods and at which node they have been deployed
<ul class="org-ul">
<li><code>kubectl get pods --all-namespaces -o wide</code></li>
</ul></li>
</ul></li>
<li>Q) What is the path of dir holding static pod definition files ?
<ul class="org-ul">
<li>A) search for process of kubelet and get the conf-dir in describtion
<ul class="org-ul">
<li><code>ps -ef | grep kubelet | grep ".yaml"</code></li>
<li>Need to search for <code>staticPodPath</code> in <code>config.yaml</code> and get the dir of static pod which is <code>/etc/kubernetes/manifests</code></li>
</ul></li>
</ul></li>
<li>Q) How many pods are definition files are present in the manifests folder
<ul class="org-ul">
<li><code>cd /etc/kuberentes/manifests; ls |wc -l</code></li>
</ul></li>
<li>Q) What is the docker image used to deploy the kube-api server as a static pod ?
<ul class="org-ul">
<li>A) <code>cd /etc/kuberentes/manifests; grep -i image kube-apiserver:v1.16.0</code></li>
</ul></li>

<li>Q) Create a static pod name static-bussybox that uses the bussybox image and the command sleep 1000
<ul class="org-ul">
<li>A) Create a yaml file for image bussybox
<ul class="org-ul">
<li><code>cd ${static-pod-config-path}   ; kubectl run static-busybox --image=busybox --command sleep 1000 --restart=Never --dry-run -o yaml &gt; static-bussybox.yaml</code></li>
<li>check if static pod is created and running <code>kubectl get pods</code></li>
</ul></li>
</ul></li>

<li>Q) Edit image on static pod to use busybox:1.28.4
<ul class="org-ul">
<li>A) <code>cd ${static-pod-config-path}; vi static-busybox.yaml</code>
<ul class="org-ul">
<li>Repalce yaml/spec/containers/image:bussybox to bussybox:1.28.4</li>
</ul></li>
</ul></li>
<li>Q) We just created a new static pod name static-greenbox. Find it and delete it
<ul class="org-ul">
<li>A) Check if pod is created or running <code>kubctl get pods</code>
<ul class="org-ul">
<li>At which node the static pod is created ?
<ul class="org-ul">
<li><code>kubectl get pod</code> pod-name suffix : in this case NODE:node01</li>
</ul></li>
<li>SSH into node01
<ul class="org-ul">
<li>Get internal ip address
<ul class="org-ul">
<li><code>kubectl get node node01 -o wide</code></li>
<li><code>ssh ip_address</code></li>
</ul></li>
</ul></li>
<li>Get the static pod config dir in node01
<ul class="org-ul">
<li><code>ps -ef | grep kubelet | grep "\--config"</code> Get the config file</li>
<li><code>grep -i static /var/lib/kubelet/config.yaml</code> Search for  static-pod dir</li>
<li><code>#staticPodPath: /etc/just-to-mess-wth-you</code> This is the dir of static pod</li>
</ul></li>
<li>Search for static-greenbox and delete the file for dir this will remove the pod
<ul class="org-ul">
<li><code>rm -rf greenbox.yaml</code></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org87c4364" class="outline-3">
<h3 id="org87c4364">Multiple Schedulers</h3>
<div class="outline-text-3" id="text-org87c4364">
<p>
In Scheduler section we have discuss about 
</p>
<ul class="org-ul">
<li>different ways of manually scheduling a POD on a node.</li>
<li>how to view scheduler related events.</li>
<li>how the default-scheduler works</li>
<li>Scheduler algorithum : taints &amp; tolerantions, nodeaffinity</li>
</ul>
</div>
<div id="outline-container-org91ad84e" class="outline-4">
<h4 id="org91ad84e">Why you need Multiple Scheduler</h4>
<div class="outline-text-4" id="text-org91ad84e">
<p>
What if none of these satisfies your needs?
</p>

<p>
For example you have a specific application that requires its components to be placed on nodes after performing some additional checks. So you decide to have your own scheduling algorithm to place pods on nodes
So that you can add your own custom conditions and checks in it. Kubernetes is highly extensible.
</p>
</div>
</div>
<div id="outline-container-org8959787" class="outline-4">
<h4 id="org8959787">How to create Mulitple Scheduler</h4>
<div class="outline-text-4" id="text-org8959787">
<p>
You can write your own kubernetes scheduler program, package it and deploy it as the default scheduler or as an additional scheduler in the kubernetes cluster.
That way all of the other applications can go through the default scheduler,
</p>

<p>
however one specific application can use your custom scheduler. Your kubernetes cluster can have multiple  schedulers at the same time.
</p>

<p>
When creating a POD or a Deployment you can instruct kubernetes to have the POD scheduled by a specific scheduler.
</p>
</div>
</div>

<div id="outline-container-org0594a5e" class="outline-4">
<h4 id="org0594a5e">Deploy custome kube-scheduler</h4>
<div class="outline-text-4" id="text-org0594a5e">
<p>
There are two way to create custom scheduler
</p>
<ul class="org-ul">
<li>deploy using binary</li>
<li>deploy using kubeadm or yaml file</li>
</ul>
</div>
<ul class="org-ul">
<li><a id="org54dabf6"></a>Deploy using Binary file<br />
<div class="outline-text-5" id="text-org54dabf6">
<p>
Earlier Section we saw how to deploy the kube-scheduler using binary
</p>
<ul class="org-ul">
<li>We download the kube-scheduler binary <code>wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler</code></li>
<li>run it as a service with a set of options
<ul class="org-ul">
<li>one of option is <code>--scheduler-name=my-custom-scheduler</code> if not specified the it take <code>default-scheduler</code> as it's name</li>
</ul></li>
</ul>

<pre class="example">
# # install kube-schedule
wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler

# DEFAULT SCHEDULER kube-scheduler.service
ExecStart=/usr/local/bin/kube-scheduler \\
--config=/etc/kubernetes/config/kube-scheduler.yaml \\
--scheduler-name=default-scheduler \\


# CUSTOM SCHEDULER kube-scheduler.service
ExecStart=/usr/local/bin/kube-scheduler \\
--config=/etc/kubernetes/config/kube-scheduler.yaml \\
--scheduler-name=my-custom-scheduler

</pre>
</div>
</li>

<li><a id="org530d3cc"></a>Deploy using kubeadm<br />
<div class="outline-text-5" id="text-org530d3cc">
<p>
Default scheduler 
</p>
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">default scheduler: /etc/kubernetes/manifiests/kube-scheduler.yaml</span>
<span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Pod
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">creationTimestamp</span>: <span style="color: #4e3163;">null</span>
  <span style="color: #715ab1;">labels</span>:
    <span style="color: #715ab1;">component</span>: kube-scheduler
    <span style="color: #715ab1;">tier</span>: control-plane
  <span style="color: #715ab1;">name</span>: kube-scheduler
  <span style="color: #715ab1;">namespace</span>: kube-system
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">containers</span>:
  - <span style="color: #715ab1;">command</span>:
    - kube-scheduler
    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/scheduler.conf
    - --leader-elect=true
    - --port=0
    <span style="color: #715ab1;">image</span>: k8s.gcr.io/kube-scheduler:v1.22.2
    <span style="color: #715ab1;">imagePullPolicy</span>: IfNotPresent
    <span style="color: #715ab1;">livenessProbe</span>:
      <span style="color: #715ab1;">failureThreshold</span>: 8
      <span style="color: #715ab1;">httpGet</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">host</span>: 127.0.0.1
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">path</span>: /healthz
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">port</span>: 10259
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">scheme</span>: HTTPS
      <span style="color: #715ab1;">initialDelaySeconds</span>: 10
      <span style="color: #715ab1;">periodSeconds</span>: 10
      <span style="color: #715ab1;">timeoutSeconds</span>: 15
    <span style="color: #715ab1;">name</span>: kube-scheduler
    <span style="color: #715ab1;">resources</span>:
      <span style="color: #715ab1;">requests</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">cpu</span>: 100m
    <span style="color: #715ab1;">startupProbe</span>:
      <span style="color: #715ab1;">failureThreshold</span>: 24
      <span style="color: #715ab1;">httpGet</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">host</span>: 127.0.0.1
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">path</span>: /healthz
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">port</span>: 10259
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">scheme</span>: HTTPS
      <span style="color: #715ab1;">initialDelaySeconds</span>: 10
      <span style="color: #715ab1;">periodSeconds</span>: 10
      <span style="color: #715ab1;">timeoutSeconds</span>: 15
    <span style="color: #715ab1;">volumeMounts</span>:
    - <span style="color: #715ab1;">mountPath</span>: /etc/kubernetes/scheduler.conf
      <span style="color: #715ab1;">name</span>: kubeconfig
      <span style="color: #715ab1;">readOnly</span>: <span style="color: #4e3163;">true</span>
  <span style="color: #715ab1;">hostNetwork</span>: <span style="color: #4e3163;">true</span>
  <span style="color: #715ab1;">priorityClassName</span>: system-node-critical
  <span style="color: #715ab1;">securityContext</span>:
    <span style="color: #715ab1;">seccompProfile</span>:
      <span style="color: #715ab1;">type</span>: RuntimeDefault
  <span style="color: #715ab1;">volumes</span>:
  - <span style="color: #715ab1;">hostPath</span>:
      <span style="color: #715ab1;">path</span>: /etc/kubernetes/scheduler.conf
      <span style="color: #715ab1;">type</span>: FileOrCreate
    <span style="color: #715ab1;">name</span>: kubeconfig
<span style="color: #715ab1;">status</span>: {}

</pre>
</div>
<p>
Custom Scheduler
</p>
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Pod
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">creationTimestamp</span>: <span style="color: #4e3163;">null</span>
  <span style="color: #715ab1;">labels</span>:
    <span style="color: #715ab1;">component</span>: kube-scheduler
    <span style="color: #715ab1;">tier</span>: control-plane
  <span style="color: #715ab1;">name</span>: kube-scheduler
  <span style="color: #715ab1;">namespace</span>: kube-system
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">containers</span>:
  - <span style="color: #715ab1;">command</span>:
    - kube-scheduler
    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/scheduler.conf
    - --leader-elect=true
    - --port=0
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">###############################################</span>
    - --scheduler-name=my-custome-scheduler
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">##########################################33</span>
    <span style="color: #715ab1;">image</span>: k8s.gcr.io/kube-scheduler:v1.22.2
    <span style="color: #715ab1;">imagePullPolicy</span>: IfNotPresent
    <span style="color: #715ab1;">livenessProbe</span>:
      <span style="color: #715ab1;">failureThreshold</span>: 8
      <span style="color: #715ab1;">httpGet</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">host</span>: 127.0.0.1
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">path</span>: /healthz
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">port</span>: 10259
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">scheme</span>: HTTPS
      <span style="color: #715ab1;">initialDelaySeconds</span>: 10
      <span style="color: #715ab1;">periodSeconds</span>: 10
      <span style="color: #715ab1;">timeoutSeconds</span>: 15
    <span style="color: #715ab1;">name</span>: kube-scheduler
    <span style="color: #715ab1;">resources</span>:
      <span style="color: #715ab1;">requests</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">cpu</span>: 100m
    <span style="color: #715ab1;">startupProbe</span>:
      <span style="color: #715ab1;">failureThreshold</span>: 24
      <span style="color: #715ab1;">httpGet</span>:
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">host</span>: 127.0.0.1
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">path</span>: /healthz
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">port</span>: 10259
<span style="color: #ff0000; background-color: #ff0000; font-weight: bold;">        </span><span style="color: #715ab1;">scheme</span>: HTTPS
      <span style="color: #715ab1;">initialDelaySeconds</span>: 10
      <span style="color: #715ab1;">periodSeconds</span>: 10
      <span style="color: #715ab1;">timeoutSeconds</span>: 15
    <span style="color: #715ab1;">volumeMounts</span>:
    - <span style="color: #715ab1;">mountPath</span>: /etc/kubernetes/scheduler.conf
      <span style="color: #715ab1;">name</span>: kubeconfig
      <span style="color: #715ab1;">readOnly</span>: <span style="color: #4e3163;">true</span>
  <span style="color: #715ab1;">hostNetwork</span>: <span style="color: #4e3163;">true</span>
  <span style="color: #715ab1;">priorityClassName</span>: system-node-critical
  <span style="color: #715ab1;">securityContext</span>:
    <span style="color: #715ab1;">seccompProfile</span>:
      <span style="color: #715ab1;">type</span>: RuntimeDefault
  <span style="color: #715ab1;">volumes</span>:
  - <span style="color: #715ab1;">hostPath</span>:
      <span style="color: #715ab1;">path</span>: /etc/kubernetes/scheduler.conf
      <span style="color: #715ab1;">type</span>: FileOrCreate
    <span style="color: #715ab1;">name</span>: kubeconfig
<span style="color: #715ab1;">status</span>: {}

</pre>
</div>

<p>
In <code>yaml/spec/container/command</code> associated options to start the scheduler.
We can create a custom scheduler by setting <code>--scheduler-name=my-custome-scheduler</code>
</p>
</div>
</li>
<li><a id="org96ea043"></a>Leader elect options<br />
<div class="outline-text-5" id="text-org96ea043">
<p>
Finally an important option to look here is the <code>leader-elect</code> option.
The leader-elect option is <b>used when</b> <b>you have multiple copies of scheduler running</b> on <b>different master nodes</b>, in a High Availability setup where you have multiple master nodes with the kube-scheduler process running on both of them.
If <b>multiple copies</b> of the same scheduler are <b>running on different nodes</b>  <b>only one can be active at a time</b>.
</p>

<p>
<b>Thats where leader-elect option</b> helps in <b>choosing a leader</b> who will lead scheduling activities.Discuss later in HA setup section.
To get multiple schedulers working you must either set the <code>--leader-elec=false</code> In case where you dont have multiple masters.
</p>

<p>
In case you do have multiple masters, you can pass in an additional parameter <code>=--lock object name=my-custom-scheduler</code>
This is to differentiate <code>new-custom-scheduler</code> from the default during the <code>leader-election</code> process
</p>
</div>
</li>
<li><a id="org2bfc082"></a>Cmd To deploy my-custom-schedule using  yaml file<br />
<div class="outline-text-5" id="text-org2bfc082">
<pre class="example">
kubectl apply -f new-custom-scheduler.yaml

kubectl get pod  --namespace=kube-system 
</pre>
</div>
</li>
</ul>
</div>

<div id="outline-container-org52e10d4" class="outline-4">
<h4 id="org52e10d4">Config new pod to deploy using my-custome-scheduler</h4>
<div class="outline-text-4" id="text-org52e10d4">
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">pod-def.yaml</span>
<span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Pod
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: <span style="color: #2d9574;">"nginx"</span>
  <span style="color: #715ab1;">namespace</span>: <span style="color: #2d9574;">"default"</span>
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">containers</span>:
    - <span style="color: #715ab1;">image</span>: nginx
    <span style="color: #715ab1;">name</span>: nginx
  <span style="color: #715ab1;">schedulerName</span>: my-custom-scheduler
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubectl create -f pod-def.yaml # create the pod </span>
</pre>
</div>

<p>
The next step is to configure a new POD or a deployment to use the <code>new-custom-scheduler</code>. 
add <code>schedulerName</code> in <code>pod-def.yaml/spec/contaitners/schedulerName:my-custome-scheduelr</code>
</p>

<p>
So when pod is created, <code>my-custome-scheduler</code>  picks it up to schedule.
</p>

<p>
Create the pod using cmd <code>kubectl create -f pod-def.yaml</code>
</p>

<p>
If the scheduler was not configured correctly, then the pod will continue to remain in a Pending state. If everything is good, then the pod will be in a Running state.
</p>
</div>
</div>
<div id="outline-container-orge5552fc" class="outline-4">
<h4 id="orge5552fc">How do know which scheduler will pick the pod</h4>
<div class="outline-text-4" id="text-orge5552fc">
<p>
View the events using the <code>kubectl get events</code> cmd. This lists all the events in the current namespace.
</p>
<pre class="example">
$kubectl get events
</pre>
</div>
</div>

<div id="outline-container-orgb069fac" class="outline-4">
<h4 id="orgb069fac">View logs of a custom scheduler</h4>
<div class="outline-text-4" id="text-orgb069fac">
<pre class="example">
$kubectl logs my-custom-scheduler --name-space=kube-system
</pre>
</div>
</div>
</div>
<div id="outline-container-org05f0575" class="outline-3">
<h3 id="org05f0575">Practice Test - Multiple Schedulers</h3>
<div class="outline-text-3" id="text-org05f0575">
<p>
Practice Test: <a href="https://uklabs.kodekloud.com/topic/practice-test-multiple-schedulers-2/">https://uklabs.kodekloud.com/topic/practice-test-multiple-schedulers-2/</a>
</p>
</div>
</div>
<div id="outline-container-org9bf274c" class="outline-3">
<h3 id="org9bf274c">Solution - Practice Test - Multiple Schedulers : (Optional)</h3>
<div class="outline-text-3" id="text-org9bf274c">
<ul class="org-ul">
<li>Q) What is the name of the POD that deploy kubernetes scheduler in this environment ?
<ul class="org-ul">
<li>A) Ans: kube-scheduler-master
<ul class="org-ul">
<li>Get all the pod for kube-system namespace
<ul class="org-ul">
<li><code>kubectl -n kube-system get pods</code></li>
</ul></li>
<li>Get the name of pod which run scheduler #</li>
</ul></li>
</ul></li>
<li>Q) What is the image used to deploy the kubernetes scheduler ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl -n kube-system describe pod kube-scheduler-master | grep Image</code></li>
</ul></li>
</ul></li>
<li><p>
Q) Deploy an additional scheduler to cluster following the given specification [Namespace: kube-system,NameL my-scheduler, status: running, Custom Scheduler Name]
</p>

<p>
Use manifests file 
</p>
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>cd /etc/kubernetes/manifests/</code></li>
<li><code>cp kube-schedler.yaml /root/my-scheduler.yaml</code></li>
<li>Conf yaml file Inside <code>/spec/contaitners/command</code>
<ul class="org-ul">
<li>set: <code>--scheduler-anme=my-scheduelr</code></li>
<li>set: <code>--leader-election=false</code></li>
</ul></li>
<li>Create the custom scheduler
<ul class="org-ul">
<li><code>kubectl create -f my-scheduler.yaml</code></li>
</ul></li>
<li>Check if custom scheduler is created or not
<ul class="org-ul">
<li><code>kubeclt -n kube-system get pods</code></li>
</ul></li>
</ul></li>
</ul></li>
<li>Q) Pod definition file is given. Use it to create a POD with the new custome scheduler.
Name:nginx, Uses custom scheduler, Status: Running
<ul class="org-ul">
<li>A) Create the custom-scheduler pod yaml file 
<ul class="org-ul">
<li></li>
</ul></li>
</ul></li>
</ul>
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">pod-def.yaml</span>
<span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Pod
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: <span style="color: #2d9574;">"nginx"</span>
  <span style="color: #715ab1;">namespace</span>: <span style="color: #2d9574;">"default"</span>
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">containers</span>:
  <span style="color: #715ab1;">schedulerName</span>: my-custom-scheduler
  - <span style="color: #715ab1;">image</span>: nginx
    <span style="color: #715ab1;">name</span>: nginx
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubectl create -f pod-def.yaml # create the pod</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubectl get pods # Check if pod is running</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubeclt describe pod nginx # Check Event, From and Message</span>
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">From tell about which scheduler has run the pod</span>

</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org847e441" class="outline-2">
<h2 id="org847e441">Logging &amp; Monitoring  13 min</h2>
<div class="outline-text-2" id="text-org847e441">
</div>
<div id="outline-container-org702f45c" class="outline-3">
<h3 id="org702f45c">Download Presentation Deck</h3>
<div class="outline-text-3" id="text-org702f45c">
</div>
</div>
<div id="outline-container-orgd56a733" class="outline-3">
<h3 id="orgd56a733">Monitor Cluster Components</h3>
<div class="outline-text-3" id="text-orgd56a733">
</div>
<div id="outline-container-orgf3bdb31" class="outline-4">
<h4 id="orgf3bdb31">Monitor</h4>
<div class="outline-text-4" id="text-orgf3bdb31">
<p>
How do you monitor resource consumption on Kubernetes? Or more importantly
What would you like to monitor?
</p>
<ul class="org-ul">
<li>Node Level metrices:
<ul class="org-ul">
<li>number of nodes in the cluster,</li>
<li>how many nodes are healthy as well as</li>
<li>performance metrics such as CPU.</li>
<li>Memory</li>
<li>network and</li>
<li>disk utilization.</li>
</ul></li>
<li>POD level metrics :
<ul class="org-ul">
<li>number of PODs, and</li>
<li>performance metrics of each POD such
<ul class="org-ul">
<li>CPU and</li>
<li>Memory consumption on them.</li>
</ul></li>
</ul></li>
</ul>

<p>
So we need a solution that will monitor these metrics store them and provide analytics around this data.
As of this recording, Kubernetes does not come with a full featured built-in monitoring solution.
</p>

<p>
However, there are a number of open-source solutions available today, such as the Metrics-Server, Prometheus,Elastic Stack, and proprietary solutions like Datadog and Dynatrace.
</p>
</div>
</div>
<div id="outline-container-org45a11e7" class="outline-4">
<h4 id="org45a11e7">Heapset vs Metrics Server</h4>
<div class="outline-text-4" id="text-org45a11e7">
<p>
Heapster was one of the original projects that enabled monitoring and analysis features for kubernetes
You will see a lot of reference online when you look for reference architectures on monitoring Kubernetes.
</p>

<p>
However, Heapster is now Deprecated and a slimmed down version was formed known as the Metrics Server.
</p>
</div>
</div>
<div id="outline-container-orga28e072" class="outline-4">
<h4 id="orga28e072">Metrics Server</h4>
<div class="outline-text-4" id="text-orga28e072">
<p>
You can have one metrics server per kubernetes cluster the metric server retrieves metrics from each of the kubernetes nodes and pods, aggregates them and stores them in memory.
</p>

<p>
Note that the metric server is only an <code>in-memory</code> monitoring solution and does not store the metrics on the desk and as a result you cannot see historical performance data.
</p>

<p>
For that you must rely on one of the advanced monitoring solutions we talked about earlier
</p>
</div>
</div>
<div id="outline-container-orgece44b4" class="outline-4">
<h4 id="orgece44b4">How are the metrics generated for the PODs on these nodes?</h4>
<div class="outline-text-4" id="text-orgece44b4">
<p>
Kubernetes runs an agent on each node known as the kubelet, which is responsible for receiving instructions from the kubernetes API master server and running PODs on the nodes.
The kubelet also contains a subcomponent known as as cAdvisor or Container Advisor. cAdvisor is responsible for retrieving performance metrics from pods, and exposing them through the kubelet API to make the metrics available for the Metrics Server.
</p>
</div>
</div>
<div id="outline-container-orgf5cbf7b" class="outline-4">
<h4 id="orgf5cbf7b">Metrics Server - Getting Started</h4>
<div class="outline-text-4" id="text-orgf5cbf7b">
<p>
If you are using
</p>
<ul class="org-ul">
<li>minikube for your local cluster,run the command <code>minikube addons enable metrics-server</code>.</li>
<li>other environments deploy the metrics server by git cloning
<ul class="org-ul">
<li><code>git clone https://github.com/kubernetes-incubator/meterics-server.git</code></li>
</ul></li>
<li><p>
deploy the metric servier     
</p>
<ul class="org-ul">
<li><code>kubectl create -f deploy/1.8+/</code></li>
</ul>
<p>
This command deploys a set of pods, services and roles to enable metrics server to pull for performance metrics from the nodes in the cluster.
</p></li>
</ul>

<p>
Once deployed, give the metrics-server some time to collect and process data. Once processed, cluster performance can be viewed by running the command <code>kubectl top node</code> 
</p>
<div class="org-src-container">
<pre class="src src-sh">$<span style="color: #715ab1;">kubectl</span> top node
<span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">This provides the CPU and Memory consumption of each of the nodes. As you can see 8% of the CPU on my master node is consumed, which is about 166 milli cores.</span>
</pre>
</div>

<p>
Use the <code>kubectl top pod</code> command to view performance metrics of pods in kubernetes.
</p>
<pre class="example">
$kubectl top pod 
</pre>
</div>
</div>
</div>
<div id="outline-container-org2a5a472" class="outline-3">
<h3 id="org2a5a472">Practice Test - Monitoring</h3>
<div class="outline-text-3" id="text-org2a5a472">
<p>
Note: In this test you will enable cluster monitoring. Once you do remember to wait for atleast 5 minutes to allow the metrics-server enough time to collect and report performance metrics.
</p>


<p>
Practice Test - <a href="https://uklabs.kodekloud.com/topic/practice-test-monitor-cluster-components-2/">https://uklabs.kodekloud.com/topic/practice-test-monitor-cluster-components-2/</a>
</p>
</div>
</div>

<div id="outline-container-org6fd1ac2" class="outline-3">
<h3 id="org6fd1ac2">Solution: Monitor Cluster Components : (Optional)</h3>
<div class="outline-text-3" id="text-org6fd1ac2">
<ul class="org-ul">
<li>Q) We have deployed a few PODS running worklaods. Inspect it.
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pods</code></li>
</ul></li>
</ul></li>
<li>Q) Let us deploy metrics-server to monitor the pods and Nodes. Pull the git repository for the deployment files.
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>git clone the repo
<ul class="org-ul">
<li><code>git clone https://github.com/kodekloudhub/kubernetecis-metrics-server.gitcheckout</code></li>
</ul></li>
</ul></li>
</ul></li>
<li>Q) Deploy the metrics-server by creating all the components downlaoded.
Run the <code>kubectl create -f .</code> cmd from within the downlaoded repo
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl create -f .</code></li>
</ul></li>
</ul></li>
<li>Q) It Takes few minites for the metrics server to start gathering data. Check the metrics
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl top node</code> or <code>watch "kubectl top node"</code></li>
</ul></li>
</ul></li>
<li>Q) Identify the node that consume the most CPU.
<ul class="org-ul">
<li>A) <code>kubectl top node</code></li>
</ul></li>
<li>Q) Identifies the node that consume the most memory ?
<ul class="org-ul">
<li>A) <code>kubectl top node</code></li>
</ul></li>
<li>Q) Identifies the pod which consume the most memory ?
<ul class="org-ul">
<li>A) <code>kubectl top pod</code></li>
</ul></li>
<li>Q) Identifie the Pod which consume most CUP ?
<ul class="org-ul">
<li>A) <code>kubectl top pod</code></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org1dae6e0" class="outline-3">
<h3 id="org1dae6e0">Managing Application Logs</h3>
<div class="outline-text-3" id="text-org1dae6e0">
<p>
we will talk about various Logging mechanisms in kubernetes. Let us start with logging in Docker.
</p>
</div>
<div id="outline-container-org236189a" class="outline-4">
<h4 id="org236189a">Logs - Docker</h4>
<div class="outline-text-4" id="text-org236189a">
<p>
We are running Docker container called event-simulator and all that it does is generate random events simulating a webserver.
</p>
<pre class="example">
kubectl run -d kodekloud/event-simulator # i could see the log as it in -d: detached mode

# To see the logs
docker logs -f ecf  # Use the f option to stream the logs live just like the docker command.
</pre>
</div>
</div>

<div id="outline-container-org5eba59b" class="outline-4">
<h4 id="org5eba59b">Logs - Kubernetes <code>kubectl logs event-simulator-pod event-simulator</code></h4>
<div class="outline-text-4" id="text-org5eba59b">
<p>
We create a pod with the same docker image using the pod definition-yaml file.
</p>
<pre class="example">
apiVersion: v1
kind:Pod
metadata:
  name: event-simulator-pod
spec:
  containers:
  - name: event-simulator
    image: kodekolud/event-simulator
</pre>

<p>
Once its the pod is running, we can view the logs using the kubectl logs command with the pod name.
</p>
<pre class="example">
kubectl create -f event-simulator.yaml
kubectl logs -f event-simulator-pod  # Use the f option to stream the logs live just like the docker command.
</pre>
</div>
</div>
<div id="outline-container-orgf2df235" class="outline-4">
<h4 id="orgf2df235">Logs - Kubernetic Pod with Multi Containers</h4>
<div class="outline-text-4" id="text-orgf2df235">
<p>
Kubernetes PODs can have multiple docker containers in them.
</p>

<p>
I modify my pod definition file to include an additional container called image-processor.
</p>
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Pod
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: event-simulator-pod
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">containers</span>:
  - <span style="color: #715ab1;">name</span>: event-simulator
    <span style="color: #715ab1;">image</span>: kodekloud/event-simulator
  - <span style="color: #715ab1;">name</span>: image-processor
    <span style="color: #715ab1;">image</span>: some-image-processor
<span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">kubectl apply -f pod-with-mulit-container.yaml </span>
</pre>
</div>

<p>
-Q) How to see log for mulit container pod 
If you ran the kubectl logs command now with the pod name, which containers log would it show? If there are multiple containers within a pod.
You must specify the name of the container explicitly in the command. Otherwise it would fail asking you to specify a name.
</p>
<div class="org-src-container">
<pre class="src src-sh">kubectl logs -f event-simulator-pod <span style="color: #2aa1ae; background-color: #ecf3ec;">#</span><span style="color: #2aa1ae; background-color: #ecf3ec;">show-error</span>
kubectl logs -f event-simulator event-simulator <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Show log of container image:kodekloud </span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgaea8742" class="outline-3">
<h3 id="orgaea8742">Practice Test - Monitor Application Logs</h3>
<div class="outline-text-3" id="text-orgaea8742">
<p>
Practice Test - <a href="https://uklabs.kodekloud.com/topic/practice-test-managing-application-logs-2/">https://uklabs.kodekloud.com/topic/practice-test-managing-application-logs-2/</a>
</p>
</div>
</div>
<div id="outline-container-orge5027cc" class="outline-3">
<h3 id="orge5027cc">Solution: Logging : (Optional)</h3>
<div class="outline-text-3" id="text-orge5027cc">
<ul class="org-ul">
<li>Q) We have deployed a pod hosting an application. Inspect it. Wait for it to start.
<ul class="org-ul">
<li>A) <code>kubeclt get pods</code></li>
</ul></li>
<li>Q) A users 'USERS' has expressed concerns accessing the application. Identify the cause of the issuse ? (Hint : Inspect the pods)
<ul class="org-ul">
<li><code>kubectl logs webapp-1 | grep USERS</code></li>
</ul></li>
<li>Q) We have a new pod 'webapp-2' hosting an application. Inspect it. Wait for it to start.
<ul class="org-ul">
<li><code>kubectl get pods</code></li>
</ul></li>
<li>Q) A user is reporting issues while trying to purchase an item. Identify the user and the cause of the issuse.
(Hint:: Inspect the logs of webapp in the POD)
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>Check the status,ready of pod
<ul class="org-ul">
<li><code>kubectl get pods</code> # webapp containes two containers</li>
</ul></li>
<li>Check the logs of webapp container
<ul class="org-ul">
<li><code>kubectl logs webapp-2 -c simple-webapp</code> # search error in logs</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgfb5700b" class="outline-2">
<h2 id="orgfb5700b">Application Lifecycle Management | 1h31min</h2>
<div class="outline-text-2" id="text-orgfb5700b">
<p>
In this section we will discuss about
</p>
<ul class="org-ul">
<li>Rolling Update and Rollbacks in Deployments</li>
<li>Config Application</li>
<li>Scale Application</li>
<li>Self-Healing Application</li>
</ul>
</div>
<div id="outline-container-orgee55f28" class="outline-3">
<h3 id="orgee55f28">Rolling Updates and Rollbacks</h3>
<div class="outline-text-3" id="text-orgee55f28">
<p>
Before going to <b>Rolling Updates</b> and <b>Rollback</b>
</p>
</div>
<div id="outline-container-org9b85abf" class="outline-4">
<h4 id="org9b85abf">Rollouts and Versioning</h4>
<div class="outline-text-4" id="text-org9b85abf">
<p>
Lets understand <b>Rollouts</b> and <b>Versioning</b> in deployment.
</p>

<ul class="org-ul">
<li>When you frist create a deployment, it trigger a rollout, a new rollout,create a new deployment.Lets call it as <b>Revision 1</b></li>
<li>Infuture, when application is upgraded, meaning when the container verison is updated to  new-version, then a <b>new-Reversion</b> is created. Lets call <b>Revision-2</b></li>
<li>This help us to keep track of changes made to deployment and enables us to <b>roll back</b> to a previous version (<b>Revision 1</b>) of deployment.</li>
</ul>
</div>
</div>

<div id="outline-container-org18301fb" class="outline-4">
<h4 id="org18301fb">Status of rollout Command</h4>
<div class="outline-text-4" id="text-org18301fb">
<p>
Rollout Command Status
</p>
<pre class="example">
kubectl rollout status deployment/myapp-deployment
# To see the history of rollout
kubectl rollout history deployment/myapp-deployment
</pre>
</div>
</div>
<div id="outline-container-org541b919" class="outline-4">
<h4 id="org541b919">Deployment Strategy (Recreate and Rolling Update)</h4>
<div class="outline-text-4" id="text-org541b919">
<p>
There are two types of Deployment Strategy
</p>
<ul class="org-ul">
<li>Destroy the current deployment and then create new deployment know as <b>recreate strategy</b>
<ul class="org-ul">
<li>Disadvanges: due to delay the application might be down and</li>
</ul></li>
<li>Don't destroy all older version at once but we destroy one-pod of older version and create one with new-version untill all the older pods are destroied this is also know as <b>Rolling Update</b></li>
<li>By default is <b>rolling update</b> is default strategy</li>
</ul>
</div>
</div>

<div id="outline-container-orgb1a1d0f" class="outline-4">
<h4 id="orgb1a1d0f">Update your deployment</h4>
<div class="outline-text-4" id="text-orgb1a1d0f">
<p>
Update can be different things:
</p>
<ul class="org-ul">
<li>Update you app version</li>
<li>Update your container image</li>
<li>Updating there labels</li>
<li>Updating the no of replicas</li>
<li>&#x2026;.etc</li>
</ul>

<p>
Since we are having the deploy.yaml file it will be easy to modify the or update.
Once we make the we can apply update by <code>kubectl apply -f deployment-def.yaml</code>
</p>

<p>
There is other way to update using <code>set image</code> cmd
</p>
<pre class="example">
kubectl set image deployment/myapp-deployment nginx=nginx:1.9.1
</pre>
</div>
</div>

<div id="outline-container-org2014372" class="outline-4">
<h4 id="org2014372">Different btw Recreate and Rolling update &lt;insert img&gt;</h4>
<div class="outline-text-4" id="text-org2014372">
<p>
we can see diff using describe cmd 
</p>
</div>
</div>

<div id="outline-container-orgb664a0f" class="outline-4">
<h4 id="orgb664a0f">How Deployment upgrades the cluster</h4>
<div class="outline-text-4" id="text-orgb664a0f">
<p>
When a new deployment is created say <code>deploy 5 replicas</code>
</p>
<ul class="org-ul">
<li>1st create repliacset
<ul class="org-ul">
<li>replicaset ensuse there are 5 pods in replicaset</li>
</ul></li>
<li>When you upgrade a <b>new replica set</b> is created under the deployment
-Then is start deploying containers in it and at same time it delete the old containers in <b>old replica set</b> following rolling update stratagy</li>
</ul>
<pre class="example">
kubectl get replicasets
</pre>
</div>
</div>

<div id="outline-container-org96ec7da" class="outline-4">
<h4 id="org96ec7da">Roll back</h4>
<div class="outline-text-4" id="text-org96ec7da">
<p>
After you deploy a new-version you want to swtich back to older version due to some bugs. So you want to rollback the update.
</p>
<pre class="example">
kubectl rollout undo deployment/myapp-deployment
</pre>
</div>
</div>
<div id="outline-container-orgb586221" class="outline-4">
<h4 id="orgb586221">Summarize</h4>
<div class="outline-text-4" id="text-orgb586221">
<div class="org-src-container">
<pre class="src src-sh">kubectl create -f deployment-definition.yaml   <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">create deployment </span>
kubectl get deployment                         <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">list deployment</span>
kubectl apply -f deployment-definition.yaml    <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">appy,set,update the deploy</span>
kubectl set image deployment/myapp-deployment <span style="color: #715ab1;">nginx</span>=nginx:1.9.1
kubectl rollout status deployment/myapp-deployment     <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">status of rollout    </span>
kubectl rollout history deployment/myapp-deployemnt
kubectl rollout undo deployement/myapp      <span style="color: #2aa1ae; background-color: #ecf3ec;"># </span><span style="color: #2aa1ae; background-color: #ecf3ec;">Undo the roll-back the deployment</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgaa4610e" class="outline-3">
<h3 id="orgaa4610e">Practice Test - Rolling Updates and Rollback</h3>
<div class="outline-text-3" id="text-orgaa4610e">
<p>
Practice Test: <a href="https://uklabs.kodekloud.com/topic/practice-test-rolling-updates-and-rollbacks-2/">https://uklabs.kodekloud.com/topic/practice-test-rolling-updates-and-rollbacks-2/</a>
</p>
</div>
</div>
<div id="outline-container-org2ccb2ca" class="outline-3">
<h3 id="org2ccb2ca">Solution: Rolling update : (Optional)</h3>
<div class="outline-text-3" id="text-org2ccb2ca">
<ul class="org-ul">
<li>Q) We have deployed a simple web application. Inspect the PODs and Services. Wait for the application to fully deploy and view the application using the link above your terminal
<ul class="org-ul">
<li>A)</li>
<li><code>kubectl get pods</code> # get no of pods</li>
<li><code>web-portal</code> # check ulr is working or not and url page colour</li>
</ul></li>
<li>Q) What is current color of web application ?
<ul class="org-ul">
<li>A) Blue</li>
</ul></li>
<li>Q)Run script <code>curl-test.sh</code> to send multiple requests to test the web application. Take a note of the output.
<ul class="org-ul">
<li>A) <code>sh curl-test.sh</code></li>
</ul></li>
<li>Q)Inspect the deployment and identify the number of PODs deployed by it.
<ul class="org-ul">
<li>A)4</li>
</ul></li>
<li>Q) What container image is used to deploy the applications ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl describe deployments.apps frontend | grep -i image</code></li>
</ul></li>
</ul></li>
<li>Q) Inspect the depolyment and identify the current strategy
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>Read the kubernetics doc: strategy (Recreate, Rolling Update)</li>
<li><code>kubectl describe depolyment.apps frontend | grep -i StrategyType</code> # Ans: Rollling Update</li>
</ul></li>
</ul></li>
<li>Q) If you were to upgrade the application now what would happend ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>Pods, are upgraded few at a time</li>
</ul></li>
</ul></li>
<li>Q) Let us try that. Update the application by setting the image on the deployment to 'kodekloud/webapp-color:v2'
Do not delete and re-create the deployment. Only set the new image name for the existing deployment.
Deployment Name: frontend
Deployment image: kodakloud/webapp-color:v2
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>Using kubectl edit deployment cmd
<ul class="org-ul">
<li><code>kubectl edit deployments.apps frontend</code> and change image from v1 to v2</li>
<li>Check pods <code>kubectl get pods</code></li>
</ul></li>
</ul></li>
</ul></li>
<li>Q) Up to how many Pods can be down for upgrade at a time Consider the current stragegy settings and no of pods.
<ul class="org-ul">
<li>A) <code>kubectl describe deployments.apps frontend | grep -i RollingUpdateStrategy</code> # Check result 25% max unavailable. 25% max  surges</li>
<li>4/4= 1 pod can be down</li>
</ul></li>
<li>Q) Change the deployment strategy to 'Recreate' Do not delete and re-create the deployment.Only update the strategy for the existing deployment.
Depolyment Name: frontend
Deployment Image: kodekloud/webapp-color:v2
Strategy: Recreate
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>Edit the deployment file
<ul class="org-ul">
<li><code>kubectl edit deplooyment.apps frontend</code></li>
</ul></li>
<li>Change yaml/spec/strategy/type: Recreate instead of
RollingUpdate</li>
<li>Check the changes   
<ul class="org-ul">
<li><code>kubectl describe deployments.apps frontend</code></li>
</ul></li>
</ul></li>
</ul></li>

<li>Q) Upgrade the application by setting the image on the deployment to 'kodekloud/webapp-color:v3'
Do not delete and re-create the deployment. Only set the new image name for the existing deployment.
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>Edit the deployment file
<ul class="org-ul">
<li><code>kubectl edit deplooyment.apps frontend</code></li>
</ul></li>
<li>Change yaml/spec/containers/image: v3 instead of v2</li>
<li>Check the changes   
<ul class="org-ul">
<li><code>kubectl describe deployments.apps frontend</code></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org91767ce" class="outline-3">
<h3 id="org91767ce">Configure Applications</h3>
<div class="outline-text-3" id="text-org91767ce">
<p>
Configuring applications comprises of understanding the following concepts:
</p>

<p>
Configuring Command and Arguments on applications
Configuring Environment Variables
Configuring Secrets
</p>

<p>
We will see these next
</p>
</div>
</div>
<div id="outline-container-org895607e" class="outline-3">
<h3 id="org895607e">Commands &lt;SKIP because docker cmd and entry point&gt;</h3>
<div class="outline-text-3" id="text-org895607e">
<pre class="example">
FROM Ubuntu
CMD sleep 5
</pre>

<p>
CMD can be used as
</p>
<ul class="org-ul">
<li>CMD command param1   <code>CMD sleep 5</code></li>
<li><p>
CMD ["command", "param1"] <code>CMD ["sleep","5"]</code>
</p>

<p>
Now build the docker image .
</p></li>
</ul>
<pre class="example">
docker build -t ubuntu-sleeper .
docker run ubuntu-sleeper    # sleep for 5 sec
docker run ubuntu-sleeper sleep 10   # over-write cmd   # sleep for 10 sec   
</pre>


<pre class="example">
FROM Ubuntu
ENTRYPOINT ["sleep"]
CMD  ["5"]

docker build -t ubuntu-sleeper .
docker run ubuntu-sleeper           # sleep for 5 sec
docker run ubuntu-sleeper 10        # over-write cmd   # sleep for 10 sec

# Want to overwite the sleep command

docker run ubuntu-sleep --entrypoint sleep2.0 ubuntu-sleeper 10 

</pre>
</div>
</div>

<div id="outline-container-org3ff34bc" class="outline-3">
<h3 id="org3ff34bc">Practice Test - Commands and Arguments</h3>
<div class="outline-text-3" id="text-org3ff34bc">
<p>
Practice Test: <a href="https://uklabs.kodekloud.com/topic/practice-test-commands-and-arguments-2/">https://uklabs.kodekloud.com/topic/practice-test-commands-and-arguments-2/</a>
</p>
</div>
</div>
<div id="outline-container-org08fa062" class="outline-3">
<h3 id="org08fa062">Solution - Commands and Arguments (Optional)</h3>
<div class="outline-text-3" id="text-org08fa062">
<ul class="org-ul">
<li>Q) How many PODs exit on the system ? in the current [default] namespace ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pods</code></li>
</ul></li>
</ul></li>
<li>Q) What is command used to run the pod 'ubuntu-sleeper'
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl describe pod ubuntu-sleeper| grep -i command -A 4</code></li>
</ul></li>
</ul></li>
<li>Q) Create a pod with the ubuntu image to run a container to sleep for 5000 sec. Modify the file ubuntu-sleeper-2.yaml
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>vi ubuntu-sleeper-2.yaml</code></li>
<li><p>
add <code>command:[""sleep", "5000"]</code>
</p>
<pre class="example">
apiVersion: v1
kind: Pod
metadata:
  name: ubuntu-sleeper-2
spec: 
   containers:
   - name: ubuntu
     image: ubuntu
     command: ["sleep", "5000"]
</pre></li>
<li>Check <code>kubectl describe pod ubuntu-sleeper | grep -i command -A 4</code></li>
</ul></li>
</ul></li>
<li>Q) Create a pod using 'ubuntu-sleeper-3.yaml'. There is something woring with it. Try to fix it! Note: ONly make necessary changes
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl apply -f ubuntu-sleeper-3.yaml</code> # Error i yaml file</li>
<li>De-bug: change <code>yaml/spec/containers/command: "1200"</code></li>
</ul></li>
</ul></li>
<li>Q) Update the pod 'ubuntu-sleeper-3.yaml' to sleep for 2000 sec. Note: Only make the necessary changes. Do not modify the name of the pod.
<ul class="org-ul">
<li>A) 
<ul class="org-ul">
<li><code>kubectl delete -f ubuntu-sleeper-3.yaml</code></li>
<li><code>vi ubuntu-sleeper-3.yaml</code></li>
<li>replace <code>yaml/spec/conatiners/command: - "1200"</code> with "2000"</li>
</ul></li>
</ul></li>
<li>Q) Inspect the file 'Dockerfile' given at /root/webapp-color. What command is run at container startup ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>cd path/</code></li>
<li>cat Dockerfile</li>
<li>check for entrypoint or cmd in docker  # Ans python-app.py</li>
</ul></li>
</ul></li>
<li>Q) Inspect Dockerfile2 . What is command is run at conatienr startup 
<ul class="org-ul">
<li><p>
A) 
</p>
<ul class="org-ul">
<li><code>cat Dockerfile2</code></li>
</ul>
<pre class="example">
FROM python:3/6-alpine
RUN pip install flask
COPY . /opt/
EXPOSE 8080
WORKDIR /opt 
ENTRYPOINT ["python, "app.py"]
CMD ["--color", "red"]
</pre>
<ul class="org-ul">
<li>Inspect dockerfile # python app.py &#x2013;color red</li>
</ul></li>
</ul></li>
<li>Q) Inspect the two files under directory 'webapp-color-2'. What command is run at container startup ?</li>
<li><p>
Q) Create a pod with the given specifications. By default it display a 'blue' background. Set the given command line arguments to change it to green.
</p>
<pre class="example">
kubectl run webapp-green --image=kodekloud/webapp-color --restart=Never --dry-run -o yaml &gt; pod.yaml

cat pod.yaml

apiVersion: v1

kind: Pod
metadata:
  createTimestamp: null
  labels:
    run: webapp-green
  name: webapp-green
spec:
  containers:
  - image: kodekloud/webapp-color
    name: webapp-green
    args: ["--color=green"]
w
kubectl apply -f pod.yaml
kubectl describe pod  webapp-green # inspect the arguments
</pre></li>
</ul>
</div>
</div>
<div id="outline-container-org081f557" class="outline-3">
<h3 id="org081f557">Commands and Arguments &lt;Simillar to Entrypoint and cmd in Docker&gt;</h3>
</div>

<div id="outline-container-org2e6eb51" class="outline-3">
<h3 id="org2e6eb51">Passing(env) to pod</h3>
<div class="outline-text-3" id="text-org2e6eb51">
<p>
There are three ways to  pass the evn into kubernetics
</p>
<ul class="org-ul">
<li>Plain Key Value</li>
<li>ConfigMap</li>
<li>Secrets</li>
</ul>
</div>
</div>

<div id="outline-container-org75c487a" class="outline-3">
<h3 id="org75c487a">[Plain Key Value pair]</h3>
<div class="outline-text-3" id="text-org75c487a">
<pre class="example">
docker run --name test-name -e APP_COLOR=pink simple-webapp-color
env:
  - name: APP_COLOR
    value: pink

env:
  - name: APP_COLOR
    valueFrom:
       configMapKeyRef:

env:
  - name: APP_COLOR
    valueFrom:
	secretKeyRef: 
</pre>
</div>
</div>

<div id="outline-container-orgbb461ea" class="outline-3">
<h3 id="orgbb461ea">[ConfigMa]p and attaching in pod-defin</h3>
<div class="outline-text-3" id="text-orgbb461ea">
<p>
When you have a lot of pod definition(<code>env</code>) files it will become difficult to manage the environment data stored within the query files. We can take this information out of the pod definition file and manage it centrally using Configuration Maps (<code>ConfigMap</code>).
<code>ConfigMaps</code> are used to pass configuration data in the form of key value pairs in Kubernetes.
</p>

<p>
There are two phases involved in configuring ConfigMaps.
</p>
<ul class="org-ul">
<li>create the ConfigMaps
<ul class="org-ul">
<li><code>APP_COLOR: blue</code>
<code>APP_MODE: prod</code></li>
</ul></li>
<li><p>
Inject(pass env) them into the POD. Just like any other Kubernetes object.
</p>

<p>
CREATE CONFIGMAP
we can pass env-file into kuberentecis in two ways imperative and declarative
</p>
<ul class="org-ul">
<li>Imperative:  <code>kubectl create configmap</code></li>
<li>Delarative: <code>kubectl create -f</code></li>
</ul>

<p>
Imperative way:
</p></li>
<li><code>kubectl create configmap &lt;name-of-configmap&gt; --from-literal=&lt;key&gt;=&lt;value&gt;</code></li>
<li><code>kubectl create configmap app-config --from-literal=APP_COLOR=blue --from-literal=APP_MOD=prod</code></li>
<li><code>kubectl create configmap app-config --from-file=app_config.properties</code></li>
</ul>

<p>
Declarative way:
</p>
<ul class="org-ul">
<li><code>kubectl create -f</code></li>
<li>config-map.yaml</li>
</ul>
<pre class="example">
apiVersion: vq
kind: ConfigMa[
metadata:
  name: app-config
data:
  APP_COLOR: blue
  APP_MODE: prod
# kubectl create -f config-map.yaml
</pre>
</div>
<div id="outline-container-orga517eee" class="outline-4">
<h4 id="orga517eee">View ConfigMaps</h4>
<div class="outline-text-4" id="text-orga517eee">
<p>
<code>kubectl get configmaps</code>
<code>kubectl describe configmaps</code>
</p>
</div>
</div>
<div id="outline-container-org035e303" class="outline-4">
<h4 id="org035e303">Attach ConfigMap with Pods defination.yaml</h4>
<div class="outline-text-4" id="text-org035e303">
<p>
Conside a config-map.yaml file
</p>
<pre class="example">
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  APP_COLOR: blue
  APP_MODE: prod
#kubectl apply -f config-map.yaml
</pre>

<pre class="example">
apiVersion: v1
kind: Pod
metadata:
   name: simple-webapp-color
   labels:
     name: simple-webapp-color
spec:
  containers:
  - name: simple-webapp-color
    image: simple-webapp-color
    ports:
      - containerPort: 8080
    envFrom:
      - configMapRef:
	    name: app-config
#kubectl apply -f pod-definition.yaml
</pre>


<ul class="org-ul">
<li>In pod definition we can inject or attach the env using three ways
<ul class="org-ul">
<li><p>
Key value pair : <code>name: app-config</code> <code>key: APP_COLOR</code>
</p>
<pre class="example">
env:
  - name: APP_COLOR
    valueFrom:
      configMapKeyRef:
	name: app-config
	key: APP_COLOR
</pre></li>
<li><p>
configMap.yaml file : <code>name: &lt;configMap-name&gt;</code>
</p>
<pre class="example">
envFrom:
  - configMapRef:
	 name: app-config  
</pre></li>
<li><p>
Volume :
</p>
<pre class="example">
volumes:
- name: app-config-volume
  configMap:
    name: app-config
</pre></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc0c8415" class="outline-3">
<h3 id="orgc0c8415">[ConfigMap] Practice Test: Environment Variables</h3>
<div class="outline-text-3" id="text-orgc0c8415">
<p>
Practice Test: <a href="https://uklabs.kodekloud.com/topic/practice-test-env-variables-2/">https://uklabs.kodekloud.com/topic/practice-test-env-variables-2/</a>
</p>
</div>
</div>
<div id="outline-container-orge8d6fcc" class="outline-3">
<h3 id="orge8d6fcc">[ConfigMap] Solution - Environment Variables (Optional)</h3>
<div class="outline-text-3" id="text-orge8d6fcc">
<ul class="org-ul">
<li>Q) Find the no of pods ?
<ul class="org-ul">
<li>A) <code>kubectl get pods</code></li>
</ul></li>
<li>Q) What is the environment variable name set on the container in the pod ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>Get the pod name <code>kubectl get pods</code></li>
<li>inspect the pod <code>kubectl describe pod webapp-color| grep -i enviorment -A 2</code>  # Env name: APP<sub>COLOR</sub></li>
</ul></li>
</ul></li>
<li>Q) What is the value for evn APP<sub>COLOR</sub> ?
<ul class="org-ul">
<li>A) <code>pink</code></li>
</ul></li>
<li>Q) View the web application UI by clicking on the 'Webapp Color' Tab above your Terminal.
<ul class="org-ul">
<li>A) Ok</li>
</ul></li>
<li>Q) Update the env on pod to display 'green' background ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pod webapp-color -o yaml &gt; pod.yaml</code></li>
<li><code>kubectl delete pod webapp-color</code></li>
<li><code>vi pod.yaml</code></li>
<li>change env[name=APP<sub>COLOR</sub>]=green</li>
</ul></li>
</ul></li>
<li>Q) How many ConfigMaps exist in the environment ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get configmap</code> or <code>kubeclt get cm</code></li>
<li>==</li>
</ul></li>
</ul></li>
<li>Q) Identify the database host from the config map 'db-config'
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get cm</code> # get the config map name</li>
<li>describe cm <code>kubeclt describe cm db-config</code></li>
</ul></li>
</ul></li>
<li>Q) Create a new ConfigMap for the 'webapp-color' Pod. Use the spec given
spec['ConfigName']=webapp-config-map, spec[Data[APP<sub>COLOR</sub>]]=darkblue
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl create cm webapp-color-map --from-literal=APP_COLOR=darkblue</code></li>
</ul></li>
</ul></li>
<li>Q) Update the env variable on the pod use the newly created configMap
Note: Delete and recreate the pod. Only make the necessary changes. Do not modify the name of the Pod.
Note: Pod Name: webapp-color EnvFrom:webapp-config-map

<ul class="org-ul">
<li>A) <code>kubectl delete pod webapp-color</code>
<ul class="org-ul">
<li><code>kubectl explain --recursive | grep envFrom -A 3</code> # COPY THE FORMAT</li>
<li><code>vi pod.yaml</code></li>
<li><p>
replace envfield with envfrom in pod.yaml
</p>
<pre class="example">
- envFrom:
   - configMapRe
	nameL webapp-config-map
</pre></li>
<li><code>kubectl apply -f pod.yaml</code></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org1fa375a" class="outline-3">
<h3 id="org1fa375a">[Secrets] and attaching in pod or Applications</h3>
<div class="outline-text-3" id="text-org1fa375a">
<p>
There are two steps in using secrets in kubernetecis
</p>
<ul class="org-ul">
<li>create a secret file : To store the credencials which need to encript</li>
<li>attach secret file to pod-defination.yaml file</li>
</ul>
</div>

<div id="outline-container-org42972e6" class="outline-4">
<h4 id="org42972e6">Create Secret</h4>
<div class="outline-text-4" id="text-org42972e6">
<p>
Create can be generated by two ways
</p>
<ul class="org-ul">
<li><p>
Imperative way
</p>
<pre class="example">
docker login  registry.gitlab.com/digival/digiassess/digiassessapi -u da-api-deploy-token -p uPciF8yZneXoNTL685c-
# ##### Create a yaml file for gitlab docker repo credencials #################################################

kubectl create secret docker-registry &lt;secret-name&gt; \
 --docker-server=https://registry.gitlab.com/digival/xyseef/xexxxxx \
 --docker-username=&lt;mygitlab_id&gt; \
 --docker-password=&lt;mygitlab_password&gt;- \
 --dry-run=client  --output=yaml &gt; docker-repo-secrets.yaml

# ################ or ###############################
kubectl create secret generic &lt;secret-name&gt; --from-lietral=&lt;key&gt;=&lt;value&gt;
kubectl create secret generic app-secret --from-literal=DB_Host=mysql --from-literal=DB_User=root --from-literal=DB_Password=paswrd 
</pre>
<p>
However adding credencials in comamnd line will difficult as no of credencials increase so we can attach them using file
</p>
<pre class="example">
kubectl create secret generic &lt;secret-name&gt; --from-file=&lt;path-to-file&gt;
kubectl create secret generic app-secret --from-file=app_secret.properties
</pre></li>
<li><p>
Declarative way
</p>
<pre class="example">
apiVersion :V1
kind: Secret
metadata:
  name: app-secret
data:
  DB_Host: mysql
  DB_User: root
  DB_Password: paswrd
</pre>
<p>
It is not a good practice to give credencials with out encryption
For encryption we use the linux <code>base64</code> encryption
</p>
<pre class="example">
# # # To encript # # #
echo -n 'mysql' | base64
# bX1zcWw=
echo -n 'root'  | base64
# cm9vdA=
# # # To decript # # #
echo -n 
</pre></li>
</ul>
</div>
</div>

<div id="outline-container-org7e04de0" class="outline-4">
<h4 id="org7e04de0">View Secret</h4>
<div class="outline-text-4" id="text-org7e04de0">
<pre class="example">
kubectl get secrets
kubectl describe secrets

# To view the serets encripted values
kubectl get secret app-secret -o yaml

# To view the decripted value of credencials
echo -n 'bX1zcWw' | base64 --decode
# mysql 
echo -n 'cm9vdA==' | base64 --decode
# root
</pre>
</div>
</div>

<div id="outline-container-orgfb879d8" class="outline-4">
<h4 id="orgfb879d8">Config (attach) secret with pod-definition</h4>
<div class="outline-text-4" id="text-orgfb879d8">
<pre class="example">
apiVersion :V1
kind: Secret
metadata:
  name: app-secret
data:
  DB_Host: bX1zcWw=
  DB_User: cm9vdA==
  DB_Password: q3tRHAw6-8U

---
apiVersion: v1
kind: Pod
metadata:
  name: simple-webapp-color
  labels:
    name: simple-webapp-color
spec:
  containers:
  - name: simple-webapp-color
    image: simple-webapp-color
    ports:
      - containerPort: 8080
    envFrom:
      - secretRef:
	   name: app-secret   
</pre>
</div>
</div>
</div>

<div id="outline-container-org0d0338f" class="outline-3">
<h3 id="org0d0338f">Conclusion of Passing ENV to  application</h3>
<div class="outline-text-3" id="text-org0d0338f">
<p>
So we can pass enviorment variable to application by
</p>
<ul class="org-ul">
<li>attaching secret.yaml file <b>[secretRef]</b></li>
<li>giving credencials or (envir varible) inside the pod defination <b>[secretRef]</b></li>
<li>attaching secret as volume <b>volume</b></li>
</ul>

<pre class="example">
envFrom:
   - secretRef:
	name: app-config

env:
   - name: DB_Password
     valueFrom:
       secretKeyRef:
	  name: app-secret
	  key: DB_Password

volumes:
- name: app-server-volume
  secret:
    secretName: app-secret   
</pre>

<p>
If you where to mount a secret as volume in pod then each attribute in secret is created a file and with value of secrete as its content
Since we are having three attributes there are three files
</p>

<pre class="example">
ls /opt/app-secret-volumes
cat /opt/app-secret-volume/DB_Password 
</pre>
</div>
</div>


<div id="outline-container-org3630847" class="outline-3">
<h3 id="org3630847">A note about Secrets!</h3>
<div class="outline-text-3" id="text-org3630847">
<p>
Remember that secrets encode data in base64 format. Anyone with the base64 encoded secret can easily decode it. As such the secrets can be considered as not very safe.
</p>

<p>
The concept of safety of the Secrets is a bit confusing in Kubernetes. The <a href="https://kubernetes.io/docs/concepts/configuration/secret/">kubernetes documentation</a> page and a lot of blogs out there refer to secrets as a "safer option" to store sensitive data. They are safer than storing in plain text as they reduce the risk of accidentally exposing passwords and other sensitive data. In my opinion it's not the secret itself that is safe, it is the practices around it. 
</p>

<p>
Secrets are not encrypted, so it is not safer in that sense. However, some best practices around using secrets make it safer. As in best practices like:
</p>
<ul class="org-ul">
<li>Not checking-in secret object definition files to source code repositories.</li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/">Enabling Encryption at Rest</a> for Secrets so they are stored encrypted in ETCD.</li>
</ul>

<p>
Also the way kubernetes handles secrets. Such as:
</p>
<ul class="org-ul">
<li>A secret is only sent to a node if a pod on that node requires it.</li>
<li>Kubelet stores the secret into a tmpfs so that the secret is not written to disk storage.</li>
<li>Once the Pod that depends on the secret is deleted, kubelet will delete its local copy of the secret data as well.</li>
</ul>

<p>
Read about the <a href="https://kubernetes.io/docs/concepts/configuration/secret/#protections">protections</a> and <a href="https://kubernetes.io/docs/concepts/configuration/secret/#risks">risks</a> of using secrets <a href="https://kubernetes.io/docs/concepts/configuration/secret/#risks">here</a>
</p>

<p>
Having said that, there are other better ways of handling sensitive data like passwords in Kubernetes, such as using tools like Helm Secrets, <a href="https://www.vaultproject.io/">HashiCorp Vault</a>. I hope to make a lecture on these in the future.
</p>
</div>
</div>
<div id="outline-container-org9e7ed44" class="outline-3">
<h3 id="org9e7ed44">Practice Test - Secrets</h3>
<div class="outline-text-3" id="text-org9e7ed44">
<p>
Practice Test: <a href="https://uklabs.kodekloud.com/topic/practice-test-secrets-2/">https://uklabs.kodekloud.com/topic/practice-test-secrets-2/</a>
</p>
</div>
</div>
<div id="outline-container-org0c8c97f" class="outline-3">
<h3 id="org0c8c97f">Solution - Secrets (Optional)</h3>
<div class="outline-text-3" id="text-org0c8c97f">
<ul class="org-ul">
<li>Q) How many Secrets exist on the system ? namespace=default
<ul class="org-ul">
<li>A) <code>kubectl get secrets</code> # Ans 1</li>
</ul></li>
<li>Q) How many secrets are defined in the 'default-token' secret ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl describe secrets default-tocken-kg52b</code> # check how many sec 3</li>
</ul></li>
</ul></li>
<li>Q) What is the type of the 'default-token' secret ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl describe secrets default-tocken-kg52b | grep -i type</code></li>
</ul></li>
</ul></li>
<li>Q) Which of the following is not a secret data defined in 'default-token' secret
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl describe secrets default-tocken-kg52b</code></li>
</ul></li>
</ul></li>
<li><p>
Q) We are going to deploy an application with the below architechture
We have already deployed the required pods and services. Check out the pods and services created. Check out the web application using the 'Webapp MySQL' link abive your terminal, next to to Quiz Protal Link.
</p></li>
</ul>

<div id="org61ef0d7" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-22 20-54-15.png" alt="Screenshot from 2021-10-22 20-54-15.png" />
</p>
</div>

<ul class="org-ul">
<li>A)  - <code>kubectl get pods,svc</code>
<ul class="org-ul">
<li></li>
</ul></li>
</ul>
<ul class="org-ul">
<li>Q) The reason the application is failed is because we have not created the secrets yet. Create a new Secret anme 'db-secret' with the data given (on the right)
Secret Name=db-secret ,
Secret 1: DB<sub>Host</sub>=sql01
Secret 2:DB<sub>User</sub>=root
Secret 3:DB<sub>Password</sub>=password123
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><pre class="example">
kubectl create secret generic db-secret --from-literal= DB_HOST=sql01 --from-literal=DB_User=root --from-literal=DB_Password=paas

kubectl describe secrets db-secret
</pre></li>
</ul></li>
</ul></li>

<li>Q) Configure webapp-pod to laod enviorment varibales from the newly created secret.
Pod name: web app-pod, Image name: kodekloud/simple-webapp-mysql
  Env From: Secret=db-secret
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pods</code></li>
<li><code>kubectl get pod webapp-pod -o yaml &gt; pod.yaml</code></li>
<li><code>kubectl delete pdo webapp-pod</code></li>
<li><code>vi pod.yaml</code></li>
<li><p>
<code>kubectl expalin pods --recursive | less</code> search envFrom
</p>
<pre class="example">
apiVersion: v1
kind: Pod
metadata:
  labels:
    name: webapp-pod
  namespace: default
spec:
  containers:
  - image: kodekloud/simple-webapp-mysql
    imagePullPolicy: Always
    name: webapp
    envFrom:
    - secretRef:
	name: db-secret
</pre></li>
<li><code>kubectl apply -f pod.yaml</code></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgd7db42e" class="outline-3">
<h3 id="orgd7db42e">Scale Applications</h3>
</div>
<div id="outline-container-orgf312d2c" class="outline-3">
<h3 id="orgf312d2c">Multi Container PODs (Microservices)</h3>
<div class="outline-text-3" id="text-orgf312d2c">
<p>
Explained Microservices
</p>

<p>
Multi container pod share
</p>

<p>
The idea of decoupling a large monolithic application into sub-components known as <b>microservices</b>
</p>

<p>
Which enables us to develop and deploy a set of independent small and reusable code this architecture can then help us scale up/down as well as modify each service
At times you may need two services to work together such as a web server and a logging service.
</p>

<p>
You need one agent instance per web server instance paired together. You don't want to march and bloat the code of the two services as each of them target different functionalities and you'd still like them to be developed and deployed separately you only need the two functionality to work together.
</p>

<p>
You need one agent per web server instance paired together that can scale up and down together and that is why
you have multi-container pods that share the same lifecycle which means they are created together and destroyed together they share the same network space which means they can refer to each other as local host and they have access to the same storage volumes.
</p>

<p>
This way you do not have to establish volume sharing or services between the pods to enable communication between them to create a multi container pod. Add the new container information to the pod definition file.
</p>

<p>
Remember the container section under the spec section in a pod definition file is an array. And the reason it is an array is to allow multiple containers in a single pod.
</p>
<pre class="example">
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2



spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
      - containerPort: 8080 
  - name: mongodb
    image: mongodb1.3
</pre>


<p>
In this case we add a new container named log agent to our existing pod.Well that's it for this lecture.
</p>

<p>
Head over to the coding exercises section and practice configuring multi container pods.
</p>
</div>
</div>


<div id="outline-container-org0460be8" class="outline-3">
<h3 id="org0460be8">Practice Test - Multi Container PODs</h3>
<div class="outline-text-3" id="text-org0460be8">
<p>
Link to Practice Test: <a href="https://uklabs.kodekloud.com/topic/practice-test-multi-container-pods-2/">https://uklabs.kodekloud.com/topic/practice-test-multi-container-pods-2/</a>
</p>
</div>
</div>
<div id="outline-container-org4eb7b59" class="outline-3">
<h3 id="org4eb7b59">Solution - Multi-Container Pods (Optional)</h3>
<div class="outline-text-3" id="text-org4eb7b59">
<ul class="org-ul">
<li>Q) Idenfity the no of containers running in the 'red' pod ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pods</code></li>
</ul></li>
</ul></li>
<li>Q) Idenfity the name of container running in the 'blue' pod.
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>Kubectl get pods</code></li>
<li><code>kubectl describe pod blue</code></li>
<li>GET THE MANE OF CONTAINER: <code>kubectl describe pod blue| grep -i Contaienrs -A 15</code> THERE ARE TWO CONTAINERS</li>
</ul></li>
</ul></li>
<li>Q) Create a multi-container pod with 2 containers
Name: yellow
Contaienr 1 Name: lemon
Container 2 Image: bussybox
Container 2 Name: gold
Container 2 Image: redis  
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><pre class="example">
kubectl run yellow --image=busybox --resart=Never --dry-run -o yaml &gt; pod.yaml
vi pod.yaml
</pre>
<pre class="example">
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: yellow
  name: yellow
spec:
  containers:
  - image: busybox
    name: lemon
  - image: redis
    name: gold

kubectl apply -f pod.yaml
kubectl describe pod yellow
# Inspect the the containers
</pre></li>
</ul></li>
</ul></li>
<li><p>
Q) We have deployed a application logging stack in the elastic-stack namespace. Inspect it.
</p></li>
</ul>

<div id="org164d5a1" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 07-30-47.png" alt="Screenshot from 2021-10-23 07-30-47.png" />        
</p>
</div>
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get ns</code></li>
<li>Get the pods and service running in namespace: elastic-stack
<ul class="org-ul">
<li><code>kubectl -n elastic-stack get pod,svc</code></li>
</ul></li>
</ul></li>
</ul>
<ul class="org-ul">
<li>Q) Inspect the kibana UI using the link aboe your terminal. There shouldn't be any logs for now.
<ul class="org-ul">
<li>A)</li>
</ul></li>
<li>Q) Inspect the 'app' pod any identify the number of containers in it.
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>Get the pods and service running in namespace: elastic-stack
<ul class="org-ul">
<li><code>kubectl -n elastic-stack get pod,svc</code></li>
</ul></li>
</ul></li>
</ul></li>
<li>Q) The 'application outputs logs to the file /log/app.log. View the logs and try to identify the user having issuse with login.'
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl -n elastic-stack log pod</code></li>
</ul></li>
</ul></li>

<li><p>
Q) Edit the pod to add a sidecare container to send logs to elasticSearch.
</p>

<p>
Mount the log volume to the sidecar container.
Name: app, Container Name: sidecar,
Container Image: kodekloud/filebeat-confgured
Volume Mount: log-volume
Mount Path: <i>var/log/event-simulator</i>
Existing Conatainer Name: app
Existing Container Image: kodekloud/event-simulator
</p></li>
</ul>

<div id="orgc104330" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 07-44-56.png" alt="Screenshot from 2021-10-23 07-44-56.png" />        
</p>
</div>
<ul class="org-ul">
<li><p>
A)
</p>
<ul class="org-ul">
<li><code>kubectl -n elastic-stack get pod app -o yaml &gt; app.yaml</code></li>
<li><code>kubectl delete pod app -n elastic-stack</code></li>
<li><code>vi apply.yaml</code></li>
</ul>
<pre class="example">
# add below lines  inside spec/containers:

spec:
  contaienrs:
  - image:kodekloud/filebeat-confgured
    name: sidecar
    volueMounts:
    - mountPat: /var/log/event-simulator
      name: log-volue 
</pre></li>
</ul>

<p>
-Q) Inspect the Kibana UI. You should now see logs apperting in the 'Discover' section.
</p>
<ul class="org-ul">
<li>A)</li>
</ul>
</div>
</div>
<div id="outline-container-org452da59" class="outline-3">
<h3 id="org452da59">Multi-container PODs Design Patterns</h3>
<div class="outline-text-3" id="text-org452da59">
<p>
There are 3 common patterns, when it comes to designing multi-container PODs. The first and what we just saw with the logging service example is known as a side car pattern. The others are the adapter and the ambassador pattern.
</p>

<p>
But these fall under the CKAD curriculum and are not required for the CKA exam. So we will be discuss these in more detail in the CKAD course.
</p>

<div id="org6d9a41a" class="figure">
<p><img src="./Kube-cka/2019-06-07_09-07-13-d077fffd07f3232ae259a9298c0ffa66.PNG" alt="2019-06-07_09-07-13-d077fffd07f3232ae259a9298c0ffa66.PNG" />
</p>
</div>
</div>
</div>
<div id="outline-container-orge5ed758" class="outline-3">
<h3 id="orge5ed758">InitContainers</h3>
<div class="outline-text-3" id="text-orge5ed758">
<p>
In a multi-container pod, each container is expected to run a process that stays alive as long as the POD's lifecycle. For example in the multi-container pod that we talked about earlier that has a web application and logging agent, both the containers are expected to stay alive at all times. The process running in the log agent container is expected to stay alive as long as the web application is running. If any of them fails, the POD restarts.
</p>


<p>
But at times you may want to run a process that runs to completion in a container. For example a process that pulls a code or binary from a repository that will be used by the main web application. That is a task that will be run only  one time when the pod is first created. Or a process that waits  for an external service or database to be up before the actual application starts. That's where initContainers comes in.
</p>


<p>
An initContainer is configured in a pod like all other containers, except that it is specified inside a initContainers section,  like this:
</p>

<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Pod
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: myapp-pod
  <span style="color: #715ab1;">labels</span>:
    <span style="color: #715ab1;">app</span>: myapp
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">containers</span>:
  - <span style="color: #715ab1;">name</span>: myapp-container
    <span style="color: #715ab1;">image</span>: busybox:1.28
    <span style="color: #715ab1;">command</span>: [<span style="color: #2d9574;">'sh'</span>, <span style="color: #2d9574;">'-c'</span>, <span style="color: #2d9574;">'echo The app is running! &amp;&amp; sleep 3600'</span>]
  <span style="color: #715ab1;">initContainers</span>:
  - <span style="color: #715ab1;">name</span>: init-myservice
    <span style="color: #715ab1;">image</span>: busybox
    <span style="color: #715ab1;">command</span>: [<span style="color: #2d9574;">'sh'</span>, <span style="color: #2d9574;">'-c'</span>, <span style="color: #2d9574;">'git clone &lt;some-repository-that-will-be-used-by-application&gt; ; done;'</span>]
</pre>
</div>

<p>
When a POD is first created the initContainer is run, and the process in the initContainer must run to a completion before the real container hosting the application starts. 
</p>

<p>
You can configure multiple such initContainers as well, like how we did for multi-pod containers. In that case each init container is run one at a time in sequential order.
</p>

<p>
If any of the initContainers fail to complete, Kubernetes restarts the Pod repeatedly until the Init Container succeeds.
</p>
<div class="org-src-container">
<pre class="src src-yaml"><span style="color: #715ab1;">apiVersion</span>: v1
<span style="color: #715ab1;">kind</span>: Pod
<span style="color: #715ab1;">metadata</span>:
  <span style="color: #715ab1;">name</span>: myapp-pod
  <span style="color: #715ab1;">labels</span>:
    <span style="color: #715ab1;">app</span>: myapp
<span style="color: #715ab1;">spec</span>:
  <span style="color: #715ab1;">containers</span>:
  - <span style="color: #715ab1;">name</span>: myapp-container
    <span style="color: #715ab1;">image</span>: busybox:1.28
    <span style="color: #715ab1;">command</span>: [<span style="color: #2d9574;">'sh'</span>, <span style="color: #2d9574;">'-c'</span>, <span style="color: #2d9574;">'echo The app is running! &amp;&amp; sleep 3600'</span>]
  <span style="color: #715ab1;">initContainers</span>:
  - <span style="color: #715ab1;">name</span>: init-myservice
    <span style="color: #715ab1;">image</span>: busybox:1.28
    <span style="color: #715ab1;">command</span>: [<span style="color: #2d9574;">'sh'</span>, <span style="color: #2d9574;">'-c'</span>, <span style="color: #2d9574;">'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'</span>]
  - <span style="color: #715ab1;">name</span>: init-mydb
    <span style="color: #715ab1;">image</span>: busybox:1.28
    <span style="color: #715ab1;">command</span>: [<span style="color: #2d9574;">'sh'</span>, <span style="color: #2d9574;">'-c'</span>, <span style="color: #2d9574;">'until nslookup mydb; do echo waiting for mydb; sleep 2; done;'</span>]
</pre>
</div>
</div>
</div>

<div id="outline-container-orge2f04ea" class="outline-3">
<h3 id="orge2f04ea">Practice Test - Init Containers</h3>
<div class="outline-text-3" id="text-orge2f04ea">
<p>
Practice Test Link: <a href="https://uklabs.kodekloud.com/topic/practice-test-init-containers-2/">https://uklabs.kodekloud.com/topic/practice-test-init-containers-2/</a>
</p>
</div>
</div>
<div id="outline-container-org94898d4" class="outline-3">
<h3 id="org94898d4">Solution - Init Containers (Optional)</h3>
<div class="outline-text-3" id="text-org94898d4">
<ul class="org-ul">
<li>Q) Identify the pod that has an initContainer configured
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pods</code></li>
<li>In <code>STATUS</code> we see <code>Init:0/1</code> and the name of pod is <b>blue</b></li>
</ul></li>
</ul></li>
<li>Q) What is the image used by the initContainer on the blue pod ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl describe pod blue | grep -i "init"  -A5</code></li>
<li>The image used by init-container is bussybox</li>
</ul></li>
</ul></li>
<li>Q) What is status of the initContainer on pod blue
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl describe pod blue | grep -i state -A4</code></li>
</ul></li>
</ul></li>
<li>Q) Why is the initContainer terminated ? What is the reason ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl describe pod blue | grep -i state -A4</code></li>
<li>The resason is state is completed</li>
</ul></li>
</ul></li>
<li>Q) We just created a new app  named purple.How many initContaienrs does it have ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pods | grep Init</code></li>
<li>The container <b>purple</b></li>
<li>Revaluate:
<ul class="org-ul">
<li><code>kubectl describe pod purple | grep Image</code></li>
<li>there are two init containers</li>
<li>Ans is 2</li>
</ul></li>
</ul></li>
</ul></li>
<li>Q) What is the state of pod ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl describe pod blue | grep State -B 11</code></li>
<li>There are two container
<ul class="org-ul">
<li>Container-1 : busybox:1.28 is in running state</li>
<li>Container-2 : busybox:1.28 is Wating</li>
<li>So ANS to solution is <b>Waiting</b></li>
</ul></li>
</ul></li>
</ul></li>
<li>Q) How long after the creation of the POD will application come up and be availabe to users ?
<ul class="org-ul">
<li></li>
</ul></li>
<li>Q) Update the pod red to use an initConatiner that uses the busybox image and sleep for 20 seconds
Pod: red,
initContainer Configured Correctly
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pod red -o yaml &gt; red.yaml</code></li>
<li><code>kubectl delete pod red</code></li>
<li><p>
<code>vi red.yaml</code>
</p>
<pre class="example">
apiVersion: v1
kind: Pod
metadata:
  name: red
  namespace: default
spec:
  containers:
  - command:
    - sh
    - -c
    - echo The app is running! &amp;&amp; sleep 3600
    image: busybox:1.28
    imagePullpolicy: IfNotPresent
    name: red-container
    resources: {}
    terminationMessagepath: /dev/terminaation-log
    terminationMessagepolicy: File
  initContainers:
  - image: busybox
    name: red-initcontainer
    command: ["sleep", "20"]
</pre></li>
<li><code>kubectl apply -f red.yaml</code></li>
<li><code>kubectl describe pod red</code></li>
<li>Check the status of each container</li>
</ul></li>
</ul></li>

<li>Q) A new application orange is deployed. There is something wrong with it Identify and fix the issuse.
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>Inspect the pod
<ul class="org-ul">
<li><code>kubectl describe pod orage</code></li>
<li>the is spelling error in initContainer command[sh -c sleeeeep 2]  name: origianl command is [sh -c sleep 2]</li>
<li>change the sleeeep to sleep</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org021b395" class="outline-3">
<h3 id="org021b395">Self Healing Applications</h3>
<div class="outline-text-3" id="text-org021b395">
<p>
Kubernetes supports self-healing applications through ReplicaSets and Replication Controllers. The replication controller helps in ensuring that a POD is re-created automatically when the application within the POD crashes. It helps in ensuring enough replicas of the application are running at all times.
</p>

<p>
Kubernetes provides additional support to check the health of applications running within PODs and take necessary actions through Liveness and Readiness Probes. However these are not required for the CKA exam and as such they are not covered here. These are topics for the Certified Kubernetes Application Developers (CKAD) exam and are covered in the CKAD course. 
</p>
</div>
</div>
<div id="outline-container-orgd21de8f" class="outline-3">
<h3 id="orgd21de8f">If you like it, Share it!</h3>
<div class="outline-text-3" id="text-orgd21de8f">
<p>
Hope you are enjoying this course. If you like it share it in your community. Here's a twitter template:
</p>

<p>
<a href="https://ctt.ac/nc_f6">https://ctt.ac/nc_f6</a>
</p>
</div>
</div>
</div>


<div id="outline-container-org04b0fd1" class="outline-2">
<h2 id="org04b0fd1">Storage 55min</h2>
<div class="outline-text-2" id="text-org04b0fd1">
</div>
<div id="outline-container-org998a649" class="outline-3">
<h3 id="org998a649">Docker Storage</h3>
<div class="outline-text-3" id="text-org998a649">
</div>
<div id="outline-container-orgfc2c086" class="outline-4">
<h4 id="orgfc2c086">Storage in Docker</h4>
</div>
<div id="outline-container-org83f9cc3" class="outline-4">
<h4 id="org83f9cc3">Volume Driver Plugins in Docker</h4>
</div>
<div id="outline-container-orgdb0295c" class="outline-4">
<h4 id="orgdb0295c">Container Storage Interface (CSI)</h4>
</div>
</div>
<div id="outline-container-org627896d" class="outline-3">
<h3 id="org627896d">Volumes in Kubernetics</h3>
<div class="outline-text-3" id="text-org627896d">
</div>
<div id="outline-container-orge92c16e" class="outline-4">
<h4 id="orge92c16e">Volumes</h4>
</div>
<div id="outline-container-org5d9f040" class="outline-4">
<h4 id="org5d9f040">Persistent Volumes</h4>
</div>

<div id="outline-container-org116ab00" class="outline-4">
<h4 id="org116ab00">Persistent Volume Claims (PVC)</h4>
</div>
<div id="outline-container-orgdd72baa" class="outline-4">
<h4 id="orgdd72baa">Using PVCs in PODs</h4>
</div>
<div id="outline-container-org965b782" class="outline-4">
<h4 id="org965b782">Practice Test - Persistent Volumes and Persistent Volume Claims</h4>
</div>
<div id="outline-container-org567da6a" class="outline-4">
<h4 id="org567da6a">Solution - Persistent Volumes and Persistent Volume Claims</h4>
</div>
</div>
<div id="outline-container-org547df55" class="outline-3">
<h3 id="org547df55">Application Configuration</h3>
<div class="outline-text-3" id="text-org547df55">
<p>
We discussed how to configure an application to use a volume in the "Volumes" lecture using volumeMounts. This along with the practice test should be sufficient for the exam.
</p>
</div>
</div>
<div id="outline-container-org1612dc2" class="outline-3">
<h3 id="org1612dc2">Additional Topics</h3>
<div class="outline-text-3" id="text-org1612dc2">
<p>
Additional topics such as StatefulSets are out of scope for the exam. However, if you wish to learn them, they are covered in the  Certified Kubernetes Application Developer (CKAD) course.
</p>
</div>
</div>
<div id="outline-container-orge5cc8bd" class="outline-3">
<h3 id="orge5cc8bd">Storage Class</h3>
</div>
</div>

<div id="outline-container-org57ea756" class="outline-2">
<h2 id="org57ea756">Networking 3h 7min</h2>
<div class="outline-text-2" id="text-org57ea756">
</div>
<div id="outline-container-orgffa6f2a" class="outline-3">
<h3 id="orgffa6f2a">Prerequisite Networking</h3>
<div class="outline-text-3" id="text-orgffa6f2a">
</div>
<div id="outline-container-org27522a3" class="outline-4">
<h4 id="org27522a3">Switching Routing</h4>
<div class="outline-text-4" id="text-org27522a3">

<div id="orge5770df" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 15-45-25.gif" alt="Screenshot from 2021-10-23 15-45-25.gif" />
</p>
</div>


<div id="org0ec7f3a" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 15-46-29.gif" alt="Screenshot from 2021-10-23 15-46-29.gif" />
</p>
</div>


<div id="org7a94f2d" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 15-47-13.gif" alt="Screenshot from 2021-10-23 15-47-13.gif" />
</p>
</div>


<div id="orga6828cb" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 15-48-51.gif" alt="Screenshot from 2021-10-23 15-48-51.gif" />
</p>
</div>

<p>
Set Linux host as a router 
</p>

<div id="org5969e4c" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 15-50-30.gif" alt="Screenshot from 2021-10-23 15-50-30.gif" />
</p>
</div>
</div>
</div>
<div id="outline-container-org2aa59cd" class="outline-4">
<h4 id="org2aa59cd">DNS</h4>
<div class="outline-text-4" id="text-org2aa59cd">

<div id="org51ed6ac" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-18-36.gif" alt="Screenshot from 2021-10-23 16-18-36.gif" />
</p>
</div>

<div id="orgfa00ed0" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-20-34.gif" alt="Screenshot from 2021-10-23 16-20-34.gif" />
</p>
</div>

<div id="org6442e49" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-21-03.gif" alt="Screenshot from 2021-10-23 16-21-03.gif" />
</p>
</div>

<div id="org343a859" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-23-37.gif" alt="Screenshot from 2021-10-23 16-23-37.gif" />
</p>
</div>

<div id="org4fd2dda" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-41-15.gif" alt="Screenshot from 2021-10-23 16-41-15.gif" />
</p>
</div>

<div id="orgac1e2df" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-42-28.gif" alt="Screenshot from 2021-10-23 16-42-28.gif" />
</p>
</div>


<div id="org91293d4" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-42-28.png" alt="Screenshot from 2021-10-23 16-42-28.png" />
</p>
</div>

<div id="org4fa01a4" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-42-49.png" alt="Screenshot from 2021-10-23 16-42-49.png" />
</p>
</div>

<div id="org822a9c3" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-42-55.png" alt="Screenshot from 2021-10-23 16-42-55.png" />
</p>
</div>

<div id="orgbfedf1d" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 16-43-11.png" alt="Screenshot from 2021-10-23 16-43-11.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org4bd9417" class="outline-4">
<h4 id="org4bd9417">CoreDNS</h4>
<div class="outline-text-4" id="text-org4bd9417">
<p>
In the previous lecture we saw why you need a DNS server and how it can help manage name resolution in large environments with many hostnames and Ips and how you can configure your hosts to point to a DNS server. In this article we will see how to configure a host as a DNS server.
</p>


<p>
We are given a server dedicated as the DNS server, and a set of Ips to configure as entries in the server. There are many DNS server solutions out there, in this lecture we will focus on a particular one  CoreDNS.
</p>


<p>
So how do you get core dns? CoreDNS binaries can be downloaded from their Github releases page or as a docker image. Lets go the traditional route. Download the binary using curl or wget. And extract it. You get the coredns executable.
</p>
</div>
</div>
<div id="outline-container-org5fc590d" class="outline-4">
<h4 id="org5fc590d">Network Namespaces</h4>
<div class="outline-text-4" id="text-org5fc590d">

<div id="org3d30835" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 17-47-08.gif" alt="Screenshot from 2021-10-23 17-47-08.gif" />
</p>
</div>

<div id="org3e03bd8" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 17-47-25.gif" alt="Screenshot from 2021-10-23 17-47-25.gif" />
</p>
</div>

<div id="org4de8552" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 17-48-16.gif" alt="Screenshot from 2021-10-23 17-48-16.gif" />
</p>
</div>

<div id="org89fbcbe" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 17-48-26.gif" alt="Screenshot from 2021-10-23 17-48-26.gif" />
</p>
</div>

<div id="orgfd9d33a" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 17-48-29.gif" alt="Screenshot from 2021-10-23 17-48-29.gif" />
</p>
</div>

<div id="org34500f1" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 17-50-49.gif" alt="Screenshot from 2021-10-23 17-50-49.gif" />
</p>
</div>

<div id="org6ae169d" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 17-50-52.gif" alt="Screenshot from 2021-10-23 17-50-52.gif" />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orge0beac0" class="outline-3">
<h3 id="orge0beac0">FAQ</h3>
<div class="outline-text-3" id="text-orge0beac0">
<p>
While testing the Network Namespaces, if you come across issues where you can't ping one namespace from the other, make sure you set the NETMASK while setting IP Address. ie: 192.168.1.10/24
</p>


<p>
ip -n red addr add 192.168.1.10/24 dev veth-red
</p>


<p>
Another thing to check is FirewallD/IP Table rules. Either add rules to IP Tables to allow traffic from one namespace to another. Or disable IP Tables all together (Only in a learning environment).
</p>
</div>
</div>

<div id="outline-container-org10598ea" class="outline-3">
<h3 id="org10598ea">SKIP Prerequisite - Docker Networking</h3>
</div>
<div id="outline-container-org2950f39" class="outline-3">
<h3 id="org2950f39">SKIP Prerequisite - CNI</h3>
</div>
<div id="outline-container-org80f32af" class="outline-3">
<h3 id="org80f32af">Cluster Networkingin</h3>
<div class="outline-text-3" id="text-org80f32af">

<div id="org9ae37d9" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 18-20-57.gif" alt="Screenshot from 2021-10-23 18-20-57.gif" />
</p>
</div>

<div id="orgd9178aa" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 18-21-34.png" alt="Screenshot from 2021-10-23 18-21-34.png" />
</p>
</div>

<div id="orgf9a6e36" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 18-21-39.png" alt="Screenshot from 2021-10-23 18-21-39.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgb828b4d" class="outline-3">
<h3 id="orgb828b4d">Important Note about CNI and CKA Exam</h3>
<div class="outline-text-3" id="text-orgb828b4d">
<p>
Important Note about CNI and CKA Exam
</p>

<p>
An important tip about deploying Network Addons in a Kubernetes cluster.
</p>

<p>
In the upcoming labs, we will work with Network Addons. This includes installing a network plugin in the cluster. While we have used weave-net as an example, please bear in mind that you can use any of the plugins which are described here:
</p>

<p>
<a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">https://kubernetes.io/docs/concepts/cluster-administration/addons/</a>
<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-networking-model">https://kubernetes.io/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-networking-model</a>
</p>


<p>
In the CKA exam, for a question that requires you to deploy a network addon, unless specifically directed, you may use any of the solutions described in the link above.
</p>

<p>
However, the documentation currently does not contain a direct reference to the exact command to be used to deploy a third party network addon.
</p>

<p>
The links above redirect to third party/ vendor sites or GitHub repositories which cannot be used in the exam. This has been intentionally done to keep the content in the Kubernetes documentation vendor-neutral.
</p>

<p>
At this moment in time, there is still one place within the documentation where you can find the exact command to deploy weave network addon:
<a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/#steps-for-the-first-control-plane-node">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/#steps-for-the-first-control-plane-node</a> (step 2)
</p>
</div>
</div>
<div id="outline-container-org09ae042" class="outline-3">
<h3 id="org09ae042">Practice Test - Explore Kubernetes Environment</h3>
</div>
<div id="outline-container-orgcfa4298" class="outline-3">
<h3 id="orgcfa4298">Solution - Explore Environment (optional)</h3>
</div>
<div id="outline-container-orge5f4194" class="outline-3">
<h3 id="orge5f4194">Pod Networking</h3>
</div>
<div id="outline-container-org25abac7" class="outline-3">
<h3 id="org25abac7">CNI in kubernetes</h3>
</div>
<div id="outline-container-org0fb0aa7" class="outline-3">
<h3 id="org0fb0aa7">CNI weave</h3>
</div>
<div id="outline-container-org782398d" class="outline-3">
<h3 id="org782398d">Practice Test - Explore CNI Weave</h3>
</div>
<div id="outline-container-orgab1ba80" class="outline-3">
<h3 id="orgab1ba80">Solution - Explore CNI Weave (optional)</h3>
</div>
<div id="outline-container-org5c52a63" class="outline-3">
<h3 id="org5c52a63">Practice Test - Deploy Network Solution</h3>
</div>
<div id="outline-container-org4c448b5" class="outline-3">
<h3 id="org4c448b5">Solution - Deploy Network Solution (optional)</h3>
</div>
<div id="outline-container-org99958a4" class="outline-3">
<h3 id="org99958a4">IP Address Management - Weave</h3>
</div>
<div id="outline-container-org923d0fe" class="outline-3">
<h3 id="org923d0fe">Practice Test - Networking Weave</h3>
</div>
<div id="outline-container-orgd90f791" class="outline-3">
<h3 id="orgd90f791">Solution - Networking Weave (optional)</h3>
</div>
<div id="outline-container-org24b1621" class="outline-3">
<h3 id="org24b1621">Service Networking</h3>
</div>
<div id="outline-container-org05af443" class="outline-3">
<h3 id="org05af443">Practice Test - Service Networking</h3>
</div>
<div id="outline-container-org2d0c9d4" class="outline-3">
<h3 id="org2d0c9d4">Solution - Service Networking (optional)</h3>
</div>
<div id="outline-container-org2e3d06d" class="outline-3">
<h3 id="org2e3d06d">DNS in kubernetes</h3>
</div>
<div id="outline-container-orgdbce78a" class="outline-3">
<h3 id="orgdbce78a">CoreDNS in Kubernetes</h3>
</div>
<div id="outline-container-org818f76e" class="outline-3">
<h3 id="org818f76e">Practice Test - Explore DNS</h3>
</div>
<div id="outline-container-org8c4e5f0" class="outline-3">
<h3 id="org8c4e5f0">Solution - Explore DNS (optional)</h3>
</div>
<div id="outline-container-org6ba6e31" class="outline-3">
<h3 id="org6ba6e31">Ingress</h3>
<div class="outline-text-3" id="text-org6ba6e31">

<div id="org842bc30" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 20-02-34.gif" alt="Screenshot from 2021-10-23 20-02-34.gif" />
</p>
</div>

<div id="org2c09b20" class="figure">
<p><img src="./Kube-cka/Screenshot from 2021-10-23 20-03-10.gif" alt="Screenshot from 2021-10-23 20-03-10.gif" />
</p>
</div>
</div>
</div>

<div id="outline-container-orgd5307dc" class="outline-3">
<h3 id="orgd5307dc">Article: Ingress</h3>
</div>
<div id="outline-container-orga994360" class="outline-3">
<h3 id="orga994360">Practice Test - Ingress - 1</h3>
</div>
<div id="outline-container-orga1f1ff3" class="outline-3">
<h3 id="orga1f1ff3">Solution - Ingress Networking 1 - (optional)</h3>
</div>
<div id="outline-container-orge3af46a" class="outline-3">
<h3 id="orge3af46a">Ingress - Annotations and rewrite-target</h3>
</div>
<div id="outline-container-org3a5a320" class="outline-3">
<h3 id="org3a5a320">Practice Test - Ingress - 2</h3>
</div>
<div id="outline-container-org75f06a2" class="outline-3">
<h3 id="org75f06a2">Solution - Ingress Networking - 2 (optional)</h3>
</div>
</div>
<div id="outline-container-orgc7c6727" class="outline-2">
<h2 id="orgc7c6727">Security 2h 21 min</h2>
<div class="outline-text-2" id="text-orgc7c6727">
</div>
<div id="outline-container-orga398b96" class="outline-3">
<h3 id="orga398b96">Kubernetes Security Primitives</h3>
</div>
<div id="outline-container-orga687c36" class="outline-3">
<h3 id="orga687c36">Authentication</h3>
</div>

<div id="outline-container-org0bb94bd" class="outline-3">
<h3 id="org0bb94bd">Article on Setting up Basic Authentication</h3>
</div>
<div id="outline-container-org35effd8" class="outline-3">
<h3 id="org35effd8">TLS Introduction</h3>
</div>
<div id="outline-container-orgd8b4588" class="outline-3">
<h3 id="orgd8b4588">TLS Basics</h3>
</div>
<div id="outline-container-org28f5ced" class="outline-3">
<h3 id="org28f5ced">TLS in Kubernetes</h3>
</div>
<div id="outline-container-org083b91f" class="outline-3">
<h3 id="org083b91f">TLS in Kubernetes - Certificate Creation</h3>
</div>
<div id="outline-container-org487eef4" class="outline-3">
<h3 id="org487eef4">View Certificate Details</h3>
</div>
<div id="outline-container-org3f4932e" class="outline-3">
<h3 id="org3f4932e">Resource: Download Kubernetes Certificate Health Check Spreadsheet</h3>
</div>
<div id="outline-container-org2b0cf12" class="outline-3">
<h3 id="org2b0cf12">Practice Test - View Certificates</h3>
</div>
<div id="outline-container-org6603581" class="outline-3">
<h3 id="org6603581">Certificates API</h3>
</div>
<div id="outline-container-orgcf34c14" class="outline-3">
<h3 id="orgcf34c14">Practice Test - Certificates API</h3>
</div>
<div id="outline-container-orgd40c1e8" class="outline-3">
<h3 id="orgd40c1e8">KubeConfig</h3>
</div>
<div id="outline-container-org203dace" class="outline-3">
<h3 id="org203dace">Practice Test - KubeConfig</h3>
</div>
<div id="outline-container-org9f3041f" class="outline-3">
<h3 id="org9f3041f">Persistent Key/Value Store</h3>
</div>
<div id="outline-container-orge2820ea" class="outline-3">
<h3 id="orge2820ea">API Groups</h3>
</div>
<div id="outline-container-org928686e" class="outline-3">
<h3 id="org928686e">Authorization</h3>
</div>
<div id="outline-container-org242e2dc" class="outline-3">
<h3 id="org242e2dc">Role Based Access Controls</h3>
</div>
<div id="outline-container-orgb45b49a" class="outline-3">
<h3 id="orgb45b49a">Practice Test - RBAC</h3>
</div>
<div id="outline-container-org04c5c7a" class="outline-3">
<h3 id="org04c5c7a">Cluster Roles and Role Bindings</h3>
</div>
<div id="outline-container-org861d71d" class="outline-3">
<h3 id="org861d71d">Practice Test - Cluster Roles and Role Bindings</h3>
</div>
<div id="outline-container-org9899a5b" class="outline-3">
<h3 id="org9899a5b">Service Accounts</h3>
</div>
<div id="outline-container-org78ea4bd" class="outline-3">
<h3 id="org78ea4bd">Practice Test Service Accounts</h3>
</div>
<div id="outline-container-org7698b2e" class="outline-3">
<h3 id="org7698b2e">Image Security</h3>
</div>
<div id="outline-container-orgc654f14" class="outline-3">
<h3 id="orgc654f14">Practice Test - Image Security</h3>
</div>
<div id="outline-container-orga240ec2" class="outline-3">
<h3 id="orga240ec2">Security Contexts</h3>
</div>
<div id="outline-container-orgdb160fa" class="outline-3">
<h3 id="orgdb160fa">Practice Test - Security Contexts</h3>
</div>
<div id="outline-container-orge3fec2f" class="outline-3">
<h3 id="orge3fec2f">Network Policy</h3>
</div>
<div id="outline-container-org0ba53c9" class="outline-3">
<h3 id="org0ba53c9">Developing network policies</h3>
</div>
<div id="outline-container-org309f9c9" class="outline-3">
<h3 id="org309f9c9">Practice Test - Network Policy</h3>
</div>
<div id="outline-container-orgf447efb" class="outline-3">
<h3 id="orgf447efb">Solution - Network Policies (optional)</h3>
</div>
</div>
<div id="outline-container-orgbeeccd4" class="outline-2">
<h2 id="orgbeeccd4">Design and Install a Kubernetes Cluster</h2>
<div class="outline-text-2" id="text-orgbeeccd4">
</div>
<div id="outline-container-org500e43f" class="outline-3">
<h3 id="org500e43f">Design a Kubernetes Cluster</h3>
</div>
<div id="outline-container-orgd861752" class="outline-3">
<h3 id="orgd861752">Choosing Kubernetes Infrastructure</h3>
</div>
<div id="outline-container-orgff481fa" class="outline-3">
<h3 id="orgff481fa">Configure High Availability</h3>
</div>
<div id="outline-container-orge0032b3" class="outline-3">
<h3 id="orge0032b3">ETCD in HA</h3>
</div>
<div id="outline-container-orgfb9fa87" class="outline-3">
<h3 id="orgfb9fa87">Important Update: Kubernetes the Hard Way</h3>
</div>
</div>
<div id="outline-container-org59fb8b5" class="outline-2">
<h2 id="org59fb8b5">Cluster Maintenace | 1h 11 min</h2>
<div class="outline-text-2" id="text-org59fb8b5">
</div>
<div id="outline-container-orgc9ee594" class="outline-3">
<h3 id="orgc9ee594">OS Upgrades</h3>
<div class="outline-text-3" id="text-orgc9ee594">
<p>
There is a scenarios where you want to take down the node as part of your cluster like maintainace, security update, applying patches&#x2026;etc.
So you have a cluster with a few notes and pods serving applications.
</p>
<ul class="org-ul">
<li>Q) What happens when one of these nodes go down.?
<ul class="org-ul">
<li>Of course the pods on them are not accessible. Now depending upon how you deployed those PODs your users may be impacted.</li>
<li>For example, since you have multiple replicas of the blue pod, the users accessing the blue application are not impacted as they are being served through the other blue pod that's on line. However users accessing the green pod, are impacted as that was the only pod running the green application.</li>
</ul></li>
<li>Q) Now what does kubernetes do in this case?
<ul class="org-ul">
<li>If the node came back online immediately, then the kubectl process starts and the pods come back onine.</li>
</ul></li>
<li>Q) However, if the node was down for more than 5 minutes ?
<ul class="org-ul">
<li>then the pods are terminated from that node.</li>
<li>Well, kubernetes considers them as dead.</li>
<li>If the PODs where part of a replicaset then they are recreated on other nodes.The time it waits for a pod to come back online is known as the <code>pod eviction timeout</code> and is set on the <code>controller manager</code> with a default value of 5 minutes.</li>
<li><code>kube-contorller-manager --pod-eviction-timeout=5m0s</code></li>
<li>So whenever a node goes offline, the master node waits for upto 5 minutes before considering the node dead.</li>
</ul></li>
<li>Q) What happend when node come back after 5 mints ?
<ul class="org-ul">
<li>When the node comes back on line after the pod eviction timeout it comes up blank without any pods scheduled on it.</li>
<li>Since the blue pod was part of a replicaset, it had a new pod created On another node. However since the green pod was not part of the replica set it's just gone.</li>
</ul></li>
</ul>
<p>
NOTE:
</p>
<ul class="org-ul">
<li>Thus if you have maintenance tasks to be performed on a node if you know that the workloads running on the Node have other replicas and if it's okay that they go down for a short period of time. And if you're sure the node will come back on line within five minutes you can make a quick upgrade and reboot.</li>

<li>Q) However you do not for sure know if a node is going to be back on line in five minutes ? 
<ul class="org-ul">
<li>Well you cannot for sure say it is going to be back at all.
So there is a safer way to do it.
<ul class="org-ul">
<li>You can purposefully drain the node of all the workloads so that the workloads are moved to other nodes in the cluster. When you drain the node the pods are gracefully terminated from the node that they're on and recreated on another.</li>
<li><code>kubectl drain node-1</code></li>
<li>The node is also cordoned or marked as unschedulable. Meaning no pods can be scheduled on this node until you specifically remove the restriction.
Now that the pods are safe on the others nodes, you can reboot the first node. When it comes back online it is still unschedulable.</li>
<li>You then need to uncordon it, so that pods can be scheduled on it again.Now, remember the pods that were moved to the other nodes, dont automatically fall back. If any of those pods where deleted or if new pods were created in the cluster,Then they would be created on this node.</li>
<li><code>kubectl uncordon node-1</code></li>
</ul></li>
</ul></li>
</ul>
<p>
NOTE:
Apart from drain and uncordon, there is also another command called cordon. Cordon simply marks a node unschedulable.Unlike drain it does not terminate or move the pods on an existing node.It simply makes sure that new pods are not scheduled on that node. <code>kubectl uncordon node-1</code>
</p>
</div>
</div>
<div id="outline-container-org353e28b" class="outline-3">
<h3 id="org353e28b">Practice Test - OS Upgrades</h3>
<div class="outline-text-3" id="text-org353e28b">
<p>
Practice Test: <a href="https://uklabs.kodekloud.com/topic/practice-test-os-upgrades-2/">https://uklabs.kodekloud.com/topic/practice-test-os-upgrades-2/</a>
</p>
</div>
</div>
<div id="outline-container-org5fc058e" class="outline-3">
<h3 id="org5fc058e">Solution - OS Upgrades (optional)</h3>
<div class="outline-text-3" id="text-org5fc058e">
<ul class="org-ul">
<li>Q) Let us explore the enviroment first.How many nodes do you see in the cluster ?
<ul class="org-ul">
<li>A) <code>kubectl get nodes</code></li>
</ul></li>
<li>Q) How many applications do you see hosted on the cluster ?
<ul class="org-ul">
<li>A) <code>kubectl get deployment</code></li>
</ul></li>
<li>Q) Which nodes are the application hosted on ?
<ul class="org-ul">
<li>A) <code>kubectl get pods -o wide</code></li>
</ul></li>
<li>Q) We need to take node01 out for maintenance. Empty the node of all application and mark it unschedulable.
Node node01: Unschedulable, Pds evicted from node01
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl drain node01</code> # If error in daemonset</li>
<li><code>kubectl drain node01 --ignore-daemonset</code></li>
</ul></li>
</ul></li>
<li>Q) What nodes apps are running ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pods -o wide</code></li>
</ul></li>
</ul></li>
<li>Q) The maintenace task have been completed.Configure the node to be schedulable again.
Node
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl uncordon node01</code></li>
<li><code>kubectl get nodes</code></li>
</ul></li>
</ul></li>
<li>Q) How many pods are deployed on node01 ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl get pods -o wide</code>  # There are no pods deployed in node01</li>
<li># The pods in node01 #Result: there are no pods</li>
</ul></li>
</ul></li>
<li>Q) Why are there no pods on node01?
<ul class="org-ul">
<li>A) Only when new pods are created they will be scheduled</li>
</ul></li>

<li>Q) Why are there no pods on master node ?
<ul class="org-ul">
<li>A) <code>kubectl descirbe nodes master | grep -i tain</code></li>
</ul></li>

<li>Q) It is now time to take down node02 for maintenance.Before you remove all workload from node02 answer the following question.
Can you drain node02 using the same command as node01 ? Try it.
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl drain node02 --ignore-daemonsets</code></li>
<li>ERROR: canno delete pods not managed by ReplicationContorller,Replicaset, Job, DeamonSet,or StatefulSet</li>
</ul></li>
</ul></li>

<li>Q) Why do you need to force the drain ?
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>node02 has a pod not part of a replicaset</li>
</ul></li>
</ul></li>

<li>Q) What is the name of Pod not part of a replicaset hosted on node01 ?
<ul class="org-ul">
<li><code>kubectl drain node02</code></li>
<li>default/hr-app</li>
</ul></li>
<li>Q) Drain node02 and mark it unschedulable
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li>=kubectl drain node02 &#x2013;ignore-daemonsets &#x2013;force</li>
</ul></li>
</ul></li>
<li>Q) Node03 has our critical applications. We don't  want to schedule anymore apps on node03. Mark node03 as unschedulable but do not remove any apps currently running on it.
<ul class="org-ul">
<li>A)
<ul class="org-ul">
<li><code>kubectl cordon node03</code></li>
<li><code>kubectl get nodes</code></li>
<li>CHECK if node03 status is "Ready, SchedulingDisabled"</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org2341d39" class="outline-3">
<h3 id="org2341d39">Kubernetes Software Versions</h3>
<div class="outline-text-3" id="text-org2341d39">
<p>
version: v1.11.3
v1: major
11: minor: features or functinalites (few months )
3 : path:  bug fixes (most offen most critical bug fix)
</p>
</div>
</div>
<div id="outline-container-org5c9e732" class="outline-3">
<h3 id="org5c9e732">References</h3>
<div class="outline-text-3" id="text-org5c9e732">
<p>
<a href="https://kubernetes.io/docs/concepts/overview/kubernetes-api/">https://kubernetes.io/docs/concepts/overview/kubernetes-api/</a>
</p>

<p>
Here is a link to kubernetes documentation if you want to learn more about this topic (You don't need it for the exam though):
</p>

<p>
<a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md">https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md</a>
</p>

<p>
<a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api_changes.md">https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api_changes.md</a>
</p>
</div>
</div>

<div id="outline-container-org8df0251" class="outline-3">
<h3 id="org8df0251">Cluster Upgrade Process</h3>
</div>

<div id="outline-container-orgc301fb7" class="outline-3">
<h3 id="orgc301fb7">Demo - Cluster upgrade</h3>
</div>
<div id="outline-container-orgd7d8bfb" class="outline-3">
<h3 id="orgd7d8bfb">Practice Test - Cluster Upgrade</h3>
</div>
<div id="outline-container-org0ebde59" class="outline-3">
<h3 id="org0ebde59">Solution: Cluster Upgrade</h3>
</div>
<div id="outline-container-org591e5be" class="outline-3">
<h3 id="org591e5be">Backup and Restore Methods</h3>
</div>
<div id="outline-container-org2db90ce" class="outline-3">
<h3 id="org2db90ce">Working with ETCDCTL</h3>
</div>
<div id="outline-container-orgefbf6c8" class="outline-3">
<h3 id="orgefbf6c8">Practice Test - Backup and Restore Methods</h3>
</div>
<div id="outline-container-orgc506378" class="outline-3">
<h3 id="orgc506378">Solution - Backup and Restore</h3>
</div>
<div id="outline-container-orgca73c5a" class="outline-3">
<h3 id="orgca73c5a">Certification Exam Tip!</h3>
</div>
<div id="outline-container-org5204120" class="outline-3">
<h3 id="org5204120">References</h3>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Udemy Mumshad Mannambeth</p>
<p class="date">Created: 2022-07-17 Sun 16:30</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
